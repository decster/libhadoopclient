// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yarn_protos.proto

#ifndef PROTOBUF_yarn_5fprotos_2eproto__INCLUDED
#define PROTOBUF_yarn_5fprotos_2eproto__INCLUDED

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 2005000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 2005000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
#include "Security.pb.h"
// @@protoc_insertion_point(includes)

namespace hadoop {
namespace yarn {

// Internal implementation detail -- do not call these.
void  protobuf_AddDesc_yarn_5fprotos_2eproto();
void protobuf_AssignDesc_yarn_5fprotos_2eproto();
void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

class SerializedExceptionProto;
class ApplicationIdProto;
class ApplicationAttemptIdProto;
class ContainerIdProto;
class ResourceProto;
class ResourceOptionProto;
class NodeResourceMapProto;
class PriorityProto;
class ContainerProto;
class URLProto;
class LocalResourceProto;
class ApplicationResourceUsageReportProto;
class ApplicationReportProto;
class NodeIdProto;
class NodeReportProto;
class ResourceRequestProto;
class PreemptionMessageProto;
class StrictPreemptionContractProto;
class PreemptionContractProto;
class PreemptionContainerProto;
class PreemptionResourceRequestProto;
class ResourceBlacklistRequestProto;
class ApplicationSubmissionContextProto;
class ApplicationACLMapProto;
class YarnClusterMetricsProto;
class QueueInfoProto;
class QueueUserACLInfoProto;
class ContainerLaunchContextProto;
class ContainerStatusProto;
class ContainerResourceIncreaseRequestProto;
class ContainerResourceIncreaseProto;
class ContainerResourceDecreaseProto;
class StringLocalResourceMapProto;
class StringStringMapProto;
class StringBytesMapProto;

enum ContainerStateProto {
  C_NEW = 1,
  C_RUNNING = 2,
  C_COMPLETE = 3
};
bool ContainerStateProto_IsValid(int value);
const ContainerStateProto ContainerStateProto_MIN = C_NEW;
const ContainerStateProto ContainerStateProto_MAX = C_COMPLETE;
const int ContainerStateProto_ARRAYSIZE = ContainerStateProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* ContainerStateProto_descriptor();
inline const ::std::string& ContainerStateProto_Name(ContainerStateProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    ContainerStateProto_descriptor(), value);
}
inline bool ContainerStateProto_Parse(
    const ::std::string& name, ContainerStateProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<ContainerStateProto>(
    ContainerStateProto_descriptor(), name, value);
}
enum YarnApplicationStateProto {
  NEW = 1,
  NEW_SAVING = 2,
  SUBMITTED = 3,
  ACCEPTED = 4,
  RUNNING = 5,
  FINISHED = 6,
  FAILED = 7,
  KILLED = 8
};
bool YarnApplicationStateProto_IsValid(int value);
const YarnApplicationStateProto YarnApplicationStateProto_MIN = NEW;
const YarnApplicationStateProto YarnApplicationStateProto_MAX = KILLED;
const int YarnApplicationStateProto_ARRAYSIZE = YarnApplicationStateProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* YarnApplicationStateProto_descriptor();
inline const ::std::string& YarnApplicationStateProto_Name(YarnApplicationStateProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    YarnApplicationStateProto_descriptor(), value);
}
inline bool YarnApplicationStateProto_Parse(
    const ::std::string& name, YarnApplicationStateProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<YarnApplicationStateProto>(
    YarnApplicationStateProto_descriptor(), name, value);
}
enum FinalApplicationStatusProto {
  APP_UNDEFINED = 0,
  APP_SUCCEEDED = 1,
  APP_FAILED = 2,
  APP_KILLED = 3
};
bool FinalApplicationStatusProto_IsValid(int value);
const FinalApplicationStatusProto FinalApplicationStatusProto_MIN = APP_UNDEFINED;
const FinalApplicationStatusProto FinalApplicationStatusProto_MAX = APP_KILLED;
const int FinalApplicationStatusProto_ARRAYSIZE = FinalApplicationStatusProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* FinalApplicationStatusProto_descriptor();
inline const ::std::string& FinalApplicationStatusProto_Name(FinalApplicationStatusProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    FinalApplicationStatusProto_descriptor(), value);
}
inline bool FinalApplicationStatusProto_Parse(
    const ::std::string& name, FinalApplicationStatusProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<FinalApplicationStatusProto>(
    FinalApplicationStatusProto_descriptor(), name, value);
}
enum LocalResourceVisibilityProto {
  PUBLIC = 1,
  PRIVATE = 2,
  APPLICATION = 3
};
bool LocalResourceVisibilityProto_IsValid(int value);
const LocalResourceVisibilityProto LocalResourceVisibilityProto_MIN = PUBLIC;
const LocalResourceVisibilityProto LocalResourceVisibilityProto_MAX = APPLICATION;
const int LocalResourceVisibilityProto_ARRAYSIZE = LocalResourceVisibilityProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* LocalResourceVisibilityProto_descriptor();
inline const ::std::string& LocalResourceVisibilityProto_Name(LocalResourceVisibilityProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    LocalResourceVisibilityProto_descriptor(), value);
}
inline bool LocalResourceVisibilityProto_Parse(
    const ::std::string& name, LocalResourceVisibilityProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<LocalResourceVisibilityProto>(
    LocalResourceVisibilityProto_descriptor(), name, value);
}
enum LocalResourceTypeProto {
  ARCHIVE = 1,
  FILE = 2,
  PATTERN = 3
};
bool LocalResourceTypeProto_IsValid(int value);
const LocalResourceTypeProto LocalResourceTypeProto_MIN = ARCHIVE;
const LocalResourceTypeProto LocalResourceTypeProto_MAX = PATTERN;
const int LocalResourceTypeProto_ARRAYSIZE = LocalResourceTypeProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* LocalResourceTypeProto_descriptor();
inline const ::std::string& LocalResourceTypeProto_Name(LocalResourceTypeProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    LocalResourceTypeProto_descriptor(), value);
}
inline bool LocalResourceTypeProto_Parse(
    const ::std::string& name, LocalResourceTypeProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<LocalResourceTypeProto>(
    LocalResourceTypeProto_descriptor(), name, value);
}
enum NodeStateProto {
  NS_NEW = 1,
  NS_RUNNING = 2,
  NS_UNHEALTHY = 3,
  NS_DECOMMISSIONED = 4,
  NS_LOST = 5,
  NS_REBOOTED = 6
};
bool NodeStateProto_IsValid(int value);
const NodeStateProto NodeStateProto_MIN = NS_NEW;
const NodeStateProto NodeStateProto_MAX = NS_REBOOTED;
const int NodeStateProto_ARRAYSIZE = NodeStateProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* NodeStateProto_descriptor();
inline const ::std::string& NodeStateProto_Name(NodeStateProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    NodeStateProto_descriptor(), value);
}
inline bool NodeStateProto_Parse(
    const ::std::string& name, NodeStateProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<NodeStateProto>(
    NodeStateProto_descriptor(), name, value);
}
enum AMCommandProto {
  AM_RESYNC = 1,
  AM_SHUTDOWN = 2
};
bool AMCommandProto_IsValid(int value);
const AMCommandProto AMCommandProto_MIN = AM_RESYNC;
const AMCommandProto AMCommandProto_MAX = AM_SHUTDOWN;
const int AMCommandProto_ARRAYSIZE = AMCommandProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* AMCommandProto_descriptor();
inline const ::std::string& AMCommandProto_Name(AMCommandProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    AMCommandProto_descriptor(), value);
}
inline bool AMCommandProto_Parse(
    const ::std::string& name, AMCommandProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<AMCommandProto>(
    AMCommandProto_descriptor(), name, value);
}
enum ApplicationAccessTypeProto {
  APPACCESS_VIEW_APP = 1,
  APPACCESS_MODIFY_APP = 2
};
bool ApplicationAccessTypeProto_IsValid(int value);
const ApplicationAccessTypeProto ApplicationAccessTypeProto_MIN = APPACCESS_VIEW_APP;
const ApplicationAccessTypeProto ApplicationAccessTypeProto_MAX = APPACCESS_MODIFY_APP;
const int ApplicationAccessTypeProto_ARRAYSIZE = ApplicationAccessTypeProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* ApplicationAccessTypeProto_descriptor();
inline const ::std::string& ApplicationAccessTypeProto_Name(ApplicationAccessTypeProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    ApplicationAccessTypeProto_descriptor(), value);
}
inline bool ApplicationAccessTypeProto_Parse(
    const ::std::string& name, ApplicationAccessTypeProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<ApplicationAccessTypeProto>(
    ApplicationAccessTypeProto_descriptor(), name, value);
}
enum QueueStateProto {
  Q_STOPPED = 1,
  Q_RUNNING = 2
};
bool QueueStateProto_IsValid(int value);
const QueueStateProto QueueStateProto_MIN = Q_STOPPED;
const QueueStateProto QueueStateProto_MAX = Q_RUNNING;
const int QueueStateProto_ARRAYSIZE = QueueStateProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* QueueStateProto_descriptor();
inline const ::std::string& QueueStateProto_Name(QueueStateProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    QueueStateProto_descriptor(), value);
}
inline bool QueueStateProto_Parse(
    const ::std::string& name, QueueStateProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<QueueStateProto>(
    QueueStateProto_descriptor(), name, value);
}
enum QueueACLProto {
  QACL_SUBMIT_APPLICATIONS = 1,
  QACL_ADMINISTER_QUEUE = 2
};
bool QueueACLProto_IsValid(int value);
const QueueACLProto QueueACLProto_MIN = QACL_SUBMIT_APPLICATIONS;
const QueueACLProto QueueACLProto_MAX = QACL_ADMINISTER_QUEUE;
const int QueueACLProto_ARRAYSIZE = QueueACLProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* QueueACLProto_descriptor();
inline const ::std::string& QueueACLProto_Name(QueueACLProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    QueueACLProto_descriptor(), value);
}
inline bool QueueACLProto_Parse(
    const ::std::string& name, QueueACLProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<QueueACLProto>(
    QueueACLProto_descriptor(), name, value);
}
enum ContainerExitStatusProto {
  SUCCESS = 0,
  INVALID = -1000,
  ABORTED = -100,
  DISKS_FAILED = -101
};
bool ContainerExitStatusProto_IsValid(int value);
const ContainerExitStatusProto ContainerExitStatusProto_MIN = INVALID;
const ContainerExitStatusProto ContainerExitStatusProto_MAX = SUCCESS;
const int ContainerExitStatusProto_ARRAYSIZE = ContainerExitStatusProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* ContainerExitStatusProto_descriptor();
inline const ::std::string& ContainerExitStatusProto_Name(ContainerExitStatusProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    ContainerExitStatusProto_descriptor(), value);
}
inline bool ContainerExitStatusProto_Parse(
    const ::std::string& name, ContainerExitStatusProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<ContainerExitStatusProto>(
    ContainerExitStatusProto_descriptor(), name, value);
}
// ===================================================================

class SerializedExceptionProto : public ::google::protobuf::Message {
 public:
  SerializedExceptionProto();
  virtual ~SerializedExceptionProto();

  SerializedExceptionProto(const SerializedExceptionProto& from);

  inline SerializedExceptionProto& operator=(const SerializedExceptionProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SerializedExceptionProto& default_instance();

  void Swap(SerializedExceptionProto* other);

  // implements Message ----------------------------------------------

  SerializedExceptionProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const SerializedExceptionProto& from);
  void MergeFrom(const SerializedExceptionProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string message = 1;
  inline bool has_message() const;
  inline void clear_message();
  static const int kMessageFieldNumber = 1;
  inline const ::std::string& message() const;
  inline void set_message(const ::std::string& value);
  inline void set_message(const char* value);
  inline void set_message(const char* value, size_t size);
  inline ::std::string* mutable_message();
  inline ::std::string* release_message();
  inline void set_allocated_message(::std::string* message);

  // optional string trace = 2;
  inline bool has_trace() const;
  inline void clear_trace();
  static const int kTraceFieldNumber = 2;
  inline const ::std::string& trace() const;
  inline void set_trace(const ::std::string& value);
  inline void set_trace(const char* value);
  inline void set_trace(const char* value, size_t size);
  inline ::std::string* mutable_trace();
  inline ::std::string* release_trace();
  inline void set_allocated_trace(::std::string* trace);

  // optional string class_name = 3;
  inline bool has_class_name() const;
  inline void clear_class_name();
  static const int kClassNameFieldNumber = 3;
  inline const ::std::string& class_name() const;
  inline void set_class_name(const ::std::string& value);
  inline void set_class_name(const char* value);
  inline void set_class_name(const char* value, size_t size);
  inline ::std::string* mutable_class_name();
  inline ::std::string* release_class_name();
  inline void set_allocated_class_name(::std::string* class_name);

  // optional .hadoop.yarn.SerializedExceptionProto cause = 4;
  inline bool has_cause() const;
  inline void clear_cause();
  static const int kCauseFieldNumber = 4;
  inline const ::hadoop::yarn::SerializedExceptionProto& cause() const;
  inline ::hadoop::yarn::SerializedExceptionProto* mutable_cause();
  inline ::hadoop::yarn::SerializedExceptionProto* release_cause();
  inline void set_allocated_cause(::hadoop::yarn::SerializedExceptionProto* cause);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.SerializedExceptionProto)
 private:
  inline void set_has_message();
  inline void clear_has_message();
  inline void set_has_trace();
  inline void clear_has_trace();
  inline void set_has_class_name();
  inline void clear_has_class_name();
  inline void set_has_cause();
  inline void clear_has_cause();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::std::string* message_;
  ::std::string* trace_;
  ::std::string* class_name_;
  ::hadoop::yarn::SerializedExceptionProto* cause_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(4 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static SerializedExceptionProto* default_instance_;
};
// -------------------------------------------------------------------

class ApplicationIdProto : public ::google::protobuf::Message {
 public:
  ApplicationIdProto();
  virtual ~ApplicationIdProto();

  ApplicationIdProto(const ApplicationIdProto& from);

  inline ApplicationIdProto& operator=(const ApplicationIdProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ApplicationIdProto& default_instance();

  void Swap(ApplicationIdProto* other);

  // implements Message ----------------------------------------------

  ApplicationIdProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ApplicationIdProto& from);
  void MergeFrom(const ApplicationIdProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int32 id = 1;
  inline bool has_id() const;
  inline void clear_id();
  static const int kIdFieldNumber = 1;
  inline ::google::protobuf::int32 id() const;
  inline void set_id(::google::protobuf::int32 value);

  // optional int64 cluster_timestamp = 2;
  inline bool has_cluster_timestamp() const;
  inline void clear_cluster_timestamp();
  static const int kClusterTimestampFieldNumber = 2;
  inline ::google::protobuf::int64 cluster_timestamp() const;
  inline void set_cluster_timestamp(::google::protobuf::int64 value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationIdProto)
 private:
  inline void set_has_id();
  inline void clear_has_id();
  inline void set_has_cluster_timestamp();
  inline void clear_has_cluster_timestamp();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::int64 cluster_timestamp_;
  ::google::protobuf::int32 id_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ApplicationIdProto* default_instance_;
};
// -------------------------------------------------------------------

class ApplicationAttemptIdProto : public ::google::protobuf::Message {
 public:
  ApplicationAttemptIdProto();
  virtual ~ApplicationAttemptIdProto();

  ApplicationAttemptIdProto(const ApplicationAttemptIdProto& from);

  inline ApplicationAttemptIdProto& operator=(const ApplicationAttemptIdProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ApplicationAttemptIdProto& default_instance();

  void Swap(ApplicationAttemptIdProto* other);

  // implements Message ----------------------------------------------

  ApplicationAttemptIdProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ApplicationAttemptIdProto& from);
  void MergeFrom(const ApplicationAttemptIdProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
  inline bool has_application_id() const;
  inline void clear_application_id();
  static const int kApplicationIdFieldNumber = 1;
  inline const ::hadoop::yarn::ApplicationIdProto& application_id() const;
  inline ::hadoop::yarn::ApplicationIdProto* mutable_application_id();
  inline ::hadoop::yarn::ApplicationIdProto* release_application_id();
  inline void set_allocated_application_id(::hadoop::yarn::ApplicationIdProto* application_id);

  // optional int32 attemptId = 2;
  inline bool has_attemptid() const;
  inline void clear_attemptid();
  static const int kAttemptIdFieldNumber = 2;
  inline ::google::protobuf::int32 attemptid() const;
  inline void set_attemptid(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationAttemptIdProto)
 private:
  inline void set_has_application_id();
  inline void clear_has_application_id();
  inline void set_has_attemptid();
  inline void clear_has_attemptid();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ApplicationIdProto* application_id_;
  ::google::protobuf::int32 attemptid_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ApplicationAttemptIdProto* default_instance_;
};
// -------------------------------------------------------------------

class ContainerIdProto : public ::google::protobuf::Message {
 public:
  ContainerIdProto();
  virtual ~ContainerIdProto();

  ContainerIdProto(const ContainerIdProto& from);

  inline ContainerIdProto& operator=(const ContainerIdProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ContainerIdProto& default_instance();

  void Swap(ContainerIdProto* other);

  // implements Message ----------------------------------------------

  ContainerIdProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ContainerIdProto& from);
  void MergeFrom(const ContainerIdProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ApplicationIdProto app_id = 1;
  inline bool has_app_id() const;
  inline void clear_app_id();
  static const int kAppIdFieldNumber = 1;
  inline const ::hadoop::yarn::ApplicationIdProto& app_id() const;
  inline ::hadoop::yarn::ApplicationIdProto* mutable_app_id();
  inline ::hadoop::yarn::ApplicationIdProto* release_app_id();
  inline void set_allocated_app_id(::hadoop::yarn::ApplicationIdProto* app_id);

  // optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;
  inline bool has_app_attempt_id() const;
  inline void clear_app_attempt_id();
  static const int kAppAttemptIdFieldNumber = 2;
  inline const ::hadoop::yarn::ApplicationAttemptIdProto& app_attempt_id() const;
  inline ::hadoop::yarn::ApplicationAttemptIdProto* mutable_app_attempt_id();
  inline ::hadoop::yarn::ApplicationAttemptIdProto* release_app_attempt_id();
  inline void set_allocated_app_attempt_id(::hadoop::yarn::ApplicationAttemptIdProto* app_attempt_id);

  // optional int32 id = 3;
  inline bool has_id() const;
  inline void clear_id();
  static const int kIdFieldNumber = 3;
  inline ::google::protobuf::int32 id() const;
  inline void set_id(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerIdProto)
 private:
  inline void set_has_app_id();
  inline void clear_has_app_id();
  inline void set_has_app_attempt_id();
  inline void clear_has_app_attempt_id();
  inline void set_has_id();
  inline void clear_has_id();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ApplicationIdProto* app_id_;
  ::hadoop::yarn::ApplicationAttemptIdProto* app_attempt_id_;
  ::google::protobuf::int32 id_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(3 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ContainerIdProto* default_instance_;
};
// -------------------------------------------------------------------

class ResourceProto : public ::google::protobuf::Message {
 public:
  ResourceProto();
  virtual ~ResourceProto();

  ResourceProto(const ResourceProto& from);

  inline ResourceProto& operator=(const ResourceProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ResourceProto& default_instance();

  void Swap(ResourceProto* other);

  // implements Message ----------------------------------------------

  ResourceProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ResourceProto& from);
  void MergeFrom(const ResourceProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int32 memory = 1;
  inline bool has_memory() const;
  inline void clear_memory();
  static const int kMemoryFieldNumber = 1;
  inline ::google::protobuf::int32 memory() const;
  inline void set_memory(::google::protobuf::int32 value);

  // optional int32 virtual_cores = 2;
  inline bool has_virtual_cores() const;
  inline void clear_virtual_cores();
  static const int kVirtualCoresFieldNumber = 2;
  inline ::google::protobuf::int32 virtual_cores() const;
  inline void set_virtual_cores(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceProto)
 private:
  inline void set_has_memory();
  inline void clear_has_memory();
  inline void set_has_virtual_cores();
  inline void clear_has_virtual_cores();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::int32 memory_;
  ::google::protobuf::int32 virtual_cores_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ResourceProto* default_instance_;
};
// -------------------------------------------------------------------

class ResourceOptionProto : public ::google::protobuf::Message {
 public:
  ResourceOptionProto();
  virtual ~ResourceOptionProto();

  ResourceOptionProto(const ResourceOptionProto& from);

  inline ResourceOptionProto& operator=(const ResourceOptionProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ResourceOptionProto& default_instance();

  void Swap(ResourceOptionProto* other);

  // implements Message ----------------------------------------------

  ResourceOptionProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ResourceOptionProto& from);
  void MergeFrom(const ResourceOptionProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ResourceProto resource = 1;
  inline bool has_resource() const;
  inline void clear_resource();
  static const int kResourceFieldNumber = 1;
  inline const ::hadoop::yarn::ResourceProto& resource() const;
  inline ::hadoop::yarn::ResourceProto* mutable_resource();
  inline ::hadoop::yarn::ResourceProto* release_resource();
  inline void set_allocated_resource(::hadoop::yarn::ResourceProto* resource);

  // optional int32 over_commit_timeout = 2;
  inline bool has_over_commit_timeout() const;
  inline void clear_over_commit_timeout();
  static const int kOverCommitTimeoutFieldNumber = 2;
  inline ::google::protobuf::int32 over_commit_timeout() const;
  inline void set_over_commit_timeout(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceOptionProto)
 private:
  inline void set_has_resource();
  inline void clear_has_resource();
  inline void set_has_over_commit_timeout();
  inline void clear_has_over_commit_timeout();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ResourceProto* resource_;
  ::google::protobuf::int32 over_commit_timeout_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ResourceOptionProto* default_instance_;
};
// -------------------------------------------------------------------

class NodeResourceMapProto : public ::google::protobuf::Message {
 public:
  NodeResourceMapProto();
  virtual ~NodeResourceMapProto();

  NodeResourceMapProto(const NodeResourceMapProto& from);

  inline NodeResourceMapProto& operator=(const NodeResourceMapProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const NodeResourceMapProto& default_instance();

  void Swap(NodeResourceMapProto* other);

  // implements Message ----------------------------------------------

  NodeResourceMapProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const NodeResourceMapProto& from);
  void MergeFrom(const NodeResourceMapProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.NodeIdProto node_id = 1;
  inline bool has_node_id() const;
  inline void clear_node_id();
  static const int kNodeIdFieldNumber = 1;
  inline const ::hadoop::yarn::NodeIdProto& node_id() const;
  inline ::hadoop::yarn::NodeIdProto* mutable_node_id();
  inline ::hadoop::yarn::NodeIdProto* release_node_id();
  inline void set_allocated_node_id(::hadoop::yarn::NodeIdProto* node_id);

  // optional .hadoop.yarn.ResourceOptionProto resource_option = 2;
  inline bool has_resource_option() const;
  inline void clear_resource_option();
  static const int kResourceOptionFieldNumber = 2;
  inline const ::hadoop::yarn::ResourceOptionProto& resource_option() const;
  inline ::hadoop::yarn::ResourceOptionProto* mutable_resource_option();
  inline ::hadoop::yarn::ResourceOptionProto* release_resource_option();
  inline void set_allocated_resource_option(::hadoop::yarn::ResourceOptionProto* resource_option);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeResourceMapProto)
 private:
  inline void set_has_node_id();
  inline void clear_has_node_id();
  inline void set_has_resource_option();
  inline void clear_has_resource_option();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::NodeIdProto* node_id_;
  ::hadoop::yarn::ResourceOptionProto* resource_option_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static NodeResourceMapProto* default_instance_;
};
// -------------------------------------------------------------------

class PriorityProto : public ::google::protobuf::Message {
 public:
  PriorityProto();
  virtual ~PriorityProto();

  PriorityProto(const PriorityProto& from);

  inline PriorityProto& operator=(const PriorityProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const PriorityProto& default_instance();

  void Swap(PriorityProto* other);

  // implements Message ----------------------------------------------

  PriorityProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const PriorityProto& from);
  void MergeFrom(const PriorityProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int32 priority = 1;
  inline bool has_priority() const;
  inline void clear_priority();
  static const int kPriorityFieldNumber = 1;
  inline ::google::protobuf::int32 priority() const;
  inline void set_priority(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.PriorityProto)
 private:
  inline void set_has_priority();
  inline void clear_has_priority();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::int32 priority_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static PriorityProto* default_instance_;
};
// -------------------------------------------------------------------

class ContainerProto : public ::google::protobuf::Message {
 public:
  ContainerProto();
  virtual ~ContainerProto();

  ContainerProto(const ContainerProto& from);

  inline ContainerProto& operator=(const ContainerProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ContainerProto& default_instance();

  void Swap(ContainerProto* other);

  // implements Message ----------------------------------------------

  ContainerProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ContainerProto& from);
  void MergeFrom(const ContainerProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ContainerIdProto id = 1;
  inline bool has_id() const;
  inline void clear_id();
  static const int kIdFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerIdProto& id() const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_id();
  inline ::hadoop::yarn::ContainerIdProto* release_id();
  inline void set_allocated_id(::hadoop::yarn::ContainerIdProto* id);

  // optional .hadoop.yarn.NodeIdProto nodeId = 2;
  inline bool has_nodeid() const;
  inline void clear_nodeid();
  static const int kNodeIdFieldNumber = 2;
  inline const ::hadoop::yarn::NodeIdProto& nodeid() const;
  inline ::hadoop::yarn::NodeIdProto* mutable_nodeid();
  inline ::hadoop::yarn::NodeIdProto* release_nodeid();
  inline void set_allocated_nodeid(::hadoop::yarn::NodeIdProto* nodeid);

  // optional string node_http_address = 3;
  inline bool has_node_http_address() const;
  inline void clear_node_http_address();
  static const int kNodeHttpAddressFieldNumber = 3;
  inline const ::std::string& node_http_address() const;
  inline void set_node_http_address(const ::std::string& value);
  inline void set_node_http_address(const char* value);
  inline void set_node_http_address(const char* value, size_t size);
  inline ::std::string* mutable_node_http_address();
  inline ::std::string* release_node_http_address();
  inline void set_allocated_node_http_address(::std::string* node_http_address);

  // optional .hadoop.yarn.ResourceProto resource = 4;
  inline bool has_resource() const;
  inline void clear_resource();
  static const int kResourceFieldNumber = 4;
  inline const ::hadoop::yarn::ResourceProto& resource() const;
  inline ::hadoop::yarn::ResourceProto* mutable_resource();
  inline ::hadoop::yarn::ResourceProto* release_resource();
  inline void set_allocated_resource(::hadoop::yarn::ResourceProto* resource);

  // optional .hadoop.yarn.PriorityProto priority = 5;
  inline bool has_priority() const;
  inline void clear_priority();
  static const int kPriorityFieldNumber = 5;
  inline const ::hadoop::yarn::PriorityProto& priority() const;
  inline ::hadoop::yarn::PriorityProto* mutable_priority();
  inline ::hadoop::yarn::PriorityProto* release_priority();
  inline void set_allocated_priority(::hadoop::yarn::PriorityProto* priority);

  // optional .hadoop.common.TokenProto container_token = 6;
  inline bool has_container_token() const;
  inline void clear_container_token();
  static const int kContainerTokenFieldNumber = 6;
  inline const ::hadoop::common::TokenProto& container_token() const;
  inline ::hadoop::common::TokenProto* mutable_container_token();
  inline ::hadoop::common::TokenProto* release_container_token();
  inline void set_allocated_container_token(::hadoop::common::TokenProto* container_token);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerProto)
 private:
  inline void set_has_id();
  inline void clear_has_id();
  inline void set_has_nodeid();
  inline void clear_has_nodeid();
  inline void set_has_node_http_address();
  inline void clear_has_node_http_address();
  inline void set_has_resource();
  inline void clear_has_resource();
  inline void set_has_priority();
  inline void clear_has_priority();
  inline void set_has_container_token();
  inline void clear_has_container_token();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ContainerIdProto* id_;
  ::hadoop::yarn::NodeIdProto* nodeid_;
  ::std::string* node_http_address_;
  ::hadoop::yarn::ResourceProto* resource_;
  ::hadoop::yarn::PriorityProto* priority_;
  ::hadoop::common::TokenProto* container_token_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(6 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ContainerProto* default_instance_;
};
// -------------------------------------------------------------------

class URLProto : public ::google::protobuf::Message {
 public:
  URLProto();
  virtual ~URLProto();

  URLProto(const URLProto& from);

  inline URLProto& operator=(const URLProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const URLProto& default_instance();

  void Swap(URLProto* other);

  // implements Message ----------------------------------------------

  URLProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const URLProto& from);
  void MergeFrom(const URLProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string scheme = 1;
  inline bool has_scheme() const;
  inline void clear_scheme();
  static const int kSchemeFieldNumber = 1;
  inline const ::std::string& scheme() const;
  inline void set_scheme(const ::std::string& value);
  inline void set_scheme(const char* value);
  inline void set_scheme(const char* value, size_t size);
  inline ::std::string* mutable_scheme();
  inline ::std::string* release_scheme();
  inline void set_allocated_scheme(::std::string* scheme);

  // optional string host = 2;
  inline bool has_host() const;
  inline void clear_host();
  static const int kHostFieldNumber = 2;
  inline const ::std::string& host() const;
  inline void set_host(const ::std::string& value);
  inline void set_host(const char* value);
  inline void set_host(const char* value, size_t size);
  inline ::std::string* mutable_host();
  inline ::std::string* release_host();
  inline void set_allocated_host(::std::string* host);

  // optional int32 port = 3;
  inline bool has_port() const;
  inline void clear_port();
  static const int kPortFieldNumber = 3;
  inline ::google::protobuf::int32 port() const;
  inline void set_port(::google::protobuf::int32 value);

  // optional string file = 4;
  inline bool has_file() const;
  inline void clear_file();
  static const int kFileFieldNumber = 4;
  inline const ::std::string& file() const;
  inline void set_file(const ::std::string& value);
  inline void set_file(const char* value);
  inline void set_file(const char* value, size_t size);
  inline ::std::string* mutable_file();
  inline ::std::string* release_file();
  inline void set_allocated_file(::std::string* file);

  // optional string userInfo = 5;
  inline bool has_userinfo() const;
  inline void clear_userinfo();
  static const int kUserInfoFieldNumber = 5;
  inline const ::std::string& userinfo() const;
  inline void set_userinfo(const ::std::string& value);
  inline void set_userinfo(const char* value);
  inline void set_userinfo(const char* value, size_t size);
  inline ::std::string* mutable_userinfo();
  inline ::std::string* release_userinfo();
  inline void set_allocated_userinfo(::std::string* userinfo);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.URLProto)
 private:
  inline void set_has_scheme();
  inline void clear_has_scheme();
  inline void set_has_host();
  inline void clear_has_host();
  inline void set_has_port();
  inline void clear_has_port();
  inline void set_has_file();
  inline void clear_has_file();
  inline void set_has_userinfo();
  inline void clear_has_userinfo();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::std::string* scheme_;
  ::std::string* host_;
  ::std::string* file_;
  ::std::string* userinfo_;
  ::google::protobuf::int32 port_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(5 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static URLProto* default_instance_;
};
// -------------------------------------------------------------------

class LocalResourceProto : public ::google::protobuf::Message {
 public:
  LocalResourceProto();
  virtual ~LocalResourceProto();

  LocalResourceProto(const LocalResourceProto& from);

  inline LocalResourceProto& operator=(const LocalResourceProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const LocalResourceProto& default_instance();

  void Swap(LocalResourceProto* other);

  // implements Message ----------------------------------------------

  LocalResourceProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const LocalResourceProto& from);
  void MergeFrom(const LocalResourceProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.URLProto resource = 1;
  inline bool has_resource() const;
  inline void clear_resource();
  static const int kResourceFieldNumber = 1;
  inline const ::hadoop::yarn::URLProto& resource() const;
  inline ::hadoop::yarn::URLProto* mutable_resource();
  inline ::hadoop::yarn::URLProto* release_resource();
  inline void set_allocated_resource(::hadoop::yarn::URLProto* resource);

  // optional int64 size = 2;
  inline bool has_size() const;
  inline void clear_size();
  static const int kSizeFieldNumber = 2;
  inline ::google::protobuf::int64 size() const;
  inline void set_size(::google::protobuf::int64 value);

  // optional int64 timestamp = 3;
  inline bool has_timestamp() const;
  inline void clear_timestamp();
  static const int kTimestampFieldNumber = 3;
  inline ::google::protobuf::int64 timestamp() const;
  inline void set_timestamp(::google::protobuf::int64 value);

  // optional .hadoop.yarn.LocalResourceTypeProto type = 4;
  inline bool has_type() const;
  inline void clear_type();
  static const int kTypeFieldNumber = 4;
  inline ::hadoop::yarn::LocalResourceTypeProto type() const;
  inline void set_type(::hadoop::yarn::LocalResourceTypeProto value);

  // optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;
  inline bool has_visibility() const;
  inline void clear_visibility();
  static const int kVisibilityFieldNumber = 5;
  inline ::hadoop::yarn::LocalResourceVisibilityProto visibility() const;
  inline void set_visibility(::hadoop::yarn::LocalResourceVisibilityProto value);

  // optional string pattern = 6;
  inline bool has_pattern() const;
  inline void clear_pattern();
  static const int kPatternFieldNumber = 6;
  inline const ::std::string& pattern() const;
  inline void set_pattern(const ::std::string& value);
  inline void set_pattern(const char* value);
  inline void set_pattern(const char* value, size_t size);
  inline ::std::string* mutable_pattern();
  inline ::std::string* release_pattern();
  inline void set_allocated_pattern(::std::string* pattern);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.LocalResourceProto)
 private:
  inline void set_has_resource();
  inline void clear_has_resource();
  inline void set_has_size();
  inline void clear_has_size();
  inline void set_has_timestamp();
  inline void clear_has_timestamp();
  inline void set_has_type();
  inline void clear_has_type();
  inline void set_has_visibility();
  inline void clear_has_visibility();
  inline void set_has_pattern();
  inline void clear_has_pattern();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::URLProto* resource_;
  ::google::protobuf::int64 size_;
  ::google::protobuf::int64 timestamp_;
  int type_;
  int visibility_;
  ::std::string* pattern_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(6 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static LocalResourceProto* default_instance_;
};
// -------------------------------------------------------------------

class ApplicationResourceUsageReportProto : public ::google::protobuf::Message {
 public:
  ApplicationResourceUsageReportProto();
  virtual ~ApplicationResourceUsageReportProto();

  ApplicationResourceUsageReportProto(const ApplicationResourceUsageReportProto& from);

  inline ApplicationResourceUsageReportProto& operator=(const ApplicationResourceUsageReportProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ApplicationResourceUsageReportProto& default_instance();

  void Swap(ApplicationResourceUsageReportProto* other);

  // implements Message ----------------------------------------------

  ApplicationResourceUsageReportProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ApplicationResourceUsageReportProto& from);
  void MergeFrom(const ApplicationResourceUsageReportProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int32 num_used_containers = 1;
  inline bool has_num_used_containers() const;
  inline void clear_num_used_containers();
  static const int kNumUsedContainersFieldNumber = 1;
  inline ::google::protobuf::int32 num_used_containers() const;
  inline void set_num_used_containers(::google::protobuf::int32 value);

  // optional int32 num_reserved_containers = 2;
  inline bool has_num_reserved_containers() const;
  inline void clear_num_reserved_containers();
  static const int kNumReservedContainersFieldNumber = 2;
  inline ::google::protobuf::int32 num_reserved_containers() const;
  inline void set_num_reserved_containers(::google::protobuf::int32 value);

  // optional .hadoop.yarn.ResourceProto used_resources = 3;
  inline bool has_used_resources() const;
  inline void clear_used_resources();
  static const int kUsedResourcesFieldNumber = 3;
  inline const ::hadoop::yarn::ResourceProto& used_resources() const;
  inline ::hadoop::yarn::ResourceProto* mutable_used_resources();
  inline ::hadoop::yarn::ResourceProto* release_used_resources();
  inline void set_allocated_used_resources(::hadoop::yarn::ResourceProto* used_resources);

  // optional .hadoop.yarn.ResourceProto reserved_resources = 4;
  inline bool has_reserved_resources() const;
  inline void clear_reserved_resources();
  static const int kReservedResourcesFieldNumber = 4;
  inline const ::hadoop::yarn::ResourceProto& reserved_resources() const;
  inline ::hadoop::yarn::ResourceProto* mutable_reserved_resources();
  inline ::hadoop::yarn::ResourceProto* release_reserved_resources();
  inline void set_allocated_reserved_resources(::hadoop::yarn::ResourceProto* reserved_resources);

  // optional .hadoop.yarn.ResourceProto needed_resources = 5;
  inline bool has_needed_resources() const;
  inline void clear_needed_resources();
  static const int kNeededResourcesFieldNumber = 5;
  inline const ::hadoop::yarn::ResourceProto& needed_resources() const;
  inline ::hadoop::yarn::ResourceProto* mutable_needed_resources();
  inline ::hadoop::yarn::ResourceProto* release_needed_resources();
  inline void set_allocated_needed_resources(::hadoop::yarn::ResourceProto* needed_resources);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationResourceUsageReportProto)
 private:
  inline void set_has_num_used_containers();
  inline void clear_has_num_used_containers();
  inline void set_has_num_reserved_containers();
  inline void clear_has_num_reserved_containers();
  inline void set_has_used_resources();
  inline void clear_has_used_resources();
  inline void set_has_reserved_resources();
  inline void clear_has_reserved_resources();
  inline void set_has_needed_resources();
  inline void clear_has_needed_resources();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::int32 num_used_containers_;
  ::google::protobuf::int32 num_reserved_containers_;
  ::hadoop::yarn::ResourceProto* used_resources_;
  ::hadoop::yarn::ResourceProto* reserved_resources_;
  ::hadoop::yarn::ResourceProto* needed_resources_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(5 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ApplicationResourceUsageReportProto* default_instance_;
};
// -------------------------------------------------------------------

class ApplicationReportProto : public ::google::protobuf::Message {
 public:
  ApplicationReportProto();
  virtual ~ApplicationReportProto();

  ApplicationReportProto(const ApplicationReportProto& from);

  inline ApplicationReportProto& operator=(const ApplicationReportProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ApplicationReportProto& default_instance();

  void Swap(ApplicationReportProto* other);

  // implements Message ----------------------------------------------

  ApplicationReportProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ApplicationReportProto& from);
  void MergeFrom(const ApplicationReportProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ApplicationIdProto applicationId = 1;
  inline bool has_applicationid() const;
  inline void clear_applicationid();
  static const int kApplicationIdFieldNumber = 1;
  inline const ::hadoop::yarn::ApplicationIdProto& applicationid() const;
  inline ::hadoop::yarn::ApplicationIdProto* mutable_applicationid();
  inline ::hadoop::yarn::ApplicationIdProto* release_applicationid();
  inline void set_allocated_applicationid(::hadoop::yarn::ApplicationIdProto* applicationid);

  // optional string user = 2;
  inline bool has_user() const;
  inline void clear_user();
  static const int kUserFieldNumber = 2;
  inline const ::std::string& user() const;
  inline void set_user(const ::std::string& value);
  inline void set_user(const char* value);
  inline void set_user(const char* value, size_t size);
  inline ::std::string* mutable_user();
  inline ::std::string* release_user();
  inline void set_allocated_user(::std::string* user);

  // optional string queue = 3;
  inline bool has_queue() const;
  inline void clear_queue();
  static const int kQueueFieldNumber = 3;
  inline const ::std::string& queue() const;
  inline void set_queue(const ::std::string& value);
  inline void set_queue(const char* value);
  inline void set_queue(const char* value, size_t size);
  inline ::std::string* mutable_queue();
  inline ::std::string* release_queue();
  inline void set_allocated_queue(::std::string* queue);

  // optional string name = 4;
  inline bool has_name() const;
  inline void clear_name();
  static const int kNameFieldNumber = 4;
  inline const ::std::string& name() const;
  inline void set_name(const ::std::string& value);
  inline void set_name(const char* value);
  inline void set_name(const char* value, size_t size);
  inline ::std::string* mutable_name();
  inline ::std::string* release_name();
  inline void set_allocated_name(::std::string* name);

  // optional string host = 5;
  inline bool has_host() const;
  inline void clear_host();
  static const int kHostFieldNumber = 5;
  inline const ::std::string& host() const;
  inline void set_host(const ::std::string& value);
  inline void set_host(const char* value);
  inline void set_host(const char* value, size_t size);
  inline ::std::string* mutable_host();
  inline ::std::string* release_host();
  inline void set_allocated_host(::std::string* host);

  // optional int32 rpc_port = 6;
  inline bool has_rpc_port() const;
  inline void clear_rpc_port();
  static const int kRpcPortFieldNumber = 6;
  inline ::google::protobuf::int32 rpc_port() const;
  inline void set_rpc_port(::google::protobuf::int32 value);

  // optional .hadoop.common.TokenProto client_to_am_token = 7;
  inline bool has_client_to_am_token() const;
  inline void clear_client_to_am_token();
  static const int kClientToAmTokenFieldNumber = 7;
  inline const ::hadoop::common::TokenProto& client_to_am_token() const;
  inline ::hadoop::common::TokenProto* mutable_client_to_am_token();
  inline ::hadoop::common::TokenProto* release_client_to_am_token();
  inline void set_allocated_client_to_am_token(::hadoop::common::TokenProto* client_to_am_token);

  // optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;
  inline bool has_yarn_application_state() const;
  inline void clear_yarn_application_state();
  static const int kYarnApplicationStateFieldNumber = 8;
  inline ::hadoop::yarn::YarnApplicationStateProto yarn_application_state() const;
  inline void set_yarn_application_state(::hadoop::yarn::YarnApplicationStateProto value);

  // optional string trackingUrl = 9;
  inline bool has_trackingurl() const;
  inline void clear_trackingurl();
  static const int kTrackingUrlFieldNumber = 9;
  inline const ::std::string& trackingurl() const;
  inline void set_trackingurl(const ::std::string& value);
  inline void set_trackingurl(const char* value);
  inline void set_trackingurl(const char* value, size_t size);
  inline ::std::string* mutable_trackingurl();
  inline ::std::string* release_trackingurl();
  inline void set_allocated_trackingurl(::std::string* trackingurl);

  // optional string diagnostics = 10 [default = "N/A"];
  inline bool has_diagnostics() const;
  inline void clear_diagnostics();
  static const int kDiagnosticsFieldNumber = 10;
  inline const ::std::string& diagnostics() const;
  inline void set_diagnostics(const ::std::string& value);
  inline void set_diagnostics(const char* value);
  inline void set_diagnostics(const char* value, size_t size);
  inline ::std::string* mutable_diagnostics();
  inline ::std::string* release_diagnostics();
  inline void set_allocated_diagnostics(::std::string* diagnostics);

  // optional int64 startTime = 11;
  inline bool has_starttime() const;
  inline void clear_starttime();
  static const int kStartTimeFieldNumber = 11;
  inline ::google::protobuf::int64 starttime() const;
  inline void set_starttime(::google::protobuf::int64 value);

  // optional int64 finishTime = 12;
  inline bool has_finishtime() const;
  inline void clear_finishtime();
  static const int kFinishTimeFieldNumber = 12;
  inline ::google::protobuf::int64 finishtime() const;
  inline void set_finishtime(::google::protobuf::int64 value);

  // optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;
  inline bool has_final_application_status() const;
  inline void clear_final_application_status();
  static const int kFinalApplicationStatusFieldNumber = 13;
  inline ::hadoop::yarn::FinalApplicationStatusProto final_application_status() const;
  inline void set_final_application_status(::hadoop::yarn::FinalApplicationStatusProto value);

  // optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;
  inline bool has_app_resource_usage() const;
  inline void clear_app_resource_usage();
  static const int kAppResourceUsageFieldNumber = 14;
  inline const ::hadoop::yarn::ApplicationResourceUsageReportProto& app_resource_usage() const;
  inline ::hadoop::yarn::ApplicationResourceUsageReportProto* mutable_app_resource_usage();
  inline ::hadoop::yarn::ApplicationResourceUsageReportProto* release_app_resource_usage();
  inline void set_allocated_app_resource_usage(::hadoop::yarn::ApplicationResourceUsageReportProto* app_resource_usage);

  // optional string originalTrackingUrl = 15;
  inline bool has_originaltrackingurl() const;
  inline void clear_originaltrackingurl();
  static const int kOriginalTrackingUrlFieldNumber = 15;
  inline const ::std::string& originaltrackingurl() const;
  inline void set_originaltrackingurl(const ::std::string& value);
  inline void set_originaltrackingurl(const char* value);
  inline void set_originaltrackingurl(const char* value, size_t size);
  inline ::std::string* mutable_originaltrackingurl();
  inline ::std::string* release_originaltrackingurl();
  inline void set_allocated_originaltrackingurl(::std::string* originaltrackingurl);

  // optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;
  inline bool has_currentapplicationattemptid() const;
  inline void clear_currentapplicationattemptid();
  static const int kCurrentApplicationAttemptIdFieldNumber = 16;
  inline const ::hadoop::yarn::ApplicationAttemptIdProto& currentapplicationattemptid() const;
  inline ::hadoop::yarn::ApplicationAttemptIdProto* mutable_currentapplicationattemptid();
  inline ::hadoop::yarn::ApplicationAttemptIdProto* release_currentapplicationattemptid();
  inline void set_allocated_currentapplicationattemptid(::hadoop::yarn::ApplicationAttemptIdProto* currentapplicationattemptid);

  // optional float progress = 17;
  inline bool has_progress() const;
  inline void clear_progress();
  static const int kProgressFieldNumber = 17;
  inline float progress() const;
  inline void set_progress(float value);

  // optional string applicationType = 18;
  inline bool has_applicationtype() const;
  inline void clear_applicationtype();
  static const int kApplicationTypeFieldNumber = 18;
  inline const ::std::string& applicationtype() const;
  inline void set_applicationtype(const ::std::string& value);
  inline void set_applicationtype(const char* value);
  inline void set_applicationtype(const char* value, size_t size);
  inline ::std::string* mutable_applicationtype();
  inline ::std::string* release_applicationtype();
  inline void set_allocated_applicationtype(::std::string* applicationtype);

  // optional .hadoop.common.TokenProto am_rm_token = 19;
  inline bool has_am_rm_token() const;
  inline void clear_am_rm_token();
  static const int kAmRmTokenFieldNumber = 19;
  inline const ::hadoop::common::TokenProto& am_rm_token() const;
  inline ::hadoop::common::TokenProto* mutable_am_rm_token();
  inline ::hadoop::common::TokenProto* release_am_rm_token();
  inline void set_allocated_am_rm_token(::hadoop::common::TokenProto* am_rm_token);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationReportProto)
 private:
  inline void set_has_applicationid();
  inline void clear_has_applicationid();
  inline void set_has_user();
  inline void clear_has_user();
  inline void set_has_queue();
  inline void clear_has_queue();
  inline void set_has_name();
  inline void clear_has_name();
  inline void set_has_host();
  inline void clear_has_host();
  inline void set_has_rpc_port();
  inline void clear_has_rpc_port();
  inline void set_has_client_to_am_token();
  inline void clear_has_client_to_am_token();
  inline void set_has_yarn_application_state();
  inline void clear_has_yarn_application_state();
  inline void set_has_trackingurl();
  inline void clear_has_trackingurl();
  inline void set_has_diagnostics();
  inline void clear_has_diagnostics();
  inline void set_has_starttime();
  inline void clear_has_starttime();
  inline void set_has_finishtime();
  inline void clear_has_finishtime();
  inline void set_has_final_application_status();
  inline void clear_has_final_application_status();
  inline void set_has_app_resource_usage();
  inline void clear_has_app_resource_usage();
  inline void set_has_originaltrackingurl();
  inline void clear_has_originaltrackingurl();
  inline void set_has_currentapplicationattemptid();
  inline void clear_has_currentapplicationattemptid();
  inline void set_has_progress();
  inline void clear_has_progress();
  inline void set_has_applicationtype();
  inline void clear_has_applicationtype();
  inline void set_has_am_rm_token();
  inline void clear_has_am_rm_token();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ApplicationIdProto* applicationid_;
  ::std::string* user_;
  ::std::string* queue_;
  ::std::string* name_;
  ::std::string* host_;
  ::hadoop::common::TokenProto* client_to_am_token_;
  ::google::protobuf::int32 rpc_port_;
  int yarn_application_state_;
  ::std::string* trackingurl_;
  ::std::string* diagnostics_;
  static ::std::string* _default_diagnostics_;
  ::google::protobuf::int64 starttime_;
  ::google::protobuf::int64 finishtime_;
  ::hadoop::yarn::ApplicationResourceUsageReportProto* app_resource_usage_;
  int final_application_status_;
  float progress_;
  ::std::string* originaltrackingurl_;
  ::hadoop::yarn::ApplicationAttemptIdProto* currentapplicationattemptid_;
  ::std::string* applicationtype_;
  ::hadoop::common::TokenProto* am_rm_token_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(19 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ApplicationReportProto* default_instance_;
};
// -------------------------------------------------------------------

class NodeIdProto : public ::google::protobuf::Message {
 public:
  NodeIdProto();
  virtual ~NodeIdProto();

  NodeIdProto(const NodeIdProto& from);

  inline NodeIdProto& operator=(const NodeIdProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const NodeIdProto& default_instance();

  void Swap(NodeIdProto* other);

  // implements Message ----------------------------------------------

  NodeIdProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const NodeIdProto& from);
  void MergeFrom(const NodeIdProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string host = 1;
  inline bool has_host() const;
  inline void clear_host();
  static const int kHostFieldNumber = 1;
  inline const ::std::string& host() const;
  inline void set_host(const ::std::string& value);
  inline void set_host(const char* value);
  inline void set_host(const char* value, size_t size);
  inline ::std::string* mutable_host();
  inline ::std::string* release_host();
  inline void set_allocated_host(::std::string* host);

  // optional int32 port = 2;
  inline bool has_port() const;
  inline void clear_port();
  static const int kPortFieldNumber = 2;
  inline ::google::protobuf::int32 port() const;
  inline void set_port(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeIdProto)
 private:
  inline void set_has_host();
  inline void clear_has_host();
  inline void set_has_port();
  inline void clear_has_port();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::std::string* host_;
  ::google::protobuf::int32 port_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static NodeIdProto* default_instance_;
};
// -------------------------------------------------------------------

class NodeReportProto : public ::google::protobuf::Message {
 public:
  NodeReportProto();
  virtual ~NodeReportProto();

  NodeReportProto(const NodeReportProto& from);

  inline NodeReportProto& operator=(const NodeReportProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const NodeReportProto& default_instance();

  void Swap(NodeReportProto* other);

  // implements Message ----------------------------------------------

  NodeReportProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const NodeReportProto& from);
  void MergeFrom(const NodeReportProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.NodeIdProto nodeId = 1;
  inline bool has_nodeid() const;
  inline void clear_nodeid();
  static const int kNodeIdFieldNumber = 1;
  inline const ::hadoop::yarn::NodeIdProto& nodeid() const;
  inline ::hadoop::yarn::NodeIdProto* mutable_nodeid();
  inline ::hadoop::yarn::NodeIdProto* release_nodeid();
  inline void set_allocated_nodeid(::hadoop::yarn::NodeIdProto* nodeid);

  // optional string httpAddress = 2;
  inline bool has_httpaddress() const;
  inline void clear_httpaddress();
  static const int kHttpAddressFieldNumber = 2;
  inline const ::std::string& httpaddress() const;
  inline void set_httpaddress(const ::std::string& value);
  inline void set_httpaddress(const char* value);
  inline void set_httpaddress(const char* value, size_t size);
  inline ::std::string* mutable_httpaddress();
  inline ::std::string* release_httpaddress();
  inline void set_allocated_httpaddress(::std::string* httpaddress);

  // optional string rackName = 3;
  inline bool has_rackname() const;
  inline void clear_rackname();
  static const int kRackNameFieldNumber = 3;
  inline const ::std::string& rackname() const;
  inline void set_rackname(const ::std::string& value);
  inline void set_rackname(const char* value);
  inline void set_rackname(const char* value, size_t size);
  inline ::std::string* mutable_rackname();
  inline ::std::string* release_rackname();
  inline void set_allocated_rackname(::std::string* rackname);

  // optional .hadoop.yarn.ResourceProto used = 4;
  inline bool has_used() const;
  inline void clear_used();
  static const int kUsedFieldNumber = 4;
  inline const ::hadoop::yarn::ResourceProto& used() const;
  inline ::hadoop::yarn::ResourceProto* mutable_used();
  inline ::hadoop::yarn::ResourceProto* release_used();
  inline void set_allocated_used(::hadoop::yarn::ResourceProto* used);

  // optional .hadoop.yarn.ResourceProto capability = 5;
  inline bool has_capability() const;
  inline void clear_capability();
  static const int kCapabilityFieldNumber = 5;
  inline const ::hadoop::yarn::ResourceProto& capability() const;
  inline ::hadoop::yarn::ResourceProto* mutable_capability();
  inline ::hadoop::yarn::ResourceProto* release_capability();
  inline void set_allocated_capability(::hadoop::yarn::ResourceProto* capability);

  // optional int32 numContainers = 6;
  inline bool has_numcontainers() const;
  inline void clear_numcontainers();
  static const int kNumContainersFieldNumber = 6;
  inline ::google::protobuf::int32 numcontainers() const;
  inline void set_numcontainers(::google::protobuf::int32 value);

  // optional .hadoop.yarn.NodeStateProto node_state = 7;
  inline bool has_node_state() const;
  inline void clear_node_state();
  static const int kNodeStateFieldNumber = 7;
  inline ::hadoop::yarn::NodeStateProto node_state() const;
  inline void set_node_state(::hadoop::yarn::NodeStateProto value);

  // optional string health_report = 8;
  inline bool has_health_report() const;
  inline void clear_health_report();
  static const int kHealthReportFieldNumber = 8;
  inline const ::std::string& health_report() const;
  inline void set_health_report(const ::std::string& value);
  inline void set_health_report(const char* value);
  inline void set_health_report(const char* value, size_t size);
  inline ::std::string* mutable_health_report();
  inline ::std::string* release_health_report();
  inline void set_allocated_health_report(::std::string* health_report);

  // optional int64 last_health_report_time = 9;
  inline bool has_last_health_report_time() const;
  inline void clear_last_health_report_time();
  static const int kLastHealthReportTimeFieldNumber = 9;
  inline ::google::protobuf::int64 last_health_report_time() const;
  inline void set_last_health_report_time(::google::protobuf::int64 value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeReportProto)
 private:
  inline void set_has_nodeid();
  inline void clear_has_nodeid();
  inline void set_has_httpaddress();
  inline void clear_has_httpaddress();
  inline void set_has_rackname();
  inline void clear_has_rackname();
  inline void set_has_used();
  inline void clear_has_used();
  inline void set_has_capability();
  inline void clear_has_capability();
  inline void set_has_numcontainers();
  inline void clear_has_numcontainers();
  inline void set_has_node_state();
  inline void clear_has_node_state();
  inline void set_has_health_report();
  inline void clear_has_health_report();
  inline void set_has_last_health_report_time();
  inline void clear_has_last_health_report_time();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::NodeIdProto* nodeid_;
  ::std::string* httpaddress_;
  ::std::string* rackname_;
  ::hadoop::yarn::ResourceProto* used_;
  ::hadoop::yarn::ResourceProto* capability_;
  ::google::protobuf::int32 numcontainers_;
  int node_state_;
  ::std::string* health_report_;
  ::google::protobuf::int64 last_health_report_time_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(9 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static NodeReportProto* default_instance_;
};
// -------------------------------------------------------------------

class ResourceRequestProto : public ::google::protobuf::Message {
 public:
  ResourceRequestProto();
  virtual ~ResourceRequestProto();

  ResourceRequestProto(const ResourceRequestProto& from);

  inline ResourceRequestProto& operator=(const ResourceRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ResourceRequestProto& default_instance();

  void Swap(ResourceRequestProto* other);

  // implements Message ----------------------------------------------

  ResourceRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ResourceRequestProto& from);
  void MergeFrom(const ResourceRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.PriorityProto priority = 1;
  inline bool has_priority() const;
  inline void clear_priority();
  static const int kPriorityFieldNumber = 1;
  inline const ::hadoop::yarn::PriorityProto& priority() const;
  inline ::hadoop::yarn::PriorityProto* mutable_priority();
  inline ::hadoop::yarn::PriorityProto* release_priority();
  inline void set_allocated_priority(::hadoop::yarn::PriorityProto* priority);

  // optional string resource_name = 2;
  inline bool has_resource_name() const;
  inline void clear_resource_name();
  static const int kResourceNameFieldNumber = 2;
  inline const ::std::string& resource_name() const;
  inline void set_resource_name(const ::std::string& value);
  inline void set_resource_name(const char* value);
  inline void set_resource_name(const char* value, size_t size);
  inline ::std::string* mutable_resource_name();
  inline ::std::string* release_resource_name();
  inline void set_allocated_resource_name(::std::string* resource_name);

  // optional .hadoop.yarn.ResourceProto capability = 3;
  inline bool has_capability() const;
  inline void clear_capability();
  static const int kCapabilityFieldNumber = 3;
  inline const ::hadoop::yarn::ResourceProto& capability() const;
  inline ::hadoop::yarn::ResourceProto* mutable_capability();
  inline ::hadoop::yarn::ResourceProto* release_capability();
  inline void set_allocated_capability(::hadoop::yarn::ResourceProto* capability);

  // optional int32 num_containers = 4;
  inline bool has_num_containers() const;
  inline void clear_num_containers();
  static const int kNumContainersFieldNumber = 4;
  inline ::google::protobuf::int32 num_containers() const;
  inline void set_num_containers(::google::protobuf::int32 value);

  // optional bool relax_locality = 5 [default = true];
  inline bool has_relax_locality() const;
  inline void clear_relax_locality();
  static const int kRelaxLocalityFieldNumber = 5;
  inline bool relax_locality() const;
  inline void set_relax_locality(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceRequestProto)
 private:
  inline void set_has_priority();
  inline void clear_has_priority();
  inline void set_has_resource_name();
  inline void clear_has_resource_name();
  inline void set_has_capability();
  inline void clear_has_capability();
  inline void set_has_num_containers();
  inline void clear_has_num_containers();
  inline void set_has_relax_locality();
  inline void clear_has_relax_locality();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::PriorityProto* priority_;
  ::std::string* resource_name_;
  ::hadoop::yarn::ResourceProto* capability_;
  ::google::protobuf::int32 num_containers_;
  bool relax_locality_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(5 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ResourceRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class PreemptionMessageProto : public ::google::protobuf::Message {
 public:
  PreemptionMessageProto();
  virtual ~PreemptionMessageProto();

  PreemptionMessageProto(const PreemptionMessageProto& from);

  inline PreemptionMessageProto& operator=(const PreemptionMessageProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const PreemptionMessageProto& default_instance();

  void Swap(PreemptionMessageProto* other);

  // implements Message ----------------------------------------------

  PreemptionMessageProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const PreemptionMessageProto& from);
  void MergeFrom(const PreemptionMessageProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;
  inline bool has_strictcontract() const;
  inline void clear_strictcontract();
  static const int kStrictContractFieldNumber = 1;
  inline const ::hadoop::yarn::StrictPreemptionContractProto& strictcontract() const;
  inline ::hadoop::yarn::StrictPreemptionContractProto* mutable_strictcontract();
  inline ::hadoop::yarn::StrictPreemptionContractProto* release_strictcontract();
  inline void set_allocated_strictcontract(::hadoop::yarn::StrictPreemptionContractProto* strictcontract);

  // optional .hadoop.yarn.PreemptionContractProto contract = 2;
  inline bool has_contract() const;
  inline void clear_contract();
  static const int kContractFieldNumber = 2;
  inline const ::hadoop::yarn::PreemptionContractProto& contract() const;
  inline ::hadoop::yarn::PreemptionContractProto* mutable_contract();
  inline ::hadoop::yarn::PreemptionContractProto* release_contract();
  inline void set_allocated_contract(::hadoop::yarn::PreemptionContractProto* contract);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionMessageProto)
 private:
  inline void set_has_strictcontract();
  inline void clear_has_strictcontract();
  inline void set_has_contract();
  inline void clear_has_contract();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::StrictPreemptionContractProto* strictcontract_;
  ::hadoop::yarn::PreemptionContractProto* contract_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static PreemptionMessageProto* default_instance_;
};
// -------------------------------------------------------------------

class StrictPreemptionContractProto : public ::google::protobuf::Message {
 public:
  StrictPreemptionContractProto();
  virtual ~StrictPreemptionContractProto();

  StrictPreemptionContractProto(const StrictPreemptionContractProto& from);

  inline StrictPreemptionContractProto& operator=(const StrictPreemptionContractProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StrictPreemptionContractProto& default_instance();

  void Swap(StrictPreemptionContractProto* other);

  // implements Message ----------------------------------------------

  StrictPreemptionContractProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StrictPreemptionContractProto& from);
  void MergeFrom(const StrictPreemptionContractProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.PreemptionContainerProto container = 1;
  inline int container_size() const;
  inline void clear_container();
  static const int kContainerFieldNumber = 1;
  inline const ::hadoop::yarn::PreemptionContainerProto& container(int index) const;
  inline ::hadoop::yarn::PreemptionContainerProto* mutable_container(int index);
  inline ::hadoop::yarn::PreemptionContainerProto* add_container();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionContainerProto >&
      container() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionContainerProto >*
      mutable_container();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.StrictPreemptionContractProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionContainerProto > container_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static StrictPreemptionContractProto* default_instance_;
};
// -------------------------------------------------------------------

class PreemptionContractProto : public ::google::protobuf::Message {
 public:
  PreemptionContractProto();
  virtual ~PreemptionContractProto();

  PreemptionContractProto(const PreemptionContractProto& from);

  inline PreemptionContractProto& operator=(const PreemptionContractProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const PreemptionContractProto& default_instance();

  void Swap(PreemptionContractProto* other);

  // implements Message ----------------------------------------------

  PreemptionContractProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const PreemptionContractProto& from);
  void MergeFrom(const PreemptionContractProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;
  inline int resource_size() const;
  inline void clear_resource();
  static const int kResourceFieldNumber = 1;
  inline const ::hadoop::yarn::PreemptionResourceRequestProto& resource(int index) const;
  inline ::hadoop::yarn::PreemptionResourceRequestProto* mutable_resource(int index);
  inline ::hadoop::yarn::PreemptionResourceRequestProto* add_resource();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionResourceRequestProto >&
      resource() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionResourceRequestProto >*
      mutable_resource();

  // repeated .hadoop.yarn.PreemptionContainerProto container = 2;
  inline int container_size() const;
  inline void clear_container();
  static const int kContainerFieldNumber = 2;
  inline const ::hadoop::yarn::PreemptionContainerProto& container(int index) const;
  inline ::hadoop::yarn::PreemptionContainerProto* mutable_container(int index);
  inline ::hadoop::yarn::PreemptionContainerProto* add_container();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionContainerProto >&
      container() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionContainerProto >*
      mutable_container();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionContractProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionResourceRequestProto > resource_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionContainerProto > container_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static PreemptionContractProto* default_instance_;
};
// -------------------------------------------------------------------

class PreemptionContainerProto : public ::google::protobuf::Message {
 public:
  PreemptionContainerProto();
  virtual ~PreemptionContainerProto();

  PreemptionContainerProto(const PreemptionContainerProto& from);

  inline PreemptionContainerProto& operator=(const PreemptionContainerProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const PreemptionContainerProto& default_instance();

  void Swap(PreemptionContainerProto* other);

  // implements Message ----------------------------------------------

  PreemptionContainerProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const PreemptionContainerProto& from);
  void MergeFrom(const PreemptionContainerProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ContainerIdProto id = 1;
  inline bool has_id() const;
  inline void clear_id();
  static const int kIdFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerIdProto& id() const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_id();
  inline ::hadoop::yarn::ContainerIdProto* release_id();
  inline void set_allocated_id(::hadoop::yarn::ContainerIdProto* id);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionContainerProto)
 private:
  inline void set_has_id();
  inline void clear_has_id();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ContainerIdProto* id_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static PreemptionContainerProto* default_instance_;
};
// -------------------------------------------------------------------

class PreemptionResourceRequestProto : public ::google::protobuf::Message {
 public:
  PreemptionResourceRequestProto();
  virtual ~PreemptionResourceRequestProto();

  PreemptionResourceRequestProto(const PreemptionResourceRequestProto& from);

  inline PreemptionResourceRequestProto& operator=(const PreemptionResourceRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const PreemptionResourceRequestProto& default_instance();

  void Swap(PreemptionResourceRequestProto* other);

  // implements Message ----------------------------------------------

  PreemptionResourceRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const PreemptionResourceRequestProto& from);
  void MergeFrom(const PreemptionResourceRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ResourceRequestProto resource = 1;
  inline bool has_resource() const;
  inline void clear_resource();
  static const int kResourceFieldNumber = 1;
  inline const ::hadoop::yarn::ResourceRequestProto& resource() const;
  inline ::hadoop::yarn::ResourceRequestProto* mutable_resource();
  inline ::hadoop::yarn::ResourceRequestProto* release_resource();
  inline void set_allocated_resource(::hadoop::yarn::ResourceRequestProto* resource);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionResourceRequestProto)
 private:
  inline void set_has_resource();
  inline void clear_has_resource();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ResourceRequestProto* resource_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static PreemptionResourceRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class ResourceBlacklistRequestProto : public ::google::protobuf::Message {
 public:
  ResourceBlacklistRequestProto();
  virtual ~ResourceBlacklistRequestProto();

  ResourceBlacklistRequestProto(const ResourceBlacklistRequestProto& from);

  inline ResourceBlacklistRequestProto& operator=(const ResourceBlacklistRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ResourceBlacklistRequestProto& default_instance();

  void Swap(ResourceBlacklistRequestProto* other);

  // implements Message ----------------------------------------------

  ResourceBlacklistRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ResourceBlacklistRequestProto& from);
  void MergeFrom(const ResourceBlacklistRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated string blacklist_additions = 1;
  inline int blacklist_additions_size() const;
  inline void clear_blacklist_additions();
  static const int kBlacklistAdditionsFieldNumber = 1;
  inline const ::std::string& blacklist_additions(int index) const;
  inline ::std::string* mutable_blacklist_additions(int index);
  inline void set_blacklist_additions(int index, const ::std::string& value);
  inline void set_blacklist_additions(int index, const char* value);
  inline void set_blacklist_additions(int index, const char* value, size_t size);
  inline ::std::string* add_blacklist_additions();
  inline void add_blacklist_additions(const ::std::string& value);
  inline void add_blacklist_additions(const char* value);
  inline void add_blacklist_additions(const char* value, size_t size);
  inline const ::google::protobuf::RepeatedPtrField< ::std::string>& blacklist_additions() const;
  inline ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_blacklist_additions();

  // repeated string blacklist_removals = 2;
  inline int blacklist_removals_size() const;
  inline void clear_blacklist_removals();
  static const int kBlacklistRemovalsFieldNumber = 2;
  inline const ::std::string& blacklist_removals(int index) const;
  inline ::std::string* mutable_blacklist_removals(int index);
  inline void set_blacklist_removals(int index, const ::std::string& value);
  inline void set_blacklist_removals(int index, const char* value);
  inline void set_blacklist_removals(int index, const char* value, size_t size);
  inline ::std::string* add_blacklist_removals();
  inline void add_blacklist_removals(const ::std::string& value);
  inline void add_blacklist_removals(const char* value);
  inline void add_blacklist_removals(const char* value, size_t size);
  inline const ::google::protobuf::RepeatedPtrField< ::std::string>& blacklist_removals() const;
  inline ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_blacklist_removals();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceBlacklistRequestProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::std::string> blacklist_additions_;
  ::google::protobuf::RepeatedPtrField< ::std::string> blacklist_removals_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ResourceBlacklistRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class ApplicationSubmissionContextProto : public ::google::protobuf::Message {
 public:
  ApplicationSubmissionContextProto();
  virtual ~ApplicationSubmissionContextProto();

  ApplicationSubmissionContextProto(const ApplicationSubmissionContextProto& from);

  inline ApplicationSubmissionContextProto& operator=(const ApplicationSubmissionContextProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ApplicationSubmissionContextProto& default_instance();

  void Swap(ApplicationSubmissionContextProto* other);

  // implements Message ----------------------------------------------

  ApplicationSubmissionContextProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ApplicationSubmissionContextProto& from);
  void MergeFrom(const ApplicationSubmissionContextProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
  inline bool has_application_id() const;
  inline void clear_application_id();
  static const int kApplicationIdFieldNumber = 1;
  inline const ::hadoop::yarn::ApplicationIdProto& application_id() const;
  inline ::hadoop::yarn::ApplicationIdProto* mutable_application_id();
  inline ::hadoop::yarn::ApplicationIdProto* release_application_id();
  inline void set_allocated_application_id(::hadoop::yarn::ApplicationIdProto* application_id);

  // optional string application_name = 2 [default = "N/A"];
  inline bool has_application_name() const;
  inline void clear_application_name();
  static const int kApplicationNameFieldNumber = 2;
  inline const ::std::string& application_name() const;
  inline void set_application_name(const ::std::string& value);
  inline void set_application_name(const char* value);
  inline void set_application_name(const char* value, size_t size);
  inline ::std::string* mutable_application_name();
  inline ::std::string* release_application_name();
  inline void set_allocated_application_name(::std::string* application_name);

  // optional string queue = 3 [default = "default"];
  inline bool has_queue() const;
  inline void clear_queue();
  static const int kQueueFieldNumber = 3;
  inline const ::std::string& queue() const;
  inline void set_queue(const ::std::string& value);
  inline void set_queue(const char* value);
  inline void set_queue(const char* value, size_t size);
  inline ::std::string* mutable_queue();
  inline ::std::string* release_queue();
  inline void set_allocated_queue(::std::string* queue);

  // optional .hadoop.yarn.PriorityProto priority = 4;
  inline bool has_priority() const;
  inline void clear_priority();
  static const int kPriorityFieldNumber = 4;
  inline const ::hadoop::yarn::PriorityProto& priority() const;
  inline ::hadoop::yarn::PriorityProto* mutable_priority();
  inline ::hadoop::yarn::PriorityProto* release_priority();
  inline void set_allocated_priority(::hadoop::yarn::PriorityProto* priority);

  // optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;
  inline bool has_am_container_spec() const;
  inline void clear_am_container_spec();
  static const int kAmContainerSpecFieldNumber = 5;
  inline const ::hadoop::yarn::ContainerLaunchContextProto& am_container_spec() const;
  inline ::hadoop::yarn::ContainerLaunchContextProto* mutable_am_container_spec();
  inline ::hadoop::yarn::ContainerLaunchContextProto* release_am_container_spec();
  inline void set_allocated_am_container_spec(::hadoop::yarn::ContainerLaunchContextProto* am_container_spec);

  // optional bool cancel_tokens_when_complete = 6 [default = true];
  inline bool has_cancel_tokens_when_complete() const;
  inline void clear_cancel_tokens_when_complete();
  static const int kCancelTokensWhenCompleteFieldNumber = 6;
  inline bool cancel_tokens_when_complete() const;
  inline void set_cancel_tokens_when_complete(bool value);

  // optional bool unmanaged_am = 7 [default = false];
  inline bool has_unmanaged_am() const;
  inline void clear_unmanaged_am();
  static const int kUnmanagedAmFieldNumber = 7;
  inline bool unmanaged_am() const;
  inline void set_unmanaged_am(bool value);

  // optional int32 maxAppAttempts = 8 [default = 0];
  inline bool has_maxappattempts() const;
  inline void clear_maxappattempts();
  static const int kMaxAppAttemptsFieldNumber = 8;
  inline ::google::protobuf::int32 maxappattempts() const;
  inline void set_maxappattempts(::google::protobuf::int32 value);

  // optional .hadoop.yarn.ResourceProto resource = 9;
  inline bool has_resource() const;
  inline void clear_resource();
  static const int kResourceFieldNumber = 9;
  inline const ::hadoop::yarn::ResourceProto& resource() const;
  inline ::hadoop::yarn::ResourceProto* mutable_resource();
  inline ::hadoop::yarn::ResourceProto* release_resource();
  inline void set_allocated_resource(::hadoop::yarn::ResourceProto* resource);

  // optional string applicationType = 10 [default = "YARN"];
  inline bool has_applicationtype() const;
  inline void clear_applicationtype();
  static const int kApplicationTypeFieldNumber = 10;
  inline const ::std::string& applicationtype() const;
  inline void set_applicationtype(const ::std::string& value);
  inline void set_applicationtype(const char* value);
  inline void set_applicationtype(const char* value, size_t size);
  inline ::std::string* mutable_applicationtype();
  inline ::std::string* release_applicationtype();
  inline void set_allocated_applicationtype(::std::string* applicationtype);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationSubmissionContextProto)
 private:
  inline void set_has_application_id();
  inline void clear_has_application_id();
  inline void set_has_application_name();
  inline void clear_has_application_name();
  inline void set_has_queue();
  inline void clear_has_queue();
  inline void set_has_priority();
  inline void clear_has_priority();
  inline void set_has_am_container_spec();
  inline void clear_has_am_container_spec();
  inline void set_has_cancel_tokens_when_complete();
  inline void clear_has_cancel_tokens_when_complete();
  inline void set_has_unmanaged_am();
  inline void clear_has_unmanaged_am();
  inline void set_has_maxappattempts();
  inline void clear_has_maxappattempts();
  inline void set_has_resource();
  inline void clear_has_resource();
  inline void set_has_applicationtype();
  inline void clear_has_applicationtype();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ApplicationIdProto* application_id_;
  ::std::string* application_name_;
  static ::std::string* _default_application_name_;
  ::std::string* queue_;
  static ::std::string* _default_queue_;
  ::hadoop::yarn::PriorityProto* priority_;
  ::hadoop::yarn::ContainerLaunchContextProto* am_container_spec_;
  bool cancel_tokens_when_complete_;
  bool unmanaged_am_;
  ::google::protobuf::int32 maxappattempts_;
  ::hadoop::yarn::ResourceProto* resource_;
  ::std::string* applicationtype_;
  static ::std::string* _default_applicationtype_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(10 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ApplicationSubmissionContextProto* default_instance_;
};
// -------------------------------------------------------------------

class ApplicationACLMapProto : public ::google::protobuf::Message {
 public:
  ApplicationACLMapProto();
  virtual ~ApplicationACLMapProto();

  ApplicationACLMapProto(const ApplicationACLMapProto& from);

  inline ApplicationACLMapProto& operator=(const ApplicationACLMapProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ApplicationACLMapProto& default_instance();

  void Swap(ApplicationACLMapProto* other);

  // implements Message ----------------------------------------------

  ApplicationACLMapProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ApplicationACLMapProto& from);
  void MergeFrom(const ApplicationACLMapProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;
  inline bool has_accesstype() const;
  inline void clear_accesstype();
  static const int kAccessTypeFieldNumber = 1;
  inline ::hadoop::yarn::ApplicationAccessTypeProto accesstype() const;
  inline void set_accesstype(::hadoop::yarn::ApplicationAccessTypeProto value);

  // optional string acl = 2 [default = " "];
  inline bool has_acl() const;
  inline void clear_acl();
  static const int kAclFieldNumber = 2;
  inline const ::std::string& acl() const;
  inline void set_acl(const ::std::string& value);
  inline void set_acl(const char* value);
  inline void set_acl(const char* value, size_t size);
  inline ::std::string* mutable_acl();
  inline ::std::string* release_acl();
  inline void set_allocated_acl(::std::string* acl);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationACLMapProto)
 private:
  inline void set_has_accesstype();
  inline void clear_has_accesstype();
  inline void set_has_acl();
  inline void clear_has_acl();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::std::string* acl_;
  static ::std::string* _default_acl_;
  int accesstype_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ApplicationACLMapProto* default_instance_;
};
// -------------------------------------------------------------------

class YarnClusterMetricsProto : public ::google::protobuf::Message {
 public:
  YarnClusterMetricsProto();
  virtual ~YarnClusterMetricsProto();

  YarnClusterMetricsProto(const YarnClusterMetricsProto& from);

  inline YarnClusterMetricsProto& operator=(const YarnClusterMetricsProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const YarnClusterMetricsProto& default_instance();

  void Swap(YarnClusterMetricsProto* other);

  // implements Message ----------------------------------------------

  YarnClusterMetricsProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const YarnClusterMetricsProto& from);
  void MergeFrom(const YarnClusterMetricsProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int32 num_node_managers = 1;
  inline bool has_num_node_managers() const;
  inline void clear_num_node_managers();
  static const int kNumNodeManagersFieldNumber = 1;
  inline ::google::protobuf::int32 num_node_managers() const;
  inline void set_num_node_managers(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.YarnClusterMetricsProto)
 private:
  inline void set_has_num_node_managers();
  inline void clear_has_num_node_managers();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::int32 num_node_managers_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static YarnClusterMetricsProto* default_instance_;
};
// -------------------------------------------------------------------

class QueueInfoProto : public ::google::protobuf::Message {
 public:
  QueueInfoProto();
  virtual ~QueueInfoProto();

  QueueInfoProto(const QueueInfoProto& from);

  inline QueueInfoProto& operator=(const QueueInfoProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const QueueInfoProto& default_instance();

  void Swap(QueueInfoProto* other);

  // implements Message ----------------------------------------------

  QueueInfoProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const QueueInfoProto& from);
  void MergeFrom(const QueueInfoProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string queueName = 1;
  inline bool has_queuename() const;
  inline void clear_queuename();
  static const int kQueueNameFieldNumber = 1;
  inline const ::std::string& queuename() const;
  inline void set_queuename(const ::std::string& value);
  inline void set_queuename(const char* value);
  inline void set_queuename(const char* value, size_t size);
  inline ::std::string* mutable_queuename();
  inline ::std::string* release_queuename();
  inline void set_allocated_queuename(::std::string* queuename);

  // optional float capacity = 2;
  inline bool has_capacity() const;
  inline void clear_capacity();
  static const int kCapacityFieldNumber = 2;
  inline float capacity() const;
  inline void set_capacity(float value);

  // optional float maximumCapacity = 3;
  inline bool has_maximumcapacity() const;
  inline void clear_maximumcapacity();
  static const int kMaximumCapacityFieldNumber = 3;
  inline float maximumcapacity() const;
  inline void set_maximumcapacity(float value);

  // optional float currentCapacity = 4;
  inline bool has_currentcapacity() const;
  inline void clear_currentcapacity();
  static const int kCurrentCapacityFieldNumber = 4;
  inline float currentcapacity() const;
  inline void set_currentcapacity(float value);

  // optional .hadoop.yarn.QueueStateProto state = 5;
  inline bool has_state() const;
  inline void clear_state();
  static const int kStateFieldNumber = 5;
  inline ::hadoop::yarn::QueueStateProto state() const;
  inline void set_state(::hadoop::yarn::QueueStateProto value);

  // repeated .hadoop.yarn.QueueInfoProto childQueues = 6;
  inline int childqueues_size() const;
  inline void clear_childqueues();
  static const int kChildQueuesFieldNumber = 6;
  inline const ::hadoop::yarn::QueueInfoProto& childqueues(int index) const;
  inline ::hadoop::yarn::QueueInfoProto* mutable_childqueues(int index);
  inline ::hadoop::yarn::QueueInfoProto* add_childqueues();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::QueueInfoProto >&
      childqueues() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::QueueInfoProto >*
      mutable_childqueues();

  // repeated .hadoop.yarn.ApplicationReportProto applications = 7;
  inline int applications_size() const;
  inline void clear_applications();
  static const int kApplicationsFieldNumber = 7;
  inline const ::hadoop::yarn::ApplicationReportProto& applications(int index) const;
  inline ::hadoop::yarn::ApplicationReportProto* mutable_applications(int index);
  inline ::hadoop::yarn::ApplicationReportProto* add_applications();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationReportProto >&
      applications() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationReportProto >*
      mutable_applications();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.QueueInfoProto)
 private:
  inline void set_has_queuename();
  inline void clear_has_queuename();
  inline void set_has_capacity();
  inline void clear_has_capacity();
  inline void set_has_maximumcapacity();
  inline void clear_has_maximumcapacity();
  inline void set_has_currentcapacity();
  inline void clear_has_currentcapacity();
  inline void set_has_state();
  inline void clear_has_state();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::std::string* queuename_;
  float capacity_;
  float maximumcapacity_;
  float currentcapacity_;
  int state_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::QueueInfoProto > childqueues_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationReportProto > applications_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(7 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static QueueInfoProto* default_instance_;
};
// -------------------------------------------------------------------

class QueueUserACLInfoProto : public ::google::protobuf::Message {
 public:
  QueueUserACLInfoProto();
  virtual ~QueueUserACLInfoProto();

  QueueUserACLInfoProto(const QueueUserACLInfoProto& from);

  inline QueueUserACLInfoProto& operator=(const QueueUserACLInfoProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const QueueUserACLInfoProto& default_instance();

  void Swap(QueueUserACLInfoProto* other);

  // implements Message ----------------------------------------------

  QueueUserACLInfoProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const QueueUserACLInfoProto& from);
  void MergeFrom(const QueueUserACLInfoProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string queueName = 1;
  inline bool has_queuename() const;
  inline void clear_queuename();
  static const int kQueueNameFieldNumber = 1;
  inline const ::std::string& queuename() const;
  inline void set_queuename(const ::std::string& value);
  inline void set_queuename(const char* value);
  inline void set_queuename(const char* value, size_t size);
  inline ::std::string* mutable_queuename();
  inline ::std::string* release_queuename();
  inline void set_allocated_queuename(::std::string* queuename);

  // repeated .hadoop.yarn.QueueACLProto userAcls = 2;
  inline int useracls_size() const;
  inline void clear_useracls();
  static const int kUserAclsFieldNumber = 2;
  inline ::hadoop::yarn::QueueACLProto useracls(int index) const;
  inline void set_useracls(int index, ::hadoop::yarn::QueueACLProto value);
  inline void add_useracls(::hadoop::yarn::QueueACLProto value);
  inline const ::google::protobuf::RepeatedField<int>& useracls() const;
  inline ::google::protobuf::RepeatedField<int>* mutable_useracls();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.QueueUserACLInfoProto)
 private:
  inline void set_has_queuename();
  inline void clear_has_queuename();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::std::string* queuename_;
  ::google::protobuf::RepeatedField<int> useracls_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static QueueUserACLInfoProto* default_instance_;
};
// -------------------------------------------------------------------

class ContainerLaunchContextProto : public ::google::protobuf::Message {
 public:
  ContainerLaunchContextProto();
  virtual ~ContainerLaunchContextProto();

  ContainerLaunchContextProto(const ContainerLaunchContextProto& from);

  inline ContainerLaunchContextProto& operator=(const ContainerLaunchContextProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ContainerLaunchContextProto& default_instance();

  void Swap(ContainerLaunchContextProto* other);

  // implements Message ----------------------------------------------

  ContainerLaunchContextProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ContainerLaunchContextProto& from);
  void MergeFrom(const ContainerLaunchContextProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;
  inline int localresources_size() const;
  inline void clear_localresources();
  static const int kLocalResourcesFieldNumber = 1;
  inline const ::hadoop::yarn::StringLocalResourceMapProto& localresources(int index) const;
  inline ::hadoop::yarn::StringLocalResourceMapProto* mutable_localresources(int index);
  inline ::hadoop::yarn::StringLocalResourceMapProto* add_localresources();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringLocalResourceMapProto >&
      localresources() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringLocalResourceMapProto >*
      mutable_localresources();

  // optional bytes tokens = 2;
  inline bool has_tokens() const;
  inline void clear_tokens();
  static const int kTokensFieldNumber = 2;
  inline const ::std::string& tokens() const;
  inline void set_tokens(const ::std::string& value);
  inline void set_tokens(const char* value);
  inline void set_tokens(const void* value, size_t size);
  inline ::std::string* mutable_tokens();
  inline ::std::string* release_tokens();
  inline void set_allocated_tokens(::std::string* tokens);

  // repeated .hadoop.yarn.StringBytesMapProto service_data = 3;
  inline int service_data_size() const;
  inline void clear_service_data();
  static const int kServiceDataFieldNumber = 3;
  inline const ::hadoop::yarn::StringBytesMapProto& service_data(int index) const;
  inline ::hadoop::yarn::StringBytesMapProto* mutable_service_data(int index);
  inline ::hadoop::yarn::StringBytesMapProto* add_service_data();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto >&
      service_data() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto >*
      mutable_service_data();

  // repeated .hadoop.yarn.StringStringMapProto environment = 4;
  inline int environment_size() const;
  inline void clear_environment();
  static const int kEnvironmentFieldNumber = 4;
  inline const ::hadoop::yarn::StringStringMapProto& environment(int index) const;
  inline ::hadoop::yarn::StringStringMapProto* mutable_environment(int index);
  inline ::hadoop::yarn::StringStringMapProto* add_environment();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringStringMapProto >&
      environment() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringStringMapProto >*
      mutable_environment();

  // repeated string command = 5;
  inline int command_size() const;
  inline void clear_command();
  static const int kCommandFieldNumber = 5;
  inline const ::std::string& command(int index) const;
  inline ::std::string* mutable_command(int index);
  inline void set_command(int index, const ::std::string& value);
  inline void set_command(int index, const char* value);
  inline void set_command(int index, const char* value, size_t size);
  inline ::std::string* add_command();
  inline void add_command(const ::std::string& value);
  inline void add_command(const char* value);
  inline void add_command(const char* value, size_t size);
  inline const ::google::protobuf::RepeatedPtrField< ::std::string>& command() const;
  inline ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_command();

  // repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;
  inline int application_acls_size() const;
  inline void clear_application_acls();
  static const int kApplicationACLsFieldNumber = 6;
  inline const ::hadoop::yarn::ApplicationACLMapProto& application_acls(int index) const;
  inline ::hadoop::yarn::ApplicationACLMapProto* mutable_application_acls(int index);
  inline ::hadoop::yarn::ApplicationACLMapProto* add_application_acls();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationACLMapProto >&
      application_acls() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationACLMapProto >*
      mutable_application_acls();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerLaunchContextProto)
 private:
  inline void set_has_tokens();
  inline void clear_has_tokens();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringLocalResourceMapProto > localresources_;
  ::std::string* tokens_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto > service_data_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringStringMapProto > environment_;
  ::google::protobuf::RepeatedPtrField< ::std::string> command_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationACLMapProto > application_acls_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(6 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ContainerLaunchContextProto* default_instance_;
};
// -------------------------------------------------------------------

class ContainerStatusProto : public ::google::protobuf::Message {
 public:
  ContainerStatusProto();
  virtual ~ContainerStatusProto();

  ContainerStatusProto(const ContainerStatusProto& from);

  inline ContainerStatusProto& operator=(const ContainerStatusProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ContainerStatusProto& default_instance();

  void Swap(ContainerStatusProto* other);

  // implements Message ----------------------------------------------

  ContainerStatusProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ContainerStatusProto& from);
  void MergeFrom(const ContainerStatusProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ContainerIdProto container_id = 1;
  inline bool has_container_id() const;
  inline void clear_container_id();
  static const int kContainerIdFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerIdProto& container_id() const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_container_id();
  inline ::hadoop::yarn::ContainerIdProto* release_container_id();
  inline void set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id);

  // optional .hadoop.yarn.ContainerStateProto state = 2;
  inline bool has_state() const;
  inline void clear_state();
  static const int kStateFieldNumber = 2;
  inline ::hadoop::yarn::ContainerStateProto state() const;
  inline void set_state(::hadoop::yarn::ContainerStateProto value);

  // optional string diagnostics = 3 [default = "N/A"];
  inline bool has_diagnostics() const;
  inline void clear_diagnostics();
  static const int kDiagnosticsFieldNumber = 3;
  inline const ::std::string& diagnostics() const;
  inline void set_diagnostics(const ::std::string& value);
  inline void set_diagnostics(const char* value);
  inline void set_diagnostics(const char* value, size_t size);
  inline ::std::string* mutable_diagnostics();
  inline ::std::string* release_diagnostics();
  inline void set_allocated_diagnostics(::std::string* diagnostics);

  // optional int32 exit_status = 4 [default = -1000];
  inline bool has_exit_status() const;
  inline void clear_exit_status();
  static const int kExitStatusFieldNumber = 4;
  inline ::google::protobuf::int32 exit_status() const;
  inline void set_exit_status(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerStatusProto)
 private:
  inline void set_has_container_id();
  inline void clear_has_container_id();
  inline void set_has_state();
  inline void clear_has_state();
  inline void set_has_diagnostics();
  inline void clear_has_diagnostics();
  inline void set_has_exit_status();
  inline void clear_has_exit_status();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ContainerIdProto* container_id_;
  ::std::string* diagnostics_;
  static ::std::string* _default_diagnostics_;
  int state_;
  ::google::protobuf::int32 exit_status_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(4 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ContainerStatusProto* default_instance_;
};
// -------------------------------------------------------------------

class ContainerResourceIncreaseRequestProto : public ::google::protobuf::Message {
 public:
  ContainerResourceIncreaseRequestProto();
  virtual ~ContainerResourceIncreaseRequestProto();

  ContainerResourceIncreaseRequestProto(const ContainerResourceIncreaseRequestProto& from);

  inline ContainerResourceIncreaseRequestProto& operator=(const ContainerResourceIncreaseRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ContainerResourceIncreaseRequestProto& default_instance();

  void Swap(ContainerResourceIncreaseRequestProto* other);

  // implements Message ----------------------------------------------

  ContainerResourceIncreaseRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ContainerResourceIncreaseRequestProto& from);
  void MergeFrom(const ContainerResourceIncreaseRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ContainerIdProto container_id = 1;
  inline bool has_container_id() const;
  inline void clear_container_id();
  static const int kContainerIdFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerIdProto& container_id() const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_container_id();
  inline ::hadoop::yarn::ContainerIdProto* release_container_id();
  inline void set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id);

  // optional .hadoop.yarn.ResourceProto capability = 2;
  inline bool has_capability() const;
  inline void clear_capability();
  static const int kCapabilityFieldNumber = 2;
  inline const ::hadoop::yarn::ResourceProto& capability() const;
  inline ::hadoop::yarn::ResourceProto* mutable_capability();
  inline ::hadoop::yarn::ResourceProto* release_capability();
  inline void set_allocated_capability(::hadoop::yarn::ResourceProto* capability);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerResourceIncreaseRequestProto)
 private:
  inline void set_has_container_id();
  inline void clear_has_container_id();
  inline void set_has_capability();
  inline void clear_has_capability();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ContainerIdProto* container_id_;
  ::hadoop::yarn::ResourceProto* capability_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ContainerResourceIncreaseRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class ContainerResourceIncreaseProto : public ::google::protobuf::Message {
 public:
  ContainerResourceIncreaseProto();
  virtual ~ContainerResourceIncreaseProto();

  ContainerResourceIncreaseProto(const ContainerResourceIncreaseProto& from);

  inline ContainerResourceIncreaseProto& operator=(const ContainerResourceIncreaseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ContainerResourceIncreaseProto& default_instance();

  void Swap(ContainerResourceIncreaseProto* other);

  // implements Message ----------------------------------------------

  ContainerResourceIncreaseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ContainerResourceIncreaseProto& from);
  void MergeFrom(const ContainerResourceIncreaseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ContainerIdProto container_id = 1;
  inline bool has_container_id() const;
  inline void clear_container_id();
  static const int kContainerIdFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerIdProto& container_id() const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_container_id();
  inline ::hadoop::yarn::ContainerIdProto* release_container_id();
  inline void set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id);

  // optional .hadoop.yarn.ResourceProto capability = 2;
  inline bool has_capability() const;
  inline void clear_capability();
  static const int kCapabilityFieldNumber = 2;
  inline const ::hadoop::yarn::ResourceProto& capability() const;
  inline ::hadoop::yarn::ResourceProto* mutable_capability();
  inline ::hadoop::yarn::ResourceProto* release_capability();
  inline void set_allocated_capability(::hadoop::yarn::ResourceProto* capability);

  // optional .hadoop.common.TokenProto container_token = 3;
  inline bool has_container_token() const;
  inline void clear_container_token();
  static const int kContainerTokenFieldNumber = 3;
  inline const ::hadoop::common::TokenProto& container_token() const;
  inline ::hadoop::common::TokenProto* mutable_container_token();
  inline ::hadoop::common::TokenProto* release_container_token();
  inline void set_allocated_container_token(::hadoop::common::TokenProto* container_token);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerResourceIncreaseProto)
 private:
  inline void set_has_container_id();
  inline void clear_has_container_id();
  inline void set_has_capability();
  inline void clear_has_capability();
  inline void set_has_container_token();
  inline void clear_has_container_token();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ContainerIdProto* container_id_;
  ::hadoop::yarn::ResourceProto* capability_;
  ::hadoop::common::TokenProto* container_token_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(3 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ContainerResourceIncreaseProto* default_instance_;
};
// -------------------------------------------------------------------

class ContainerResourceDecreaseProto : public ::google::protobuf::Message {
 public:
  ContainerResourceDecreaseProto();
  virtual ~ContainerResourceDecreaseProto();

  ContainerResourceDecreaseProto(const ContainerResourceDecreaseProto& from);

  inline ContainerResourceDecreaseProto& operator=(const ContainerResourceDecreaseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ContainerResourceDecreaseProto& default_instance();

  void Swap(ContainerResourceDecreaseProto* other);

  // implements Message ----------------------------------------------

  ContainerResourceDecreaseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ContainerResourceDecreaseProto& from);
  void MergeFrom(const ContainerResourceDecreaseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ContainerIdProto container_id = 1;
  inline bool has_container_id() const;
  inline void clear_container_id();
  static const int kContainerIdFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerIdProto& container_id() const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_container_id();
  inline ::hadoop::yarn::ContainerIdProto* release_container_id();
  inline void set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id);

  // optional .hadoop.yarn.ResourceProto capability = 2;
  inline bool has_capability() const;
  inline void clear_capability();
  static const int kCapabilityFieldNumber = 2;
  inline const ::hadoop::yarn::ResourceProto& capability() const;
  inline ::hadoop::yarn::ResourceProto* mutable_capability();
  inline ::hadoop::yarn::ResourceProto* release_capability();
  inline void set_allocated_capability(::hadoop::yarn::ResourceProto* capability);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerResourceDecreaseProto)
 private:
  inline void set_has_container_id();
  inline void clear_has_container_id();
  inline void set_has_capability();
  inline void clear_has_capability();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ContainerIdProto* container_id_;
  ::hadoop::yarn::ResourceProto* capability_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ContainerResourceDecreaseProto* default_instance_;
};
// -------------------------------------------------------------------

class StringLocalResourceMapProto : public ::google::protobuf::Message {
 public:
  StringLocalResourceMapProto();
  virtual ~StringLocalResourceMapProto();

  StringLocalResourceMapProto(const StringLocalResourceMapProto& from);

  inline StringLocalResourceMapProto& operator=(const StringLocalResourceMapProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StringLocalResourceMapProto& default_instance();

  void Swap(StringLocalResourceMapProto* other);

  // implements Message ----------------------------------------------

  StringLocalResourceMapProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StringLocalResourceMapProto& from);
  void MergeFrom(const StringLocalResourceMapProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string key = 1;
  inline bool has_key() const;
  inline void clear_key();
  static const int kKeyFieldNumber = 1;
  inline const ::std::string& key() const;
  inline void set_key(const ::std::string& value);
  inline void set_key(const char* value);
  inline void set_key(const char* value, size_t size);
  inline ::std::string* mutable_key();
  inline ::std::string* release_key();
  inline void set_allocated_key(::std::string* key);

  // optional .hadoop.yarn.LocalResourceProto value = 2;
  inline bool has_value() const;
  inline void clear_value();
  static const int kValueFieldNumber = 2;
  inline const ::hadoop::yarn::LocalResourceProto& value() const;
  inline ::hadoop::yarn::LocalResourceProto* mutable_value();
  inline ::hadoop::yarn::LocalResourceProto* release_value();
  inline void set_allocated_value(::hadoop::yarn::LocalResourceProto* value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.StringLocalResourceMapProto)
 private:
  inline void set_has_key();
  inline void clear_has_key();
  inline void set_has_value();
  inline void clear_has_value();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::std::string* key_;
  ::hadoop::yarn::LocalResourceProto* value_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static StringLocalResourceMapProto* default_instance_;
};
// -------------------------------------------------------------------

class StringStringMapProto : public ::google::protobuf::Message {
 public:
  StringStringMapProto();
  virtual ~StringStringMapProto();

  StringStringMapProto(const StringStringMapProto& from);

  inline StringStringMapProto& operator=(const StringStringMapProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StringStringMapProto& default_instance();

  void Swap(StringStringMapProto* other);

  // implements Message ----------------------------------------------

  StringStringMapProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StringStringMapProto& from);
  void MergeFrom(const StringStringMapProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string key = 1;
  inline bool has_key() const;
  inline void clear_key();
  static const int kKeyFieldNumber = 1;
  inline const ::std::string& key() const;
  inline void set_key(const ::std::string& value);
  inline void set_key(const char* value);
  inline void set_key(const char* value, size_t size);
  inline ::std::string* mutable_key();
  inline ::std::string* release_key();
  inline void set_allocated_key(::std::string* key);

  // optional string value = 2;
  inline bool has_value() const;
  inline void clear_value();
  static const int kValueFieldNumber = 2;
  inline const ::std::string& value() const;
  inline void set_value(const ::std::string& value);
  inline void set_value(const char* value);
  inline void set_value(const char* value, size_t size);
  inline ::std::string* mutable_value();
  inline ::std::string* release_value();
  inline void set_allocated_value(::std::string* value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.StringStringMapProto)
 private:
  inline void set_has_key();
  inline void clear_has_key();
  inline void set_has_value();
  inline void clear_has_value();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::std::string* key_;
  ::std::string* value_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static StringStringMapProto* default_instance_;
};
// -------------------------------------------------------------------

class StringBytesMapProto : public ::google::protobuf::Message {
 public:
  StringBytesMapProto();
  virtual ~StringBytesMapProto();

  StringBytesMapProto(const StringBytesMapProto& from);

  inline StringBytesMapProto& operator=(const StringBytesMapProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StringBytesMapProto& default_instance();

  void Swap(StringBytesMapProto* other);

  // implements Message ----------------------------------------------

  StringBytesMapProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StringBytesMapProto& from);
  void MergeFrom(const StringBytesMapProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string key = 1;
  inline bool has_key() const;
  inline void clear_key();
  static const int kKeyFieldNumber = 1;
  inline const ::std::string& key() const;
  inline void set_key(const ::std::string& value);
  inline void set_key(const char* value);
  inline void set_key(const char* value, size_t size);
  inline ::std::string* mutable_key();
  inline ::std::string* release_key();
  inline void set_allocated_key(::std::string* key);

  // optional bytes value = 2;
  inline bool has_value() const;
  inline void clear_value();
  static const int kValueFieldNumber = 2;
  inline const ::std::string& value() const;
  inline void set_value(const ::std::string& value);
  inline void set_value(const char* value);
  inline void set_value(const void* value, size_t size);
  inline ::std::string* mutable_value();
  inline ::std::string* release_value();
  inline void set_allocated_value(::std::string* value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.StringBytesMapProto)
 private:
  inline void set_has_key();
  inline void clear_has_key();
  inline void set_has_value();
  inline void clear_has_value();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::std::string* key_;
  ::std::string* value_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static StringBytesMapProto* default_instance_;
};
// ===================================================================


// ===================================================================

// SerializedExceptionProto

// optional string message = 1;
inline bool SerializedExceptionProto::has_message() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void SerializedExceptionProto::set_has_message() {
  _has_bits_[0] |= 0x00000001u;
}
inline void SerializedExceptionProto::clear_has_message() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void SerializedExceptionProto::clear_message() {
  if (message_ != &::google::protobuf::internal::kEmptyString) {
    message_->clear();
  }
  clear_has_message();
}
inline const ::std::string& SerializedExceptionProto::message() const {
  return *message_;
}
inline void SerializedExceptionProto::set_message(const ::std::string& value) {
  set_has_message();
  if (message_ == &::google::protobuf::internal::kEmptyString) {
    message_ = new ::std::string;
  }
  message_->assign(value);
}
inline void SerializedExceptionProto::set_message(const char* value) {
  set_has_message();
  if (message_ == &::google::protobuf::internal::kEmptyString) {
    message_ = new ::std::string;
  }
  message_->assign(value);
}
inline void SerializedExceptionProto::set_message(const char* value, size_t size) {
  set_has_message();
  if (message_ == &::google::protobuf::internal::kEmptyString) {
    message_ = new ::std::string;
  }
  message_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* SerializedExceptionProto::mutable_message() {
  set_has_message();
  if (message_ == &::google::protobuf::internal::kEmptyString) {
    message_ = new ::std::string;
  }
  return message_;
}
inline ::std::string* SerializedExceptionProto::release_message() {
  clear_has_message();
  if (message_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = message_;
    message_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void SerializedExceptionProto::set_allocated_message(::std::string* message) {
  if (message_ != &::google::protobuf::internal::kEmptyString) {
    delete message_;
  }
  if (message) {
    set_has_message();
    message_ = message;
  } else {
    clear_has_message();
    message_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional string trace = 2;
inline bool SerializedExceptionProto::has_trace() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void SerializedExceptionProto::set_has_trace() {
  _has_bits_[0] |= 0x00000002u;
}
inline void SerializedExceptionProto::clear_has_trace() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void SerializedExceptionProto::clear_trace() {
  if (trace_ != &::google::protobuf::internal::kEmptyString) {
    trace_->clear();
  }
  clear_has_trace();
}
inline const ::std::string& SerializedExceptionProto::trace() const {
  return *trace_;
}
inline void SerializedExceptionProto::set_trace(const ::std::string& value) {
  set_has_trace();
  if (trace_ == &::google::protobuf::internal::kEmptyString) {
    trace_ = new ::std::string;
  }
  trace_->assign(value);
}
inline void SerializedExceptionProto::set_trace(const char* value) {
  set_has_trace();
  if (trace_ == &::google::protobuf::internal::kEmptyString) {
    trace_ = new ::std::string;
  }
  trace_->assign(value);
}
inline void SerializedExceptionProto::set_trace(const char* value, size_t size) {
  set_has_trace();
  if (trace_ == &::google::protobuf::internal::kEmptyString) {
    trace_ = new ::std::string;
  }
  trace_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* SerializedExceptionProto::mutable_trace() {
  set_has_trace();
  if (trace_ == &::google::protobuf::internal::kEmptyString) {
    trace_ = new ::std::string;
  }
  return trace_;
}
inline ::std::string* SerializedExceptionProto::release_trace() {
  clear_has_trace();
  if (trace_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = trace_;
    trace_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void SerializedExceptionProto::set_allocated_trace(::std::string* trace) {
  if (trace_ != &::google::protobuf::internal::kEmptyString) {
    delete trace_;
  }
  if (trace) {
    set_has_trace();
    trace_ = trace;
  } else {
    clear_has_trace();
    trace_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional string class_name = 3;
inline bool SerializedExceptionProto::has_class_name() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void SerializedExceptionProto::set_has_class_name() {
  _has_bits_[0] |= 0x00000004u;
}
inline void SerializedExceptionProto::clear_has_class_name() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void SerializedExceptionProto::clear_class_name() {
  if (class_name_ != &::google::protobuf::internal::kEmptyString) {
    class_name_->clear();
  }
  clear_has_class_name();
}
inline const ::std::string& SerializedExceptionProto::class_name() const {
  return *class_name_;
}
inline void SerializedExceptionProto::set_class_name(const ::std::string& value) {
  set_has_class_name();
  if (class_name_ == &::google::protobuf::internal::kEmptyString) {
    class_name_ = new ::std::string;
  }
  class_name_->assign(value);
}
inline void SerializedExceptionProto::set_class_name(const char* value) {
  set_has_class_name();
  if (class_name_ == &::google::protobuf::internal::kEmptyString) {
    class_name_ = new ::std::string;
  }
  class_name_->assign(value);
}
inline void SerializedExceptionProto::set_class_name(const char* value, size_t size) {
  set_has_class_name();
  if (class_name_ == &::google::protobuf::internal::kEmptyString) {
    class_name_ = new ::std::string;
  }
  class_name_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* SerializedExceptionProto::mutable_class_name() {
  set_has_class_name();
  if (class_name_ == &::google::protobuf::internal::kEmptyString) {
    class_name_ = new ::std::string;
  }
  return class_name_;
}
inline ::std::string* SerializedExceptionProto::release_class_name() {
  clear_has_class_name();
  if (class_name_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = class_name_;
    class_name_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void SerializedExceptionProto::set_allocated_class_name(::std::string* class_name) {
  if (class_name_ != &::google::protobuf::internal::kEmptyString) {
    delete class_name_;
  }
  if (class_name) {
    set_has_class_name();
    class_name_ = class_name;
  } else {
    clear_has_class_name();
    class_name_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional .hadoop.yarn.SerializedExceptionProto cause = 4;
inline bool SerializedExceptionProto::has_cause() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void SerializedExceptionProto::set_has_cause() {
  _has_bits_[0] |= 0x00000008u;
}
inline void SerializedExceptionProto::clear_has_cause() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void SerializedExceptionProto::clear_cause() {
  if (cause_ != NULL) cause_->::hadoop::yarn::SerializedExceptionProto::Clear();
  clear_has_cause();
}
inline const ::hadoop::yarn::SerializedExceptionProto& SerializedExceptionProto::cause() const {
  return cause_ != NULL ? *cause_ : *default_instance_->cause_;
}
inline ::hadoop::yarn::SerializedExceptionProto* SerializedExceptionProto::mutable_cause() {
  set_has_cause();
  if (cause_ == NULL) cause_ = new ::hadoop::yarn::SerializedExceptionProto;
  return cause_;
}
inline ::hadoop::yarn::SerializedExceptionProto* SerializedExceptionProto::release_cause() {
  clear_has_cause();
  ::hadoop::yarn::SerializedExceptionProto* temp = cause_;
  cause_ = NULL;
  return temp;
}
inline void SerializedExceptionProto::set_allocated_cause(::hadoop::yarn::SerializedExceptionProto* cause) {
  delete cause_;
  cause_ = cause;
  if (cause) {
    set_has_cause();
  } else {
    clear_has_cause();
  }
}

// -------------------------------------------------------------------

// ApplicationIdProto

// optional int32 id = 1;
inline bool ApplicationIdProto::has_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ApplicationIdProto::set_has_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ApplicationIdProto::clear_has_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ApplicationIdProto::clear_id() {
  id_ = 0;
  clear_has_id();
}
inline ::google::protobuf::int32 ApplicationIdProto::id() const {
  return id_;
}
inline void ApplicationIdProto::set_id(::google::protobuf::int32 value) {
  set_has_id();
  id_ = value;
}

// optional int64 cluster_timestamp = 2;
inline bool ApplicationIdProto::has_cluster_timestamp() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ApplicationIdProto::set_has_cluster_timestamp() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ApplicationIdProto::clear_has_cluster_timestamp() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ApplicationIdProto::clear_cluster_timestamp() {
  cluster_timestamp_ = GOOGLE_LONGLONG(0);
  clear_has_cluster_timestamp();
}
inline ::google::protobuf::int64 ApplicationIdProto::cluster_timestamp() const {
  return cluster_timestamp_;
}
inline void ApplicationIdProto::set_cluster_timestamp(::google::protobuf::int64 value) {
  set_has_cluster_timestamp();
  cluster_timestamp_ = value;
}

// -------------------------------------------------------------------

// ApplicationAttemptIdProto

// optional .hadoop.yarn.ApplicationIdProto application_id = 1;
inline bool ApplicationAttemptIdProto::has_application_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ApplicationAttemptIdProto::set_has_application_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ApplicationAttemptIdProto::clear_has_application_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ApplicationAttemptIdProto::clear_application_id() {
  if (application_id_ != NULL) application_id_->::hadoop::yarn::ApplicationIdProto::Clear();
  clear_has_application_id();
}
inline const ::hadoop::yarn::ApplicationIdProto& ApplicationAttemptIdProto::application_id() const {
  return application_id_ != NULL ? *application_id_ : *default_instance_->application_id_;
}
inline ::hadoop::yarn::ApplicationIdProto* ApplicationAttemptIdProto::mutable_application_id() {
  set_has_application_id();
  if (application_id_ == NULL) application_id_ = new ::hadoop::yarn::ApplicationIdProto;
  return application_id_;
}
inline ::hadoop::yarn::ApplicationIdProto* ApplicationAttemptIdProto::release_application_id() {
  clear_has_application_id();
  ::hadoop::yarn::ApplicationIdProto* temp = application_id_;
  application_id_ = NULL;
  return temp;
}
inline void ApplicationAttemptIdProto::set_allocated_application_id(::hadoop::yarn::ApplicationIdProto* application_id) {
  delete application_id_;
  application_id_ = application_id;
  if (application_id) {
    set_has_application_id();
  } else {
    clear_has_application_id();
  }
}

// optional int32 attemptId = 2;
inline bool ApplicationAttemptIdProto::has_attemptid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ApplicationAttemptIdProto::set_has_attemptid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ApplicationAttemptIdProto::clear_has_attemptid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ApplicationAttemptIdProto::clear_attemptid() {
  attemptid_ = 0;
  clear_has_attemptid();
}
inline ::google::protobuf::int32 ApplicationAttemptIdProto::attemptid() const {
  return attemptid_;
}
inline void ApplicationAttemptIdProto::set_attemptid(::google::protobuf::int32 value) {
  set_has_attemptid();
  attemptid_ = value;
}

// -------------------------------------------------------------------

// ContainerIdProto

// optional .hadoop.yarn.ApplicationIdProto app_id = 1;
inline bool ContainerIdProto::has_app_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ContainerIdProto::set_has_app_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ContainerIdProto::clear_has_app_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ContainerIdProto::clear_app_id() {
  if (app_id_ != NULL) app_id_->::hadoop::yarn::ApplicationIdProto::Clear();
  clear_has_app_id();
}
inline const ::hadoop::yarn::ApplicationIdProto& ContainerIdProto::app_id() const {
  return app_id_ != NULL ? *app_id_ : *default_instance_->app_id_;
}
inline ::hadoop::yarn::ApplicationIdProto* ContainerIdProto::mutable_app_id() {
  set_has_app_id();
  if (app_id_ == NULL) app_id_ = new ::hadoop::yarn::ApplicationIdProto;
  return app_id_;
}
inline ::hadoop::yarn::ApplicationIdProto* ContainerIdProto::release_app_id() {
  clear_has_app_id();
  ::hadoop::yarn::ApplicationIdProto* temp = app_id_;
  app_id_ = NULL;
  return temp;
}
inline void ContainerIdProto::set_allocated_app_id(::hadoop::yarn::ApplicationIdProto* app_id) {
  delete app_id_;
  app_id_ = app_id;
  if (app_id) {
    set_has_app_id();
  } else {
    clear_has_app_id();
  }
}

// optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;
inline bool ContainerIdProto::has_app_attempt_id() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ContainerIdProto::set_has_app_attempt_id() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ContainerIdProto::clear_has_app_attempt_id() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ContainerIdProto::clear_app_attempt_id() {
  if (app_attempt_id_ != NULL) app_attempt_id_->::hadoop::yarn::ApplicationAttemptIdProto::Clear();
  clear_has_app_attempt_id();
}
inline const ::hadoop::yarn::ApplicationAttemptIdProto& ContainerIdProto::app_attempt_id() const {
  return app_attempt_id_ != NULL ? *app_attempt_id_ : *default_instance_->app_attempt_id_;
}
inline ::hadoop::yarn::ApplicationAttemptIdProto* ContainerIdProto::mutable_app_attempt_id() {
  set_has_app_attempt_id();
  if (app_attempt_id_ == NULL) app_attempt_id_ = new ::hadoop::yarn::ApplicationAttemptIdProto;
  return app_attempt_id_;
}
inline ::hadoop::yarn::ApplicationAttemptIdProto* ContainerIdProto::release_app_attempt_id() {
  clear_has_app_attempt_id();
  ::hadoop::yarn::ApplicationAttemptIdProto* temp = app_attempt_id_;
  app_attempt_id_ = NULL;
  return temp;
}
inline void ContainerIdProto::set_allocated_app_attempt_id(::hadoop::yarn::ApplicationAttemptIdProto* app_attempt_id) {
  delete app_attempt_id_;
  app_attempt_id_ = app_attempt_id;
  if (app_attempt_id) {
    set_has_app_attempt_id();
  } else {
    clear_has_app_attempt_id();
  }
}

// optional int32 id = 3;
inline bool ContainerIdProto::has_id() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ContainerIdProto::set_has_id() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ContainerIdProto::clear_has_id() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ContainerIdProto::clear_id() {
  id_ = 0;
  clear_has_id();
}
inline ::google::protobuf::int32 ContainerIdProto::id() const {
  return id_;
}
inline void ContainerIdProto::set_id(::google::protobuf::int32 value) {
  set_has_id();
  id_ = value;
}

// -------------------------------------------------------------------

// ResourceProto

// optional int32 memory = 1;
inline bool ResourceProto::has_memory() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ResourceProto::set_has_memory() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ResourceProto::clear_has_memory() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ResourceProto::clear_memory() {
  memory_ = 0;
  clear_has_memory();
}
inline ::google::protobuf::int32 ResourceProto::memory() const {
  return memory_;
}
inline void ResourceProto::set_memory(::google::protobuf::int32 value) {
  set_has_memory();
  memory_ = value;
}

// optional int32 virtual_cores = 2;
inline bool ResourceProto::has_virtual_cores() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ResourceProto::set_has_virtual_cores() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ResourceProto::clear_has_virtual_cores() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ResourceProto::clear_virtual_cores() {
  virtual_cores_ = 0;
  clear_has_virtual_cores();
}
inline ::google::protobuf::int32 ResourceProto::virtual_cores() const {
  return virtual_cores_;
}
inline void ResourceProto::set_virtual_cores(::google::protobuf::int32 value) {
  set_has_virtual_cores();
  virtual_cores_ = value;
}

// -------------------------------------------------------------------

// ResourceOptionProto

// optional .hadoop.yarn.ResourceProto resource = 1;
inline bool ResourceOptionProto::has_resource() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ResourceOptionProto::set_has_resource() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ResourceOptionProto::clear_has_resource() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ResourceOptionProto::clear_resource() {
  if (resource_ != NULL) resource_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_resource();
}
inline const ::hadoop::yarn::ResourceProto& ResourceOptionProto::resource() const {
  return resource_ != NULL ? *resource_ : *default_instance_->resource_;
}
inline ::hadoop::yarn::ResourceProto* ResourceOptionProto::mutable_resource() {
  set_has_resource();
  if (resource_ == NULL) resource_ = new ::hadoop::yarn::ResourceProto;
  return resource_;
}
inline ::hadoop::yarn::ResourceProto* ResourceOptionProto::release_resource() {
  clear_has_resource();
  ::hadoop::yarn::ResourceProto* temp = resource_;
  resource_ = NULL;
  return temp;
}
inline void ResourceOptionProto::set_allocated_resource(::hadoop::yarn::ResourceProto* resource) {
  delete resource_;
  resource_ = resource;
  if (resource) {
    set_has_resource();
  } else {
    clear_has_resource();
  }
}

// optional int32 over_commit_timeout = 2;
inline bool ResourceOptionProto::has_over_commit_timeout() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ResourceOptionProto::set_has_over_commit_timeout() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ResourceOptionProto::clear_has_over_commit_timeout() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ResourceOptionProto::clear_over_commit_timeout() {
  over_commit_timeout_ = 0;
  clear_has_over_commit_timeout();
}
inline ::google::protobuf::int32 ResourceOptionProto::over_commit_timeout() const {
  return over_commit_timeout_;
}
inline void ResourceOptionProto::set_over_commit_timeout(::google::protobuf::int32 value) {
  set_has_over_commit_timeout();
  over_commit_timeout_ = value;
}

// -------------------------------------------------------------------

// NodeResourceMapProto

// optional .hadoop.yarn.NodeIdProto node_id = 1;
inline bool NodeResourceMapProto::has_node_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void NodeResourceMapProto::set_has_node_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void NodeResourceMapProto::clear_has_node_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void NodeResourceMapProto::clear_node_id() {
  if (node_id_ != NULL) node_id_->::hadoop::yarn::NodeIdProto::Clear();
  clear_has_node_id();
}
inline const ::hadoop::yarn::NodeIdProto& NodeResourceMapProto::node_id() const {
  return node_id_ != NULL ? *node_id_ : *default_instance_->node_id_;
}
inline ::hadoop::yarn::NodeIdProto* NodeResourceMapProto::mutable_node_id() {
  set_has_node_id();
  if (node_id_ == NULL) node_id_ = new ::hadoop::yarn::NodeIdProto;
  return node_id_;
}
inline ::hadoop::yarn::NodeIdProto* NodeResourceMapProto::release_node_id() {
  clear_has_node_id();
  ::hadoop::yarn::NodeIdProto* temp = node_id_;
  node_id_ = NULL;
  return temp;
}
inline void NodeResourceMapProto::set_allocated_node_id(::hadoop::yarn::NodeIdProto* node_id) {
  delete node_id_;
  node_id_ = node_id;
  if (node_id) {
    set_has_node_id();
  } else {
    clear_has_node_id();
  }
}

// optional .hadoop.yarn.ResourceOptionProto resource_option = 2;
inline bool NodeResourceMapProto::has_resource_option() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void NodeResourceMapProto::set_has_resource_option() {
  _has_bits_[0] |= 0x00000002u;
}
inline void NodeResourceMapProto::clear_has_resource_option() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void NodeResourceMapProto::clear_resource_option() {
  if (resource_option_ != NULL) resource_option_->::hadoop::yarn::ResourceOptionProto::Clear();
  clear_has_resource_option();
}
inline const ::hadoop::yarn::ResourceOptionProto& NodeResourceMapProto::resource_option() const {
  return resource_option_ != NULL ? *resource_option_ : *default_instance_->resource_option_;
}
inline ::hadoop::yarn::ResourceOptionProto* NodeResourceMapProto::mutable_resource_option() {
  set_has_resource_option();
  if (resource_option_ == NULL) resource_option_ = new ::hadoop::yarn::ResourceOptionProto;
  return resource_option_;
}
inline ::hadoop::yarn::ResourceOptionProto* NodeResourceMapProto::release_resource_option() {
  clear_has_resource_option();
  ::hadoop::yarn::ResourceOptionProto* temp = resource_option_;
  resource_option_ = NULL;
  return temp;
}
inline void NodeResourceMapProto::set_allocated_resource_option(::hadoop::yarn::ResourceOptionProto* resource_option) {
  delete resource_option_;
  resource_option_ = resource_option;
  if (resource_option) {
    set_has_resource_option();
  } else {
    clear_has_resource_option();
  }
}

// -------------------------------------------------------------------

// PriorityProto

// optional int32 priority = 1;
inline bool PriorityProto::has_priority() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void PriorityProto::set_has_priority() {
  _has_bits_[0] |= 0x00000001u;
}
inline void PriorityProto::clear_has_priority() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void PriorityProto::clear_priority() {
  priority_ = 0;
  clear_has_priority();
}
inline ::google::protobuf::int32 PriorityProto::priority() const {
  return priority_;
}
inline void PriorityProto::set_priority(::google::protobuf::int32 value) {
  set_has_priority();
  priority_ = value;
}

// -------------------------------------------------------------------

// ContainerProto

// optional .hadoop.yarn.ContainerIdProto id = 1;
inline bool ContainerProto::has_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ContainerProto::set_has_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ContainerProto::clear_has_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ContainerProto::clear_id() {
  if (id_ != NULL) id_->::hadoop::yarn::ContainerIdProto::Clear();
  clear_has_id();
}
inline const ::hadoop::yarn::ContainerIdProto& ContainerProto::id() const {
  return id_ != NULL ? *id_ : *default_instance_->id_;
}
inline ::hadoop::yarn::ContainerIdProto* ContainerProto::mutable_id() {
  set_has_id();
  if (id_ == NULL) id_ = new ::hadoop::yarn::ContainerIdProto;
  return id_;
}
inline ::hadoop::yarn::ContainerIdProto* ContainerProto::release_id() {
  clear_has_id();
  ::hadoop::yarn::ContainerIdProto* temp = id_;
  id_ = NULL;
  return temp;
}
inline void ContainerProto::set_allocated_id(::hadoop::yarn::ContainerIdProto* id) {
  delete id_;
  id_ = id;
  if (id) {
    set_has_id();
  } else {
    clear_has_id();
  }
}

// optional .hadoop.yarn.NodeIdProto nodeId = 2;
inline bool ContainerProto::has_nodeid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ContainerProto::set_has_nodeid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ContainerProto::clear_has_nodeid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ContainerProto::clear_nodeid() {
  if (nodeid_ != NULL) nodeid_->::hadoop::yarn::NodeIdProto::Clear();
  clear_has_nodeid();
}
inline const ::hadoop::yarn::NodeIdProto& ContainerProto::nodeid() const {
  return nodeid_ != NULL ? *nodeid_ : *default_instance_->nodeid_;
}
inline ::hadoop::yarn::NodeIdProto* ContainerProto::mutable_nodeid() {
  set_has_nodeid();
  if (nodeid_ == NULL) nodeid_ = new ::hadoop::yarn::NodeIdProto;
  return nodeid_;
}
inline ::hadoop::yarn::NodeIdProto* ContainerProto::release_nodeid() {
  clear_has_nodeid();
  ::hadoop::yarn::NodeIdProto* temp = nodeid_;
  nodeid_ = NULL;
  return temp;
}
inline void ContainerProto::set_allocated_nodeid(::hadoop::yarn::NodeIdProto* nodeid) {
  delete nodeid_;
  nodeid_ = nodeid;
  if (nodeid) {
    set_has_nodeid();
  } else {
    clear_has_nodeid();
  }
}

// optional string node_http_address = 3;
inline bool ContainerProto::has_node_http_address() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ContainerProto::set_has_node_http_address() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ContainerProto::clear_has_node_http_address() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ContainerProto::clear_node_http_address() {
  if (node_http_address_ != &::google::protobuf::internal::kEmptyString) {
    node_http_address_->clear();
  }
  clear_has_node_http_address();
}
inline const ::std::string& ContainerProto::node_http_address() const {
  return *node_http_address_;
}
inline void ContainerProto::set_node_http_address(const ::std::string& value) {
  set_has_node_http_address();
  if (node_http_address_ == &::google::protobuf::internal::kEmptyString) {
    node_http_address_ = new ::std::string;
  }
  node_http_address_->assign(value);
}
inline void ContainerProto::set_node_http_address(const char* value) {
  set_has_node_http_address();
  if (node_http_address_ == &::google::protobuf::internal::kEmptyString) {
    node_http_address_ = new ::std::string;
  }
  node_http_address_->assign(value);
}
inline void ContainerProto::set_node_http_address(const char* value, size_t size) {
  set_has_node_http_address();
  if (node_http_address_ == &::google::protobuf::internal::kEmptyString) {
    node_http_address_ = new ::std::string;
  }
  node_http_address_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ContainerProto::mutable_node_http_address() {
  set_has_node_http_address();
  if (node_http_address_ == &::google::protobuf::internal::kEmptyString) {
    node_http_address_ = new ::std::string;
  }
  return node_http_address_;
}
inline ::std::string* ContainerProto::release_node_http_address() {
  clear_has_node_http_address();
  if (node_http_address_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = node_http_address_;
    node_http_address_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void ContainerProto::set_allocated_node_http_address(::std::string* node_http_address) {
  if (node_http_address_ != &::google::protobuf::internal::kEmptyString) {
    delete node_http_address_;
  }
  if (node_http_address) {
    set_has_node_http_address();
    node_http_address_ = node_http_address;
  } else {
    clear_has_node_http_address();
    node_http_address_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional .hadoop.yarn.ResourceProto resource = 4;
inline bool ContainerProto::has_resource() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ContainerProto::set_has_resource() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ContainerProto::clear_has_resource() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ContainerProto::clear_resource() {
  if (resource_ != NULL) resource_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_resource();
}
inline const ::hadoop::yarn::ResourceProto& ContainerProto::resource() const {
  return resource_ != NULL ? *resource_ : *default_instance_->resource_;
}
inline ::hadoop::yarn::ResourceProto* ContainerProto::mutable_resource() {
  set_has_resource();
  if (resource_ == NULL) resource_ = new ::hadoop::yarn::ResourceProto;
  return resource_;
}
inline ::hadoop::yarn::ResourceProto* ContainerProto::release_resource() {
  clear_has_resource();
  ::hadoop::yarn::ResourceProto* temp = resource_;
  resource_ = NULL;
  return temp;
}
inline void ContainerProto::set_allocated_resource(::hadoop::yarn::ResourceProto* resource) {
  delete resource_;
  resource_ = resource;
  if (resource) {
    set_has_resource();
  } else {
    clear_has_resource();
  }
}

// optional .hadoop.yarn.PriorityProto priority = 5;
inline bool ContainerProto::has_priority() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void ContainerProto::set_has_priority() {
  _has_bits_[0] |= 0x00000010u;
}
inline void ContainerProto::clear_has_priority() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void ContainerProto::clear_priority() {
  if (priority_ != NULL) priority_->::hadoop::yarn::PriorityProto::Clear();
  clear_has_priority();
}
inline const ::hadoop::yarn::PriorityProto& ContainerProto::priority() const {
  return priority_ != NULL ? *priority_ : *default_instance_->priority_;
}
inline ::hadoop::yarn::PriorityProto* ContainerProto::mutable_priority() {
  set_has_priority();
  if (priority_ == NULL) priority_ = new ::hadoop::yarn::PriorityProto;
  return priority_;
}
inline ::hadoop::yarn::PriorityProto* ContainerProto::release_priority() {
  clear_has_priority();
  ::hadoop::yarn::PriorityProto* temp = priority_;
  priority_ = NULL;
  return temp;
}
inline void ContainerProto::set_allocated_priority(::hadoop::yarn::PriorityProto* priority) {
  delete priority_;
  priority_ = priority;
  if (priority) {
    set_has_priority();
  } else {
    clear_has_priority();
  }
}

// optional .hadoop.common.TokenProto container_token = 6;
inline bool ContainerProto::has_container_token() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void ContainerProto::set_has_container_token() {
  _has_bits_[0] |= 0x00000020u;
}
inline void ContainerProto::clear_has_container_token() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void ContainerProto::clear_container_token() {
  if (container_token_ != NULL) container_token_->::hadoop::common::TokenProto::Clear();
  clear_has_container_token();
}
inline const ::hadoop::common::TokenProto& ContainerProto::container_token() const {
  return container_token_ != NULL ? *container_token_ : *default_instance_->container_token_;
}
inline ::hadoop::common::TokenProto* ContainerProto::mutable_container_token() {
  set_has_container_token();
  if (container_token_ == NULL) container_token_ = new ::hadoop::common::TokenProto;
  return container_token_;
}
inline ::hadoop::common::TokenProto* ContainerProto::release_container_token() {
  clear_has_container_token();
  ::hadoop::common::TokenProto* temp = container_token_;
  container_token_ = NULL;
  return temp;
}
inline void ContainerProto::set_allocated_container_token(::hadoop::common::TokenProto* container_token) {
  delete container_token_;
  container_token_ = container_token;
  if (container_token) {
    set_has_container_token();
  } else {
    clear_has_container_token();
  }
}

// -------------------------------------------------------------------

// URLProto

// optional string scheme = 1;
inline bool URLProto::has_scheme() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void URLProto::set_has_scheme() {
  _has_bits_[0] |= 0x00000001u;
}
inline void URLProto::clear_has_scheme() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void URLProto::clear_scheme() {
  if (scheme_ != &::google::protobuf::internal::kEmptyString) {
    scheme_->clear();
  }
  clear_has_scheme();
}
inline const ::std::string& URLProto::scheme() const {
  return *scheme_;
}
inline void URLProto::set_scheme(const ::std::string& value) {
  set_has_scheme();
  if (scheme_ == &::google::protobuf::internal::kEmptyString) {
    scheme_ = new ::std::string;
  }
  scheme_->assign(value);
}
inline void URLProto::set_scheme(const char* value) {
  set_has_scheme();
  if (scheme_ == &::google::protobuf::internal::kEmptyString) {
    scheme_ = new ::std::string;
  }
  scheme_->assign(value);
}
inline void URLProto::set_scheme(const char* value, size_t size) {
  set_has_scheme();
  if (scheme_ == &::google::protobuf::internal::kEmptyString) {
    scheme_ = new ::std::string;
  }
  scheme_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* URLProto::mutable_scheme() {
  set_has_scheme();
  if (scheme_ == &::google::protobuf::internal::kEmptyString) {
    scheme_ = new ::std::string;
  }
  return scheme_;
}
inline ::std::string* URLProto::release_scheme() {
  clear_has_scheme();
  if (scheme_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = scheme_;
    scheme_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void URLProto::set_allocated_scheme(::std::string* scheme) {
  if (scheme_ != &::google::protobuf::internal::kEmptyString) {
    delete scheme_;
  }
  if (scheme) {
    set_has_scheme();
    scheme_ = scheme;
  } else {
    clear_has_scheme();
    scheme_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional string host = 2;
inline bool URLProto::has_host() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void URLProto::set_has_host() {
  _has_bits_[0] |= 0x00000002u;
}
inline void URLProto::clear_has_host() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void URLProto::clear_host() {
  if (host_ != &::google::protobuf::internal::kEmptyString) {
    host_->clear();
  }
  clear_has_host();
}
inline const ::std::string& URLProto::host() const {
  return *host_;
}
inline void URLProto::set_host(const ::std::string& value) {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  host_->assign(value);
}
inline void URLProto::set_host(const char* value) {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  host_->assign(value);
}
inline void URLProto::set_host(const char* value, size_t size) {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  host_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* URLProto::mutable_host() {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  return host_;
}
inline ::std::string* URLProto::release_host() {
  clear_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = host_;
    host_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void URLProto::set_allocated_host(::std::string* host) {
  if (host_ != &::google::protobuf::internal::kEmptyString) {
    delete host_;
  }
  if (host) {
    set_has_host();
    host_ = host;
  } else {
    clear_has_host();
    host_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional int32 port = 3;
inline bool URLProto::has_port() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void URLProto::set_has_port() {
  _has_bits_[0] |= 0x00000004u;
}
inline void URLProto::clear_has_port() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void URLProto::clear_port() {
  port_ = 0;
  clear_has_port();
}
inline ::google::protobuf::int32 URLProto::port() const {
  return port_;
}
inline void URLProto::set_port(::google::protobuf::int32 value) {
  set_has_port();
  port_ = value;
}

// optional string file = 4;
inline bool URLProto::has_file() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void URLProto::set_has_file() {
  _has_bits_[0] |= 0x00000008u;
}
inline void URLProto::clear_has_file() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void URLProto::clear_file() {
  if (file_ != &::google::protobuf::internal::kEmptyString) {
    file_->clear();
  }
  clear_has_file();
}
inline const ::std::string& URLProto::file() const {
  return *file_;
}
inline void URLProto::set_file(const ::std::string& value) {
  set_has_file();
  if (file_ == &::google::protobuf::internal::kEmptyString) {
    file_ = new ::std::string;
  }
  file_->assign(value);
}
inline void URLProto::set_file(const char* value) {
  set_has_file();
  if (file_ == &::google::protobuf::internal::kEmptyString) {
    file_ = new ::std::string;
  }
  file_->assign(value);
}
inline void URLProto::set_file(const char* value, size_t size) {
  set_has_file();
  if (file_ == &::google::protobuf::internal::kEmptyString) {
    file_ = new ::std::string;
  }
  file_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* URLProto::mutable_file() {
  set_has_file();
  if (file_ == &::google::protobuf::internal::kEmptyString) {
    file_ = new ::std::string;
  }
  return file_;
}
inline ::std::string* URLProto::release_file() {
  clear_has_file();
  if (file_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = file_;
    file_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void URLProto::set_allocated_file(::std::string* file) {
  if (file_ != &::google::protobuf::internal::kEmptyString) {
    delete file_;
  }
  if (file) {
    set_has_file();
    file_ = file;
  } else {
    clear_has_file();
    file_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional string userInfo = 5;
inline bool URLProto::has_userinfo() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void URLProto::set_has_userinfo() {
  _has_bits_[0] |= 0x00000010u;
}
inline void URLProto::clear_has_userinfo() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void URLProto::clear_userinfo() {
  if (userinfo_ != &::google::protobuf::internal::kEmptyString) {
    userinfo_->clear();
  }
  clear_has_userinfo();
}
inline const ::std::string& URLProto::userinfo() const {
  return *userinfo_;
}
inline void URLProto::set_userinfo(const ::std::string& value) {
  set_has_userinfo();
  if (userinfo_ == &::google::protobuf::internal::kEmptyString) {
    userinfo_ = new ::std::string;
  }
  userinfo_->assign(value);
}
inline void URLProto::set_userinfo(const char* value) {
  set_has_userinfo();
  if (userinfo_ == &::google::protobuf::internal::kEmptyString) {
    userinfo_ = new ::std::string;
  }
  userinfo_->assign(value);
}
inline void URLProto::set_userinfo(const char* value, size_t size) {
  set_has_userinfo();
  if (userinfo_ == &::google::protobuf::internal::kEmptyString) {
    userinfo_ = new ::std::string;
  }
  userinfo_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* URLProto::mutable_userinfo() {
  set_has_userinfo();
  if (userinfo_ == &::google::protobuf::internal::kEmptyString) {
    userinfo_ = new ::std::string;
  }
  return userinfo_;
}
inline ::std::string* URLProto::release_userinfo() {
  clear_has_userinfo();
  if (userinfo_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = userinfo_;
    userinfo_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void URLProto::set_allocated_userinfo(::std::string* userinfo) {
  if (userinfo_ != &::google::protobuf::internal::kEmptyString) {
    delete userinfo_;
  }
  if (userinfo) {
    set_has_userinfo();
    userinfo_ = userinfo;
  } else {
    clear_has_userinfo();
    userinfo_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// -------------------------------------------------------------------

// LocalResourceProto

// optional .hadoop.yarn.URLProto resource = 1;
inline bool LocalResourceProto::has_resource() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void LocalResourceProto::set_has_resource() {
  _has_bits_[0] |= 0x00000001u;
}
inline void LocalResourceProto::clear_has_resource() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void LocalResourceProto::clear_resource() {
  if (resource_ != NULL) resource_->::hadoop::yarn::URLProto::Clear();
  clear_has_resource();
}
inline const ::hadoop::yarn::URLProto& LocalResourceProto::resource() const {
  return resource_ != NULL ? *resource_ : *default_instance_->resource_;
}
inline ::hadoop::yarn::URLProto* LocalResourceProto::mutable_resource() {
  set_has_resource();
  if (resource_ == NULL) resource_ = new ::hadoop::yarn::URLProto;
  return resource_;
}
inline ::hadoop::yarn::URLProto* LocalResourceProto::release_resource() {
  clear_has_resource();
  ::hadoop::yarn::URLProto* temp = resource_;
  resource_ = NULL;
  return temp;
}
inline void LocalResourceProto::set_allocated_resource(::hadoop::yarn::URLProto* resource) {
  delete resource_;
  resource_ = resource;
  if (resource) {
    set_has_resource();
  } else {
    clear_has_resource();
  }
}

// optional int64 size = 2;
inline bool LocalResourceProto::has_size() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void LocalResourceProto::set_has_size() {
  _has_bits_[0] |= 0x00000002u;
}
inline void LocalResourceProto::clear_has_size() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void LocalResourceProto::clear_size() {
  size_ = GOOGLE_LONGLONG(0);
  clear_has_size();
}
inline ::google::protobuf::int64 LocalResourceProto::size() const {
  return size_;
}
inline void LocalResourceProto::set_size(::google::protobuf::int64 value) {
  set_has_size();
  size_ = value;
}

// optional int64 timestamp = 3;
inline bool LocalResourceProto::has_timestamp() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void LocalResourceProto::set_has_timestamp() {
  _has_bits_[0] |= 0x00000004u;
}
inline void LocalResourceProto::clear_has_timestamp() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void LocalResourceProto::clear_timestamp() {
  timestamp_ = GOOGLE_LONGLONG(0);
  clear_has_timestamp();
}
inline ::google::protobuf::int64 LocalResourceProto::timestamp() const {
  return timestamp_;
}
inline void LocalResourceProto::set_timestamp(::google::protobuf::int64 value) {
  set_has_timestamp();
  timestamp_ = value;
}

// optional .hadoop.yarn.LocalResourceTypeProto type = 4;
inline bool LocalResourceProto::has_type() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void LocalResourceProto::set_has_type() {
  _has_bits_[0] |= 0x00000008u;
}
inline void LocalResourceProto::clear_has_type() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void LocalResourceProto::clear_type() {
  type_ = 1;
  clear_has_type();
}
inline ::hadoop::yarn::LocalResourceTypeProto LocalResourceProto::type() const {
  return static_cast< ::hadoop::yarn::LocalResourceTypeProto >(type_);
}
inline void LocalResourceProto::set_type(::hadoop::yarn::LocalResourceTypeProto value) {
  assert(::hadoop::yarn::LocalResourceTypeProto_IsValid(value));
  set_has_type();
  type_ = value;
}

// optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;
inline bool LocalResourceProto::has_visibility() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void LocalResourceProto::set_has_visibility() {
  _has_bits_[0] |= 0x00000010u;
}
inline void LocalResourceProto::clear_has_visibility() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void LocalResourceProto::clear_visibility() {
  visibility_ = 1;
  clear_has_visibility();
}
inline ::hadoop::yarn::LocalResourceVisibilityProto LocalResourceProto::visibility() const {
  return static_cast< ::hadoop::yarn::LocalResourceVisibilityProto >(visibility_);
}
inline void LocalResourceProto::set_visibility(::hadoop::yarn::LocalResourceVisibilityProto value) {
  assert(::hadoop::yarn::LocalResourceVisibilityProto_IsValid(value));
  set_has_visibility();
  visibility_ = value;
}

// optional string pattern = 6;
inline bool LocalResourceProto::has_pattern() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void LocalResourceProto::set_has_pattern() {
  _has_bits_[0] |= 0x00000020u;
}
inline void LocalResourceProto::clear_has_pattern() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void LocalResourceProto::clear_pattern() {
  if (pattern_ != &::google::protobuf::internal::kEmptyString) {
    pattern_->clear();
  }
  clear_has_pattern();
}
inline const ::std::string& LocalResourceProto::pattern() const {
  return *pattern_;
}
inline void LocalResourceProto::set_pattern(const ::std::string& value) {
  set_has_pattern();
  if (pattern_ == &::google::protobuf::internal::kEmptyString) {
    pattern_ = new ::std::string;
  }
  pattern_->assign(value);
}
inline void LocalResourceProto::set_pattern(const char* value) {
  set_has_pattern();
  if (pattern_ == &::google::protobuf::internal::kEmptyString) {
    pattern_ = new ::std::string;
  }
  pattern_->assign(value);
}
inline void LocalResourceProto::set_pattern(const char* value, size_t size) {
  set_has_pattern();
  if (pattern_ == &::google::protobuf::internal::kEmptyString) {
    pattern_ = new ::std::string;
  }
  pattern_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* LocalResourceProto::mutable_pattern() {
  set_has_pattern();
  if (pattern_ == &::google::protobuf::internal::kEmptyString) {
    pattern_ = new ::std::string;
  }
  return pattern_;
}
inline ::std::string* LocalResourceProto::release_pattern() {
  clear_has_pattern();
  if (pattern_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = pattern_;
    pattern_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void LocalResourceProto::set_allocated_pattern(::std::string* pattern) {
  if (pattern_ != &::google::protobuf::internal::kEmptyString) {
    delete pattern_;
  }
  if (pattern) {
    set_has_pattern();
    pattern_ = pattern;
  } else {
    clear_has_pattern();
    pattern_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// -------------------------------------------------------------------

// ApplicationResourceUsageReportProto

// optional int32 num_used_containers = 1;
inline bool ApplicationResourceUsageReportProto::has_num_used_containers() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ApplicationResourceUsageReportProto::set_has_num_used_containers() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ApplicationResourceUsageReportProto::clear_has_num_used_containers() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ApplicationResourceUsageReportProto::clear_num_used_containers() {
  num_used_containers_ = 0;
  clear_has_num_used_containers();
}
inline ::google::protobuf::int32 ApplicationResourceUsageReportProto::num_used_containers() const {
  return num_used_containers_;
}
inline void ApplicationResourceUsageReportProto::set_num_used_containers(::google::protobuf::int32 value) {
  set_has_num_used_containers();
  num_used_containers_ = value;
}

// optional int32 num_reserved_containers = 2;
inline bool ApplicationResourceUsageReportProto::has_num_reserved_containers() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ApplicationResourceUsageReportProto::set_has_num_reserved_containers() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ApplicationResourceUsageReportProto::clear_has_num_reserved_containers() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ApplicationResourceUsageReportProto::clear_num_reserved_containers() {
  num_reserved_containers_ = 0;
  clear_has_num_reserved_containers();
}
inline ::google::protobuf::int32 ApplicationResourceUsageReportProto::num_reserved_containers() const {
  return num_reserved_containers_;
}
inline void ApplicationResourceUsageReportProto::set_num_reserved_containers(::google::protobuf::int32 value) {
  set_has_num_reserved_containers();
  num_reserved_containers_ = value;
}

// optional .hadoop.yarn.ResourceProto used_resources = 3;
inline bool ApplicationResourceUsageReportProto::has_used_resources() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ApplicationResourceUsageReportProto::set_has_used_resources() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ApplicationResourceUsageReportProto::clear_has_used_resources() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ApplicationResourceUsageReportProto::clear_used_resources() {
  if (used_resources_ != NULL) used_resources_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_used_resources();
}
inline const ::hadoop::yarn::ResourceProto& ApplicationResourceUsageReportProto::used_resources() const {
  return used_resources_ != NULL ? *used_resources_ : *default_instance_->used_resources_;
}
inline ::hadoop::yarn::ResourceProto* ApplicationResourceUsageReportProto::mutable_used_resources() {
  set_has_used_resources();
  if (used_resources_ == NULL) used_resources_ = new ::hadoop::yarn::ResourceProto;
  return used_resources_;
}
inline ::hadoop::yarn::ResourceProto* ApplicationResourceUsageReportProto::release_used_resources() {
  clear_has_used_resources();
  ::hadoop::yarn::ResourceProto* temp = used_resources_;
  used_resources_ = NULL;
  return temp;
}
inline void ApplicationResourceUsageReportProto::set_allocated_used_resources(::hadoop::yarn::ResourceProto* used_resources) {
  delete used_resources_;
  used_resources_ = used_resources;
  if (used_resources) {
    set_has_used_resources();
  } else {
    clear_has_used_resources();
  }
}

// optional .hadoop.yarn.ResourceProto reserved_resources = 4;
inline bool ApplicationResourceUsageReportProto::has_reserved_resources() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ApplicationResourceUsageReportProto::set_has_reserved_resources() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ApplicationResourceUsageReportProto::clear_has_reserved_resources() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ApplicationResourceUsageReportProto::clear_reserved_resources() {
  if (reserved_resources_ != NULL) reserved_resources_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_reserved_resources();
}
inline const ::hadoop::yarn::ResourceProto& ApplicationResourceUsageReportProto::reserved_resources() const {
  return reserved_resources_ != NULL ? *reserved_resources_ : *default_instance_->reserved_resources_;
}
inline ::hadoop::yarn::ResourceProto* ApplicationResourceUsageReportProto::mutable_reserved_resources() {
  set_has_reserved_resources();
  if (reserved_resources_ == NULL) reserved_resources_ = new ::hadoop::yarn::ResourceProto;
  return reserved_resources_;
}
inline ::hadoop::yarn::ResourceProto* ApplicationResourceUsageReportProto::release_reserved_resources() {
  clear_has_reserved_resources();
  ::hadoop::yarn::ResourceProto* temp = reserved_resources_;
  reserved_resources_ = NULL;
  return temp;
}
inline void ApplicationResourceUsageReportProto::set_allocated_reserved_resources(::hadoop::yarn::ResourceProto* reserved_resources) {
  delete reserved_resources_;
  reserved_resources_ = reserved_resources;
  if (reserved_resources) {
    set_has_reserved_resources();
  } else {
    clear_has_reserved_resources();
  }
}

// optional .hadoop.yarn.ResourceProto needed_resources = 5;
inline bool ApplicationResourceUsageReportProto::has_needed_resources() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void ApplicationResourceUsageReportProto::set_has_needed_resources() {
  _has_bits_[0] |= 0x00000010u;
}
inline void ApplicationResourceUsageReportProto::clear_has_needed_resources() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void ApplicationResourceUsageReportProto::clear_needed_resources() {
  if (needed_resources_ != NULL) needed_resources_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_needed_resources();
}
inline const ::hadoop::yarn::ResourceProto& ApplicationResourceUsageReportProto::needed_resources() const {
  return needed_resources_ != NULL ? *needed_resources_ : *default_instance_->needed_resources_;
}
inline ::hadoop::yarn::ResourceProto* ApplicationResourceUsageReportProto::mutable_needed_resources() {
  set_has_needed_resources();
  if (needed_resources_ == NULL) needed_resources_ = new ::hadoop::yarn::ResourceProto;
  return needed_resources_;
}
inline ::hadoop::yarn::ResourceProto* ApplicationResourceUsageReportProto::release_needed_resources() {
  clear_has_needed_resources();
  ::hadoop::yarn::ResourceProto* temp = needed_resources_;
  needed_resources_ = NULL;
  return temp;
}
inline void ApplicationResourceUsageReportProto::set_allocated_needed_resources(::hadoop::yarn::ResourceProto* needed_resources) {
  delete needed_resources_;
  needed_resources_ = needed_resources;
  if (needed_resources) {
    set_has_needed_resources();
  } else {
    clear_has_needed_resources();
  }
}

// -------------------------------------------------------------------

// ApplicationReportProto

// optional .hadoop.yarn.ApplicationIdProto applicationId = 1;
inline bool ApplicationReportProto::has_applicationid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ApplicationReportProto::set_has_applicationid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ApplicationReportProto::clear_has_applicationid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ApplicationReportProto::clear_applicationid() {
  if (applicationid_ != NULL) applicationid_->::hadoop::yarn::ApplicationIdProto::Clear();
  clear_has_applicationid();
}
inline const ::hadoop::yarn::ApplicationIdProto& ApplicationReportProto::applicationid() const {
  return applicationid_ != NULL ? *applicationid_ : *default_instance_->applicationid_;
}
inline ::hadoop::yarn::ApplicationIdProto* ApplicationReportProto::mutable_applicationid() {
  set_has_applicationid();
  if (applicationid_ == NULL) applicationid_ = new ::hadoop::yarn::ApplicationIdProto;
  return applicationid_;
}
inline ::hadoop::yarn::ApplicationIdProto* ApplicationReportProto::release_applicationid() {
  clear_has_applicationid();
  ::hadoop::yarn::ApplicationIdProto* temp = applicationid_;
  applicationid_ = NULL;
  return temp;
}
inline void ApplicationReportProto::set_allocated_applicationid(::hadoop::yarn::ApplicationIdProto* applicationid) {
  delete applicationid_;
  applicationid_ = applicationid;
  if (applicationid) {
    set_has_applicationid();
  } else {
    clear_has_applicationid();
  }
}

// optional string user = 2;
inline bool ApplicationReportProto::has_user() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ApplicationReportProto::set_has_user() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ApplicationReportProto::clear_has_user() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ApplicationReportProto::clear_user() {
  if (user_ != &::google::protobuf::internal::kEmptyString) {
    user_->clear();
  }
  clear_has_user();
}
inline const ::std::string& ApplicationReportProto::user() const {
  return *user_;
}
inline void ApplicationReportProto::set_user(const ::std::string& value) {
  set_has_user();
  if (user_ == &::google::protobuf::internal::kEmptyString) {
    user_ = new ::std::string;
  }
  user_->assign(value);
}
inline void ApplicationReportProto::set_user(const char* value) {
  set_has_user();
  if (user_ == &::google::protobuf::internal::kEmptyString) {
    user_ = new ::std::string;
  }
  user_->assign(value);
}
inline void ApplicationReportProto::set_user(const char* value, size_t size) {
  set_has_user();
  if (user_ == &::google::protobuf::internal::kEmptyString) {
    user_ = new ::std::string;
  }
  user_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ApplicationReportProto::mutable_user() {
  set_has_user();
  if (user_ == &::google::protobuf::internal::kEmptyString) {
    user_ = new ::std::string;
  }
  return user_;
}
inline ::std::string* ApplicationReportProto::release_user() {
  clear_has_user();
  if (user_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = user_;
    user_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void ApplicationReportProto::set_allocated_user(::std::string* user) {
  if (user_ != &::google::protobuf::internal::kEmptyString) {
    delete user_;
  }
  if (user) {
    set_has_user();
    user_ = user;
  } else {
    clear_has_user();
    user_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional string queue = 3;
inline bool ApplicationReportProto::has_queue() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ApplicationReportProto::set_has_queue() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ApplicationReportProto::clear_has_queue() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ApplicationReportProto::clear_queue() {
  if (queue_ != &::google::protobuf::internal::kEmptyString) {
    queue_->clear();
  }
  clear_has_queue();
}
inline const ::std::string& ApplicationReportProto::queue() const {
  return *queue_;
}
inline void ApplicationReportProto::set_queue(const ::std::string& value) {
  set_has_queue();
  if (queue_ == &::google::protobuf::internal::kEmptyString) {
    queue_ = new ::std::string;
  }
  queue_->assign(value);
}
inline void ApplicationReportProto::set_queue(const char* value) {
  set_has_queue();
  if (queue_ == &::google::protobuf::internal::kEmptyString) {
    queue_ = new ::std::string;
  }
  queue_->assign(value);
}
inline void ApplicationReportProto::set_queue(const char* value, size_t size) {
  set_has_queue();
  if (queue_ == &::google::protobuf::internal::kEmptyString) {
    queue_ = new ::std::string;
  }
  queue_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ApplicationReportProto::mutable_queue() {
  set_has_queue();
  if (queue_ == &::google::protobuf::internal::kEmptyString) {
    queue_ = new ::std::string;
  }
  return queue_;
}
inline ::std::string* ApplicationReportProto::release_queue() {
  clear_has_queue();
  if (queue_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = queue_;
    queue_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void ApplicationReportProto::set_allocated_queue(::std::string* queue) {
  if (queue_ != &::google::protobuf::internal::kEmptyString) {
    delete queue_;
  }
  if (queue) {
    set_has_queue();
    queue_ = queue;
  } else {
    clear_has_queue();
    queue_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional string name = 4;
inline bool ApplicationReportProto::has_name() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ApplicationReportProto::set_has_name() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ApplicationReportProto::clear_has_name() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ApplicationReportProto::clear_name() {
  if (name_ != &::google::protobuf::internal::kEmptyString) {
    name_->clear();
  }
  clear_has_name();
}
inline const ::std::string& ApplicationReportProto::name() const {
  return *name_;
}
inline void ApplicationReportProto::set_name(const ::std::string& value) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::kEmptyString) {
    name_ = new ::std::string;
  }
  name_->assign(value);
}
inline void ApplicationReportProto::set_name(const char* value) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::kEmptyString) {
    name_ = new ::std::string;
  }
  name_->assign(value);
}
inline void ApplicationReportProto::set_name(const char* value, size_t size) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::kEmptyString) {
    name_ = new ::std::string;
  }
  name_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ApplicationReportProto::mutable_name() {
  set_has_name();
  if (name_ == &::google::protobuf::internal::kEmptyString) {
    name_ = new ::std::string;
  }
  return name_;
}
inline ::std::string* ApplicationReportProto::release_name() {
  clear_has_name();
  if (name_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = name_;
    name_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void ApplicationReportProto::set_allocated_name(::std::string* name) {
  if (name_ != &::google::protobuf::internal::kEmptyString) {
    delete name_;
  }
  if (name) {
    set_has_name();
    name_ = name;
  } else {
    clear_has_name();
    name_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional string host = 5;
inline bool ApplicationReportProto::has_host() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void ApplicationReportProto::set_has_host() {
  _has_bits_[0] |= 0x00000010u;
}
inline void ApplicationReportProto::clear_has_host() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void ApplicationReportProto::clear_host() {
  if (host_ != &::google::protobuf::internal::kEmptyString) {
    host_->clear();
  }
  clear_has_host();
}
inline const ::std::string& ApplicationReportProto::host() const {
  return *host_;
}
inline void ApplicationReportProto::set_host(const ::std::string& value) {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  host_->assign(value);
}
inline void ApplicationReportProto::set_host(const char* value) {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  host_->assign(value);
}
inline void ApplicationReportProto::set_host(const char* value, size_t size) {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  host_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ApplicationReportProto::mutable_host() {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  return host_;
}
inline ::std::string* ApplicationReportProto::release_host() {
  clear_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = host_;
    host_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void ApplicationReportProto::set_allocated_host(::std::string* host) {
  if (host_ != &::google::protobuf::internal::kEmptyString) {
    delete host_;
  }
  if (host) {
    set_has_host();
    host_ = host;
  } else {
    clear_has_host();
    host_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional int32 rpc_port = 6;
inline bool ApplicationReportProto::has_rpc_port() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void ApplicationReportProto::set_has_rpc_port() {
  _has_bits_[0] |= 0x00000020u;
}
inline void ApplicationReportProto::clear_has_rpc_port() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void ApplicationReportProto::clear_rpc_port() {
  rpc_port_ = 0;
  clear_has_rpc_port();
}
inline ::google::protobuf::int32 ApplicationReportProto::rpc_port() const {
  return rpc_port_;
}
inline void ApplicationReportProto::set_rpc_port(::google::protobuf::int32 value) {
  set_has_rpc_port();
  rpc_port_ = value;
}

// optional .hadoop.common.TokenProto client_to_am_token = 7;
inline bool ApplicationReportProto::has_client_to_am_token() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void ApplicationReportProto::set_has_client_to_am_token() {
  _has_bits_[0] |= 0x00000040u;
}
inline void ApplicationReportProto::clear_has_client_to_am_token() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void ApplicationReportProto::clear_client_to_am_token() {
  if (client_to_am_token_ != NULL) client_to_am_token_->::hadoop::common::TokenProto::Clear();
  clear_has_client_to_am_token();
}
inline const ::hadoop::common::TokenProto& ApplicationReportProto::client_to_am_token() const {
  return client_to_am_token_ != NULL ? *client_to_am_token_ : *default_instance_->client_to_am_token_;
}
inline ::hadoop::common::TokenProto* ApplicationReportProto::mutable_client_to_am_token() {
  set_has_client_to_am_token();
  if (client_to_am_token_ == NULL) client_to_am_token_ = new ::hadoop::common::TokenProto;
  return client_to_am_token_;
}
inline ::hadoop::common::TokenProto* ApplicationReportProto::release_client_to_am_token() {
  clear_has_client_to_am_token();
  ::hadoop::common::TokenProto* temp = client_to_am_token_;
  client_to_am_token_ = NULL;
  return temp;
}
inline void ApplicationReportProto::set_allocated_client_to_am_token(::hadoop::common::TokenProto* client_to_am_token) {
  delete client_to_am_token_;
  client_to_am_token_ = client_to_am_token;
  if (client_to_am_token) {
    set_has_client_to_am_token();
  } else {
    clear_has_client_to_am_token();
  }
}

// optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;
inline bool ApplicationReportProto::has_yarn_application_state() const {
  return (_has_bits_[0] & 0x00000080u) != 0;
}
inline void ApplicationReportProto::set_has_yarn_application_state() {
  _has_bits_[0] |= 0x00000080u;
}
inline void ApplicationReportProto::clear_has_yarn_application_state() {
  _has_bits_[0] &= ~0x00000080u;
}
inline void ApplicationReportProto::clear_yarn_application_state() {
  yarn_application_state_ = 1;
  clear_has_yarn_application_state();
}
inline ::hadoop::yarn::YarnApplicationStateProto ApplicationReportProto::yarn_application_state() const {
  return static_cast< ::hadoop::yarn::YarnApplicationStateProto >(yarn_application_state_);
}
inline void ApplicationReportProto::set_yarn_application_state(::hadoop::yarn::YarnApplicationStateProto value) {
  assert(::hadoop::yarn::YarnApplicationStateProto_IsValid(value));
  set_has_yarn_application_state();
  yarn_application_state_ = value;
}

// optional string trackingUrl = 9;
inline bool ApplicationReportProto::has_trackingurl() const {
  return (_has_bits_[0] & 0x00000100u) != 0;
}
inline void ApplicationReportProto::set_has_trackingurl() {
  _has_bits_[0] |= 0x00000100u;
}
inline void ApplicationReportProto::clear_has_trackingurl() {
  _has_bits_[0] &= ~0x00000100u;
}
inline void ApplicationReportProto::clear_trackingurl() {
  if (trackingurl_ != &::google::protobuf::internal::kEmptyString) {
    trackingurl_->clear();
  }
  clear_has_trackingurl();
}
inline const ::std::string& ApplicationReportProto::trackingurl() const {
  return *trackingurl_;
}
inline void ApplicationReportProto::set_trackingurl(const ::std::string& value) {
  set_has_trackingurl();
  if (trackingurl_ == &::google::protobuf::internal::kEmptyString) {
    trackingurl_ = new ::std::string;
  }
  trackingurl_->assign(value);
}
inline void ApplicationReportProto::set_trackingurl(const char* value) {
  set_has_trackingurl();
  if (trackingurl_ == &::google::protobuf::internal::kEmptyString) {
    trackingurl_ = new ::std::string;
  }
  trackingurl_->assign(value);
}
inline void ApplicationReportProto::set_trackingurl(const char* value, size_t size) {
  set_has_trackingurl();
  if (trackingurl_ == &::google::protobuf::internal::kEmptyString) {
    trackingurl_ = new ::std::string;
  }
  trackingurl_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ApplicationReportProto::mutable_trackingurl() {
  set_has_trackingurl();
  if (trackingurl_ == &::google::protobuf::internal::kEmptyString) {
    trackingurl_ = new ::std::string;
  }
  return trackingurl_;
}
inline ::std::string* ApplicationReportProto::release_trackingurl() {
  clear_has_trackingurl();
  if (trackingurl_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = trackingurl_;
    trackingurl_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void ApplicationReportProto::set_allocated_trackingurl(::std::string* trackingurl) {
  if (trackingurl_ != &::google::protobuf::internal::kEmptyString) {
    delete trackingurl_;
  }
  if (trackingurl) {
    set_has_trackingurl();
    trackingurl_ = trackingurl;
  } else {
    clear_has_trackingurl();
    trackingurl_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional string diagnostics = 10 [default = "N/A"];
inline bool ApplicationReportProto::has_diagnostics() const {
  return (_has_bits_[0] & 0x00000200u) != 0;
}
inline void ApplicationReportProto::set_has_diagnostics() {
  _has_bits_[0] |= 0x00000200u;
}
inline void ApplicationReportProto::clear_has_diagnostics() {
  _has_bits_[0] &= ~0x00000200u;
}
inline void ApplicationReportProto::clear_diagnostics() {
  if (diagnostics_ != _default_diagnostics_) {
    diagnostics_->assign(*_default_diagnostics_);
  }
  clear_has_diagnostics();
}
inline const ::std::string& ApplicationReportProto::diagnostics() const {
  return *diagnostics_;
}
inline void ApplicationReportProto::set_diagnostics(const ::std::string& value) {
  set_has_diagnostics();
  if (diagnostics_ == _default_diagnostics_) {
    diagnostics_ = new ::std::string;
  }
  diagnostics_->assign(value);
}
inline void ApplicationReportProto::set_diagnostics(const char* value) {
  set_has_diagnostics();
  if (diagnostics_ == _default_diagnostics_) {
    diagnostics_ = new ::std::string;
  }
  diagnostics_->assign(value);
}
inline void ApplicationReportProto::set_diagnostics(const char* value, size_t size) {
  set_has_diagnostics();
  if (diagnostics_ == _default_diagnostics_) {
    diagnostics_ = new ::std::string;
  }
  diagnostics_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ApplicationReportProto::mutable_diagnostics() {
  set_has_diagnostics();
  if (diagnostics_ == _default_diagnostics_) {
    diagnostics_ = new ::std::string(*_default_diagnostics_);
  }
  return diagnostics_;
}
inline ::std::string* ApplicationReportProto::release_diagnostics() {
  clear_has_diagnostics();
  if (diagnostics_ == _default_diagnostics_) {
    return NULL;
  } else {
    ::std::string* temp = diagnostics_;
    diagnostics_ = const_cast< ::std::string*>(_default_diagnostics_);
    return temp;
  }
}
inline void ApplicationReportProto::set_allocated_diagnostics(::std::string* diagnostics) {
  if (diagnostics_ != _default_diagnostics_) {
    delete diagnostics_;
  }
  if (diagnostics) {
    set_has_diagnostics();
    diagnostics_ = diagnostics;
  } else {
    clear_has_diagnostics();
    diagnostics_ = const_cast< ::std::string*>(_default_diagnostics_);
  }
}

// optional int64 startTime = 11;
inline bool ApplicationReportProto::has_starttime() const {
  return (_has_bits_[0] & 0x00000400u) != 0;
}
inline void ApplicationReportProto::set_has_starttime() {
  _has_bits_[0] |= 0x00000400u;
}
inline void ApplicationReportProto::clear_has_starttime() {
  _has_bits_[0] &= ~0x00000400u;
}
inline void ApplicationReportProto::clear_starttime() {
  starttime_ = GOOGLE_LONGLONG(0);
  clear_has_starttime();
}
inline ::google::protobuf::int64 ApplicationReportProto::starttime() const {
  return starttime_;
}
inline void ApplicationReportProto::set_starttime(::google::protobuf::int64 value) {
  set_has_starttime();
  starttime_ = value;
}

// optional int64 finishTime = 12;
inline bool ApplicationReportProto::has_finishtime() const {
  return (_has_bits_[0] & 0x00000800u) != 0;
}
inline void ApplicationReportProto::set_has_finishtime() {
  _has_bits_[0] |= 0x00000800u;
}
inline void ApplicationReportProto::clear_has_finishtime() {
  _has_bits_[0] &= ~0x00000800u;
}
inline void ApplicationReportProto::clear_finishtime() {
  finishtime_ = GOOGLE_LONGLONG(0);
  clear_has_finishtime();
}
inline ::google::protobuf::int64 ApplicationReportProto::finishtime() const {
  return finishtime_;
}
inline void ApplicationReportProto::set_finishtime(::google::protobuf::int64 value) {
  set_has_finishtime();
  finishtime_ = value;
}

// optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;
inline bool ApplicationReportProto::has_final_application_status() const {
  return (_has_bits_[0] & 0x00001000u) != 0;
}
inline void ApplicationReportProto::set_has_final_application_status() {
  _has_bits_[0] |= 0x00001000u;
}
inline void ApplicationReportProto::clear_has_final_application_status() {
  _has_bits_[0] &= ~0x00001000u;
}
inline void ApplicationReportProto::clear_final_application_status() {
  final_application_status_ = 0;
  clear_has_final_application_status();
}
inline ::hadoop::yarn::FinalApplicationStatusProto ApplicationReportProto::final_application_status() const {
  return static_cast< ::hadoop::yarn::FinalApplicationStatusProto >(final_application_status_);
}
inline void ApplicationReportProto::set_final_application_status(::hadoop::yarn::FinalApplicationStatusProto value) {
  assert(::hadoop::yarn::FinalApplicationStatusProto_IsValid(value));
  set_has_final_application_status();
  final_application_status_ = value;
}

// optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;
inline bool ApplicationReportProto::has_app_resource_usage() const {
  return (_has_bits_[0] & 0x00002000u) != 0;
}
inline void ApplicationReportProto::set_has_app_resource_usage() {
  _has_bits_[0] |= 0x00002000u;
}
inline void ApplicationReportProto::clear_has_app_resource_usage() {
  _has_bits_[0] &= ~0x00002000u;
}
inline void ApplicationReportProto::clear_app_resource_usage() {
  if (app_resource_usage_ != NULL) app_resource_usage_->::hadoop::yarn::ApplicationResourceUsageReportProto::Clear();
  clear_has_app_resource_usage();
}
inline const ::hadoop::yarn::ApplicationResourceUsageReportProto& ApplicationReportProto::app_resource_usage() const {
  return app_resource_usage_ != NULL ? *app_resource_usage_ : *default_instance_->app_resource_usage_;
}
inline ::hadoop::yarn::ApplicationResourceUsageReportProto* ApplicationReportProto::mutable_app_resource_usage() {
  set_has_app_resource_usage();
  if (app_resource_usage_ == NULL) app_resource_usage_ = new ::hadoop::yarn::ApplicationResourceUsageReportProto;
  return app_resource_usage_;
}
inline ::hadoop::yarn::ApplicationResourceUsageReportProto* ApplicationReportProto::release_app_resource_usage() {
  clear_has_app_resource_usage();
  ::hadoop::yarn::ApplicationResourceUsageReportProto* temp = app_resource_usage_;
  app_resource_usage_ = NULL;
  return temp;
}
inline void ApplicationReportProto::set_allocated_app_resource_usage(::hadoop::yarn::ApplicationResourceUsageReportProto* app_resource_usage) {
  delete app_resource_usage_;
  app_resource_usage_ = app_resource_usage;
  if (app_resource_usage) {
    set_has_app_resource_usage();
  } else {
    clear_has_app_resource_usage();
  }
}

// optional string originalTrackingUrl = 15;
inline bool ApplicationReportProto::has_originaltrackingurl() const {
  return (_has_bits_[0] & 0x00004000u) != 0;
}
inline void ApplicationReportProto::set_has_originaltrackingurl() {
  _has_bits_[0] |= 0x00004000u;
}
inline void ApplicationReportProto::clear_has_originaltrackingurl() {
  _has_bits_[0] &= ~0x00004000u;
}
inline void ApplicationReportProto::clear_originaltrackingurl() {
  if (originaltrackingurl_ != &::google::protobuf::internal::kEmptyString) {
    originaltrackingurl_->clear();
  }
  clear_has_originaltrackingurl();
}
inline const ::std::string& ApplicationReportProto::originaltrackingurl() const {
  return *originaltrackingurl_;
}
inline void ApplicationReportProto::set_originaltrackingurl(const ::std::string& value) {
  set_has_originaltrackingurl();
  if (originaltrackingurl_ == &::google::protobuf::internal::kEmptyString) {
    originaltrackingurl_ = new ::std::string;
  }
  originaltrackingurl_->assign(value);
}
inline void ApplicationReportProto::set_originaltrackingurl(const char* value) {
  set_has_originaltrackingurl();
  if (originaltrackingurl_ == &::google::protobuf::internal::kEmptyString) {
    originaltrackingurl_ = new ::std::string;
  }
  originaltrackingurl_->assign(value);
}
inline void ApplicationReportProto::set_originaltrackingurl(const char* value, size_t size) {
  set_has_originaltrackingurl();
  if (originaltrackingurl_ == &::google::protobuf::internal::kEmptyString) {
    originaltrackingurl_ = new ::std::string;
  }
  originaltrackingurl_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ApplicationReportProto::mutable_originaltrackingurl() {
  set_has_originaltrackingurl();
  if (originaltrackingurl_ == &::google::protobuf::internal::kEmptyString) {
    originaltrackingurl_ = new ::std::string;
  }
  return originaltrackingurl_;
}
inline ::std::string* ApplicationReportProto::release_originaltrackingurl() {
  clear_has_originaltrackingurl();
  if (originaltrackingurl_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = originaltrackingurl_;
    originaltrackingurl_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void ApplicationReportProto::set_allocated_originaltrackingurl(::std::string* originaltrackingurl) {
  if (originaltrackingurl_ != &::google::protobuf::internal::kEmptyString) {
    delete originaltrackingurl_;
  }
  if (originaltrackingurl) {
    set_has_originaltrackingurl();
    originaltrackingurl_ = originaltrackingurl;
  } else {
    clear_has_originaltrackingurl();
    originaltrackingurl_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;
inline bool ApplicationReportProto::has_currentapplicationattemptid() const {
  return (_has_bits_[0] & 0x00008000u) != 0;
}
inline void ApplicationReportProto::set_has_currentapplicationattemptid() {
  _has_bits_[0] |= 0x00008000u;
}
inline void ApplicationReportProto::clear_has_currentapplicationattemptid() {
  _has_bits_[0] &= ~0x00008000u;
}
inline void ApplicationReportProto::clear_currentapplicationattemptid() {
  if (currentapplicationattemptid_ != NULL) currentapplicationattemptid_->::hadoop::yarn::ApplicationAttemptIdProto::Clear();
  clear_has_currentapplicationattemptid();
}
inline const ::hadoop::yarn::ApplicationAttemptIdProto& ApplicationReportProto::currentapplicationattemptid() const {
  return currentapplicationattemptid_ != NULL ? *currentapplicationattemptid_ : *default_instance_->currentapplicationattemptid_;
}
inline ::hadoop::yarn::ApplicationAttemptIdProto* ApplicationReportProto::mutable_currentapplicationattemptid() {
  set_has_currentapplicationattemptid();
  if (currentapplicationattemptid_ == NULL) currentapplicationattemptid_ = new ::hadoop::yarn::ApplicationAttemptIdProto;
  return currentapplicationattemptid_;
}
inline ::hadoop::yarn::ApplicationAttemptIdProto* ApplicationReportProto::release_currentapplicationattemptid() {
  clear_has_currentapplicationattemptid();
  ::hadoop::yarn::ApplicationAttemptIdProto* temp = currentapplicationattemptid_;
  currentapplicationattemptid_ = NULL;
  return temp;
}
inline void ApplicationReportProto::set_allocated_currentapplicationattemptid(::hadoop::yarn::ApplicationAttemptIdProto* currentapplicationattemptid) {
  delete currentapplicationattemptid_;
  currentapplicationattemptid_ = currentapplicationattemptid;
  if (currentapplicationattemptid) {
    set_has_currentapplicationattemptid();
  } else {
    clear_has_currentapplicationattemptid();
  }
}

// optional float progress = 17;
inline bool ApplicationReportProto::has_progress() const {
  return (_has_bits_[0] & 0x00010000u) != 0;
}
inline void ApplicationReportProto::set_has_progress() {
  _has_bits_[0] |= 0x00010000u;
}
inline void ApplicationReportProto::clear_has_progress() {
  _has_bits_[0] &= ~0x00010000u;
}
inline void ApplicationReportProto::clear_progress() {
  progress_ = 0;
  clear_has_progress();
}
inline float ApplicationReportProto::progress() const {
  return progress_;
}
inline void ApplicationReportProto::set_progress(float value) {
  set_has_progress();
  progress_ = value;
}

// optional string applicationType = 18;
inline bool ApplicationReportProto::has_applicationtype() const {
  return (_has_bits_[0] & 0x00020000u) != 0;
}
inline void ApplicationReportProto::set_has_applicationtype() {
  _has_bits_[0] |= 0x00020000u;
}
inline void ApplicationReportProto::clear_has_applicationtype() {
  _has_bits_[0] &= ~0x00020000u;
}
inline void ApplicationReportProto::clear_applicationtype() {
  if (applicationtype_ != &::google::protobuf::internal::kEmptyString) {
    applicationtype_->clear();
  }
  clear_has_applicationtype();
}
inline const ::std::string& ApplicationReportProto::applicationtype() const {
  return *applicationtype_;
}
inline void ApplicationReportProto::set_applicationtype(const ::std::string& value) {
  set_has_applicationtype();
  if (applicationtype_ == &::google::protobuf::internal::kEmptyString) {
    applicationtype_ = new ::std::string;
  }
  applicationtype_->assign(value);
}
inline void ApplicationReportProto::set_applicationtype(const char* value) {
  set_has_applicationtype();
  if (applicationtype_ == &::google::protobuf::internal::kEmptyString) {
    applicationtype_ = new ::std::string;
  }
  applicationtype_->assign(value);
}
inline void ApplicationReportProto::set_applicationtype(const char* value, size_t size) {
  set_has_applicationtype();
  if (applicationtype_ == &::google::protobuf::internal::kEmptyString) {
    applicationtype_ = new ::std::string;
  }
  applicationtype_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ApplicationReportProto::mutable_applicationtype() {
  set_has_applicationtype();
  if (applicationtype_ == &::google::protobuf::internal::kEmptyString) {
    applicationtype_ = new ::std::string;
  }
  return applicationtype_;
}
inline ::std::string* ApplicationReportProto::release_applicationtype() {
  clear_has_applicationtype();
  if (applicationtype_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = applicationtype_;
    applicationtype_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void ApplicationReportProto::set_allocated_applicationtype(::std::string* applicationtype) {
  if (applicationtype_ != &::google::protobuf::internal::kEmptyString) {
    delete applicationtype_;
  }
  if (applicationtype) {
    set_has_applicationtype();
    applicationtype_ = applicationtype;
  } else {
    clear_has_applicationtype();
    applicationtype_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional .hadoop.common.TokenProto am_rm_token = 19;
inline bool ApplicationReportProto::has_am_rm_token() const {
  return (_has_bits_[0] & 0x00040000u) != 0;
}
inline void ApplicationReportProto::set_has_am_rm_token() {
  _has_bits_[0] |= 0x00040000u;
}
inline void ApplicationReportProto::clear_has_am_rm_token() {
  _has_bits_[0] &= ~0x00040000u;
}
inline void ApplicationReportProto::clear_am_rm_token() {
  if (am_rm_token_ != NULL) am_rm_token_->::hadoop::common::TokenProto::Clear();
  clear_has_am_rm_token();
}
inline const ::hadoop::common::TokenProto& ApplicationReportProto::am_rm_token() const {
  return am_rm_token_ != NULL ? *am_rm_token_ : *default_instance_->am_rm_token_;
}
inline ::hadoop::common::TokenProto* ApplicationReportProto::mutable_am_rm_token() {
  set_has_am_rm_token();
  if (am_rm_token_ == NULL) am_rm_token_ = new ::hadoop::common::TokenProto;
  return am_rm_token_;
}
inline ::hadoop::common::TokenProto* ApplicationReportProto::release_am_rm_token() {
  clear_has_am_rm_token();
  ::hadoop::common::TokenProto* temp = am_rm_token_;
  am_rm_token_ = NULL;
  return temp;
}
inline void ApplicationReportProto::set_allocated_am_rm_token(::hadoop::common::TokenProto* am_rm_token) {
  delete am_rm_token_;
  am_rm_token_ = am_rm_token;
  if (am_rm_token) {
    set_has_am_rm_token();
  } else {
    clear_has_am_rm_token();
  }
}

// -------------------------------------------------------------------

// NodeIdProto

// optional string host = 1;
inline bool NodeIdProto::has_host() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void NodeIdProto::set_has_host() {
  _has_bits_[0] |= 0x00000001u;
}
inline void NodeIdProto::clear_has_host() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void NodeIdProto::clear_host() {
  if (host_ != &::google::protobuf::internal::kEmptyString) {
    host_->clear();
  }
  clear_has_host();
}
inline const ::std::string& NodeIdProto::host() const {
  return *host_;
}
inline void NodeIdProto::set_host(const ::std::string& value) {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  host_->assign(value);
}
inline void NodeIdProto::set_host(const char* value) {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  host_->assign(value);
}
inline void NodeIdProto::set_host(const char* value, size_t size) {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  host_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* NodeIdProto::mutable_host() {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  return host_;
}
inline ::std::string* NodeIdProto::release_host() {
  clear_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = host_;
    host_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void NodeIdProto::set_allocated_host(::std::string* host) {
  if (host_ != &::google::protobuf::internal::kEmptyString) {
    delete host_;
  }
  if (host) {
    set_has_host();
    host_ = host;
  } else {
    clear_has_host();
    host_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional int32 port = 2;
inline bool NodeIdProto::has_port() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void NodeIdProto::set_has_port() {
  _has_bits_[0] |= 0x00000002u;
}
inline void NodeIdProto::clear_has_port() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void NodeIdProto::clear_port() {
  port_ = 0;
  clear_has_port();
}
inline ::google::protobuf::int32 NodeIdProto::port() const {
  return port_;
}
inline void NodeIdProto::set_port(::google::protobuf::int32 value) {
  set_has_port();
  port_ = value;
}

// -------------------------------------------------------------------

// NodeReportProto

// optional .hadoop.yarn.NodeIdProto nodeId = 1;
inline bool NodeReportProto::has_nodeid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void NodeReportProto::set_has_nodeid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void NodeReportProto::clear_has_nodeid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void NodeReportProto::clear_nodeid() {
  if (nodeid_ != NULL) nodeid_->::hadoop::yarn::NodeIdProto::Clear();
  clear_has_nodeid();
}
inline const ::hadoop::yarn::NodeIdProto& NodeReportProto::nodeid() const {
  return nodeid_ != NULL ? *nodeid_ : *default_instance_->nodeid_;
}
inline ::hadoop::yarn::NodeIdProto* NodeReportProto::mutable_nodeid() {
  set_has_nodeid();
  if (nodeid_ == NULL) nodeid_ = new ::hadoop::yarn::NodeIdProto;
  return nodeid_;
}
inline ::hadoop::yarn::NodeIdProto* NodeReportProto::release_nodeid() {
  clear_has_nodeid();
  ::hadoop::yarn::NodeIdProto* temp = nodeid_;
  nodeid_ = NULL;
  return temp;
}
inline void NodeReportProto::set_allocated_nodeid(::hadoop::yarn::NodeIdProto* nodeid) {
  delete nodeid_;
  nodeid_ = nodeid;
  if (nodeid) {
    set_has_nodeid();
  } else {
    clear_has_nodeid();
  }
}

// optional string httpAddress = 2;
inline bool NodeReportProto::has_httpaddress() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void NodeReportProto::set_has_httpaddress() {
  _has_bits_[0] |= 0x00000002u;
}
inline void NodeReportProto::clear_has_httpaddress() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void NodeReportProto::clear_httpaddress() {
  if (httpaddress_ != &::google::protobuf::internal::kEmptyString) {
    httpaddress_->clear();
  }
  clear_has_httpaddress();
}
inline const ::std::string& NodeReportProto::httpaddress() const {
  return *httpaddress_;
}
inline void NodeReportProto::set_httpaddress(const ::std::string& value) {
  set_has_httpaddress();
  if (httpaddress_ == &::google::protobuf::internal::kEmptyString) {
    httpaddress_ = new ::std::string;
  }
  httpaddress_->assign(value);
}
inline void NodeReportProto::set_httpaddress(const char* value) {
  set_has_httpaddress();
  if (httpaddress_ == &::google::protobuf::internal::kEmptyString) {
    httpaddress_ = new ::std::string;
  }
  httpaddress_->assign(value);
}
inline void NodeReportProto::set_httpaddress(const char* value, size_t size) {
  set_has_httpaddress();
  if (httpaddress_ == &::google::protobuf::internal::kEmptyString) {
    httpaddress_ = new ::std::string;
  }
  httpaddress_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* NodeReportProto::mutable_httpaddress() {
  set_has_httpaddress();
  if (httpaddress_ == &::google::protobuf::internal::kEmptyString) {
    httpaddress_ = new ::std::string;
  }
  return httpaddress_;
}
inline ::std::string* NodeReportProto::release_httpaddress() {
  clear_has_httpaddress();
  if (httpaddress_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = httpaddress_;
    httpaddress_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void NodeReportProto::set_allocated_httpaddress(::std::string* httpaddress) {
  if (httpaddress_ != &::google::protobuf::internal::kEmptyString) {
    delete httpaddress_;
  }
  if (httpaddress) {
    set_has_httpaddress();
    httpaddress_ = httpaddress;
  } else {
    clear_has_httpaddress();
    httpaddress_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional string rackName = 3;
inline bool NodeReportProto::has_rackname() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void NodeReportProto::set_has_rackname() {
  _has_bits_[0] |= 0x00000004u;
}
inline void NodeReportProto::clear_has_rackname() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void NodeReportProto::clear_rackname() {
  if (rackname_ != &::google::protobuf::internal::kEmptyString) {
    rackname_->clear();
  }
  clear_has_rackname();
}
inline const ::std::string& NodeReportProto::rackname() const {
  return *rackname_;
}
inline void NodeReportProto::set_rackname(const ::std::string& value) {
  set_has_rackname();
  if (rackname_ == &::google::protobuf::internal::kEmptyString) {
    rackname_ = new ::std::string;
  }
  rackname_->assign(value);
}
inline void NodeReportProto::set_rackname(const char* value) {
  set_has_rackname();
  if (rackname_ == &::google::protobuf::internal::kEmptyString) {
    rackname_ = new ::std::string;
  }
  rackname_->assign(value);
}
inline void NodeReportProto::set_rackname(const char* value, size_t size) {
  set_has_rackname();
  if (rackname_ == &::google::protobuf::internal::kEmptyString) {
    rackname_ = new ::std::string;
  }
  rackname_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* NodeReportProto::mutable_rackname() {
  set_has_rackname();
  if (rackname_ == &::google::protobuf::internal::kEmptyString) {
    rackname_ = new ::std::string;
  }
  return rackname_;
}
inline ::std::string* NodeReportProto::release_rackname() {
  clear_has_rackname();
  if (rackname_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = rackname_;
    rackname_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void NodeReportProto::set_allocated_rackname(::std::string* rackname) {
  if (rackname_ != &::google::protobuf::internal::kEmptyString) {
    delete rackname_;
  }
  if (rackname) {
    set_has_rackname();
    rackname_ = rackname;
  } else {
    clear_has_rackname();
    rackname_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional .hadoop.yarn.ResourceProto used = 4;
inline bool NodeReportProto::has_used() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void NodeReportProto::set_has_used() {
  _has_bits_[0] |= 0x00000008u;
}
inline void NodeReportProto::clear_has_used() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void NodeReportProto::clear_used() {
  if (used_ != NULL) used_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_used();
}
inline const ::hadoop::yarn::ResourceProto& NodeReportProto::used() const {
  return used_ != NULL ? *used_ : *default_instance_->used_;
}
inline ::hadoop::yarn::ResourceProto* NodeReportProto::mutable_used() {
  set_has_used();
  if (used_ == NULL) used_ = new ::hadoop::yarn::ResourceProto;
  return used_;
}
inline ::hadoop::yarn::ResourceProto* NodeReportProto::release_used() {
  clear_has_used();
  ::hadoop::yarn::ResourceProto* temp = used_;
  used_ = NULL;
  return temp;
}
inline void NodeReportProto::set_allocated_used(::hadoop::yarn::ResourceProto* used) {
  delete used_;
  used_ = used;
  if (used) {
    set_has_used();
  } else {
    clear_has_used();
  }
}

// optional .hadoop.yarn.ResourceProto capability = 5;
inline bool NodeReportProto::has_capability() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void NodeReportProto::set_has_capability() {
  _has_bits_[0] |= 0x00000010u;
}
inline void NodeReportProto::clear_has_capability() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void NodeReportProto::clear_capability() {
  if (capability_ != NULL) capability_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_capability();
}
inline const ::hadoop::yarn::ResourceProto& NodeReportProto::capability() const {
  return capability_ != NULL ? *capability_ : *default_instance_->capability_;
}
inline ::hadoop::yarn::ResourceProto* NodeReportProto::mutable_capability() {
  set_has_capability();
  if (capability_ == NULL) capability_ = new ::hadoop::yarn::ResourceProto;
  return capability_;
}
inline ::hadoop::yarn::ResourceProto* NodeReportProto::release_capability() {
  clear_has_capability();
  ::hadoop::yarn::ResourceProto* temp = capability_;
  capability_ = NULL;
  return temp;
}
inline void NodeReportProto::set_allocated_capability(::hadoop::yarn::ResourceProto* capability) {
  delete capability_;
  capability_ = capability;
  if (capability) {
    set_has_capability();
  } else {
    clear_has_capability();
  }
}

// optional int32 numContainers = 6;
inline bool NodeReportProto::has_numcontainers() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void NodeReportProto::set_has_numcontainers() {
  _has_bits_[0] |= 0x00000020u;
}
inline void NodeReportProto::clear_has_numcontainers() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void NodeReportProto::clear_numcontainers() {
  numcontainers_ = 0;
  clear_has_numcontainers();
}
inline ::google::protobuf::int32 NodeReportProto::numcontainers() const {
  return numcontainers_;
}
inline void NodeReportProto::set_numcontainers(::google::protobuf::int32 value) {
  set_has_numcontainers();
  numcontainers_ = value;
}

// optional .hadoop.yarn.NodeStateProto node_state = 7;
inline bool NodeReportProto::has_node_state() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void NodeReportProto::set_has_node_state() {
  _has_bits_[0] |= 0x00000040u;
}
inline void NodeReportProto::clear_has_node_state() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void NodeReportProto::clear_node_state() {
  node_state_ = 1;
  clear_has_node_state();
}
inline ::hadoop::yarn::NodeStateProto NodeReportProto::node_state() const {
  return static_cast< ::hadoop::yarn::NodeStateProto >(node_state_);
}
inline void NodeReportProto::set_node_state(::hadoop::yarn::NodeStateProto value) {
  assert(::hadoop::yarn::NodeStateProto_IsValid(value));
  set_has_node_state();
  node_state_ = value;
}

// optional string health_report = 8;
inline bool NodeReportProto::has_health_report() const {
  return (_has_bits_[0] & 0x00000080u) != 0;
}
inline void NodeReportProto::set_has_health_report() {
  _has_bits_[0] |= 0x00000080u;
}
inline void NodeReportProto::clear_has_health_report() {
  _has_bits_[0] &= ~0x00000080u;
}
inline void NodeReportProto::clear_health_report() {
  if (health_report_ != &::google::protobuf::internal::kEmptyString) {
    health_report_->clear();
  }
  clear_has_health_report();
}
inline const ::std::string& NodeReportProto::health_report() const {
  return *health_report_;
}
inline void NodeReportProto::set_health_report(const ::std::string& value) {
  set_has_health_report();
  if (health_report_ == &::google::protobuf::internal::kEmptyString) {
    health_report_ = new ::std::string;
  }
  health_report_->assign(value);
}
inline void NodeReportProto::set_health_report(const char* value) {
  set_has_health_report();
  if (health_report_ == &::google::protobuf::internal::kEmptyString) {
    health_report_ = new ::std::string;
  }
  health_report_->assign(value);
}
inline void NodeReportProto::set_health_report(const char* value, size_t size) {
  set_has_health_report();
  if (health_report_ == &::google::protobuf::internal::kEmptyString) {
    health_report_ = new ::std::string;
  }
  health_report_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* NodeReportProto::mutable_health_report() {
  set_has_health_report();
  if (health_report_ == &::google::protobuf::internal::kEmptyString) {
    health_report_ = new ::std::string;
  }
  return health_report_;
}
inline ::std::string* NodeReportProto::release_health_report() {
  clear_has_health_report();
  if (health_report_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = health_report_;
    health_report_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void NodeReportProto::set_allocated_health_report(::std::string* health_report) {
  if (health_report_ != &::google::protobuf::internal::kEmptyString) {
    delete health_report_;
  }
  if (health_report) {
    set_has_health_report();
    health_report_ = health_report;
  } else {
    clear_has_health_report();
    health_report_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional int64 last_health_report_time = 9;
inline bool NodeReportProto::has_last_health_report_time() const {
  return (_has_bits_[0] & 0x00000100u) != 0;
}
inline void NodeReportProto::set_has_last_health_report_time() {
  _has_bits_[0] |= 0x00000100u;
}
inline void NodeReportProto::clear_has_last_health_report_time() {
  _has_bits_[0] &= ~0x00000100u;
}
inline void NodeReportProto::clear_last_health_report_time() {
  last_health_report_time_ = GOOGLE_LONGLONG(0);
  clear_has_last_health_report_time();
}
inline ::google::protobuf::int64 NodeReportProto::last_health_report_time() const {
  return last_health_report_time_;
}
inline void NodeReportProto::set_last_health_report_time(::google::protobuf::int64 value) {
  set_has_last_health_report_time();
  last_health_report_time_ = value;
}

// -------------------------------------------------------------------

// ResourceRequestProto

// optional .hadoop.yarn.PriorityProto priority = 1;
inline bool ResourceRequestProto::has_priority() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ResourceRequestProto::set_has_priority() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ResourceRequestProto::clear_has_priority() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ResourceRequestProto::clear_priority() {
  if (priority_ != NULL) priority_->::hadoop::yarn::PriorityProto::Clear();
  clear_has_priority();
}
inline const ::hadoop::yarn::PriorityProto& ResourceRequestProto::priority() const {
  return priority_ != NULL ? *priority_ : *default_instance_->priority_;
}
inline ::hadoop::yarn::PriorityProto* ResourceRequestProto::mutable_priority() {
  set_has_priority();
  if (priority_ == NULL) priority_ = new ::hadoop::yarn::PriorityProto;
  return priority_;
}
inline ::hadoop::yarn::PriorityProto* ResourceRequestProto::release_priority() {
  clear_has_priority();
  ::hadoop::yarn::PriorityProto* temp = priority_;
  priority_ = NULL;
  return temp;
}
inline void ResourceRequestProto::set_allocated_priority(::hadoop::yarn::PriorityProto* priority) {
  delete priority_;
  priority_ = priority;
  if (priority) {
    set_has_priority();
  } else {
    clear_has_priority();
  }
}

// optional string resource_name = 2;
inline bool ResourceRequestProto::has_resource_name() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ResourceRequestProto::set_has_resource_name() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ResourceRequestProto::clear_has_resource_name() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ResourceRequestProto::clear_resource_name() {
  if (resource_name_ != &::google::protobuf::internal::kEmptyString) {
    resource_name_->clear();
  }
  clear_has_resource_name();
}
inline const ::std::string& ResourceRequestProto::resource_name() const {
  return *resource_name_;
}
inline void ResourceRequestProto::set_resource_name(const ::std::string& value) {
  set_has_resource_name();
  if (resource_name_ == &::google::protobuf::internal::kEmptyString) {
    resource_name_ = new ::std::string;
  }
  resource_name_->assign(value);
}
inline void ResourceRequestProto::set_resource_name(const char* value) {
  set_has_resource_name();
  if (resource_name_ == &::google::protobuf::internal::kEmptyString) {
    resource_name_ = new ::std::string;
  }
  resource_name_->assign(value);
}
inline void ResourceRequestProto::set_resource_name(const char* value, size_t size) {
  set_has_resource_name();
  if (resource_name_ == &::google::protobuf::internal::kEmptyString) {
    resource_name_ = new ::std::string;
  }
  resource_name_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ResourceRequestProto::mutable_resource_name() {
  set_has_resource_name();
  if (resource_name_ == &::google::protobuf::internal::kEmptyString) {
    resource_name_ = new ::std::string;
  }
  return resource_name_;
}
inline ::std::string* ResourceRequestProto::release_resource_name() {
  clear_has_resource_name();
  if (resource_name_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = resource_name_;
    resource_name_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void ResourceRequestProto::set_allocated_resource_name(::std::string* resource_name) {
  if (resource_name_ != &::google::protobuf::internal::kEmptyString) {
    delete resource_name_;
  }
  if (resource_name) {
    set_has_resource_name();
    resource_name_ = resource_name;
  } else {
    clear_has_resource_name();
    resource_name_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional .hadoop.yarn.ResourceProto capability = 3;
inline bool ResourceRequestProto::has_capability() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ResourceRequestProto::set_has_capability() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ResourceRequestProto::clear_has_capability() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ResourceRequestProto::clear_capability() {
  if (capability_ != NULL) capability_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_capability();
}
inline const ::hadoop::yarn::ResourceProto& ResourceRequestProto::capability() const {
  return capability_ != NULL ? *capability_ : *default_instance_->capability_;
}
inline ::hadoop::yarn::ResourceProto* ResourceRequestProto::mutable_capability() {
  set_has_capability();
  if (capability_ == NULL) capability_ = new ::hadoop::yarn::ResourceProto;
  return capability_;
}
inline ::hadoop::yarn::ResourceProto* ResourceRequestProto::release_capability() {
  clear_has_capability();
  ::hadoop::yarn::ResourceProto* temp = capability_;
  capability_ = NULL;
  return temp;
}
inline void ResourceRequestProto::set_allocated_capability(::hadoop::yarn::ResourceProto* capability) {
  delete capability_;
  capability_ = capability;
  if (capability) {
    set_has_capability();
  } else {
    clear_has_capability();
  }
}

// optional int32 num_containers = 4;
inline bool ResourceRequestProto::has_num_containers() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ResourceRequestProto::set_has_num_containers() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ResourceRequestProto::clear_has_num_containers() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ResourceRequestProto::clear_num_containers() {
  num_containers_ = 0;
  clear_has_num_containers();
}
inline ::google::protobuf::int32 ResourceRequestProto::num_containers() const {
  return num_containers_;
}
inline void ResourceRequestProto::set_num_containers(::google::protobuf::int32 value) {
  set_has_num_containers();
  num_containers_ = value;
}

// optional bool relax_locality = 5 [default = true];
inline bool ResourceRequestProto::has_relax_locality() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void ResourceRequestProto::set_has_relax_locality() {
  _has_bits_[0] |= 0x00000010u;
}
inline void ResourceRequestProto::clear_has_relax_locality() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void ResourceRequestProto::clear_relax_locality() {
  relax_locality_ = true;
  clear_has_relax_locality();
}
inline bool ResourceRequestProto::relax_locality() const {
  return relax_locality_;
}
inline void ResourceRequestProto::set_relax_locality(bool value) {
  set_has_relax_locality();
  relax_locality_ = value;
}

// -------------------------------------------------------------------

// PreemptionMessageProto

// optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;
inline bool PreemptionMessageProto::has_strictcontract() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void PreemptionMessageProto::set_has_strictcontract() {
  _has_bits_[0] |= 0x00000001u;
}
inline void PreemptionMessageProto::clear_has_strictcontract() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void PreemptionMessageProto::clear_strictcontract() {
  if (strictcontract_ != NULL) strictcontract_->::hadoop::yarn::StrictPreemptionContractProto::Clear();
  clear_has_strictcontract();
}
inline const ::hadoop::yarn::StrictPreemptionContractProto& PreemptionMessageProto::strictcontract() const {
  return strictcontract_ != NULL ? *strictcontract_ : *default_instance_->strictcontract_;
}
inline ::hadoop::yarn::StrictPreemptionContractProto* PreemptionMessageProto::mutable_strictcontract() {
  set_has_strictcontract();
  if (strictcontract_ == NULL) strictcontract_ = new ::hadoop::yarn::StrictPreemptionContractProto;
  return strictcontract_;
}
inline ::hadoop::yarn::StrictPreemptionContractProto* PreemptionMessageProto::release_strictcontract() {
  clear_has_strictcontract();
  ::hadoop::yarn::StrictPreemptionContractProto* temp = strictcontract_;
  strictcontract_ = NULL;
  return temp;
}
inline void PreemptionMessageProto::set_allocated_strictcontract(::hadoop::yarn::StrictPreemptionContractProto* strictcontract) {
  delete strictcontract_;
  strictcontract_ = strictcontract;
  if (strictcontract) {
    set_has_strictcontract();
  } else {
    clear_has_strictcontract();
  }
}

// optional .hadoop.yarn.PreemptionContractProto contract = 2;
inline bool PreemptionMessageProto::has_contract() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void PreemptionMessageProto::set_has_contract() {
  _has_bits_[0] |= 0x00000002u;
}
inline void PreemptionMessageProto::clear_has_contract() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void PreemptionMessageProto::clear_contract() {
  if (contract_ != NULL) contract_->::hadoop::yarn::PreemptionContractProto::Clear();
  clear_has_contract();
}
inline const ::hadoop::yarn::PreemptionContractProto& PreemptionMessageProto::contract() const {
  return contract_ != NULL ? *contract_ : *default_instance_->contract_;
}
inline ::hadoop::yarn::PreemptionContractProto* PreemptionMessageProto::mutable_contract() {
  set_has_contract();
  if (contract_ == NULL) contract_ = new ::hadoop::yarn::PreemptionContractProto;
  return contract_;
}
inline ::hadoop::yarn::PreemptionContractProto* PreemptionMessageProto::release_contract() {
  clear_has_contract();
  ::hadoop::yarn::PreemptionContractProto* temp = contract_;
  contract_ = NULL;
  return temp;
}
inline void PreemptionMessageProto::set_allocated_contract(::hadoop::yarn::PreemptionContractProto* contract) {
  delete contract_;
  contract_ = contract;
  if (contract) {
    set_has_contract();
  } else {
    clear_has_contract();
  }
}

// -------------------------------------------------------------------

// StrictPreemptionContractProto

// repeated .hadoop.yarn.PreemptionContainerProto container = 1;
inline int StrictPreemptionContractProto::container_size() const {
  return container_.size();
}
inline void StrictPreemptionContractProto::clear_container() {
  container_.Clear();
}
inline const ::hadoop::yarn::PreemptionContainerProto& StrictPreemptionContractProto::container(int index) const {
  return container_.Get(index);
}
inline ::hadoop::yarn::PreemptionContainerProto* StrictPreemptionContractProto::mutable_container(int index) {
  return container_.Mutable(index);
}
inline ::hadoop::yarn::PreemptionContainerProto* StrictPreemptionContractProto::add_container() {
  return container_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionContainerProto >&
StrictPreemptionContractProto::container() const {
  return container_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionContainerProto >*
StrictPreemptionContractProto::mutable_container() {
  return &container_;
}

// -------------------------------------------------------------------

// PreemptionContractProto

// repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;
inline int PreemptionContractProto::resource_size() const {
  return resource_.size();
}
inline void PreemptionContractProto::clear_resource() {
  resource_.Clear();
}
inline const ::hadoop::yarn::PreemptionResourceRequestProto& PreemptionContractProto::resource(int index) const {
  return resource_.Get(index);
}
inline ::hadoop::yarn::PreemptionResourceRequestProto* PreemptionContractProto::mutable_resource(int index) {
  return resource_.Mutable(index);
}
inline ::hadoop::yarn::PreemptionResourceRequestProto* PreemptionContractProto::add_resource() {
  return resource_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionResourceRequestProto >&
PreemptionContractProto::resource() const {
  return resource_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionResourceRequestProto >*
PreemptionContractProto::mutable_resource() {
  return &resource_;
}

// repeated .hadoop.yarn.PreemptionContainerProto container = 2;
inline int PreemptionContractProto::container_size() const {
  return container_.size();
}
inline void PreemptionContractProto::clear_container() {
  container_.Clear();
}
inline const ::hadoop::yarn::PreemptionContainerProto& PreemptionContractProto::container(int index) const {
  return container_.Get(index);
}
inline ::hadoop::yarn::PreemptionContainerProto* PreemptionContractProto::mutable_container(int index) {
  return container_.Mutable(index);
}
inline ::hadoop::yarn::PreemptionContainerProto* PreemptionContractProto::add_container() {
  return container_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionContainerProto >&
PreemptionContractProto::container() const {
  return container_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::PreemptionContainerProto >*
PreemptionContractProto::mutable_container() {
  return &container_;
}

// -------------------------------------------------------------------

// PreemptionContainerProto

// optional .hadoop.yarn.ContainerIdProto id = 1;
inline bool PreemptionContainerProto::has_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void PreemptionContainerProto::set_has_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void PreemptionContainerProto::clear_has_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void PreemptionContainerProto::clear_id() {
  if (id_ != NULL) id_->::hadoop::yarn::ContainerIdProto::Clear();
  clear_has_id();
}
inline const ::hadoop::yarn::ContainerIdProto& PreemptionContainerProto::id() const {
  return id_ != NULL ? *id_ : *default_instance_->id_;
}
inline ::hadoop::yarn::ContainerIdProto* PreemptionContainerProto::mutable_id() {
  set_has_id();
  if (id_ == NULL) id_ = new ::hadoop::yarn::ContainerIdProto;
  return id_;
}
inline ::hadoop::yarn::ContainerIdProto* PreemptionContainerProto::release_id() {
  clear_has_id();
  ::hadoop::yarn::ContainerIdProto* temp = id_;
  id_ = NULL;
  return temp;
}
inline void PreemptionContainerProto::set_allocated_id(::hadoop::yarn::ContainerIdProto* id) {
  delete id_;
  id_ = id;
  if (id) {
    set_has_id();
  } else {
    clear_has_id();
  }
}

// -------------------------------------------------------------------

// PreemptionResourceRequestProto

// optional .hadoop.yarn.ResourceRequestProto resource = 1;
inline bool PreemptionResourceRequestProto::has_resource() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void PreemptionResourceRequestProto::set_has_resource() {
  _has_bits_[0] |= 0x00000001u;
}
inline void PreemptionResourceRequestProto::clear_has_resource() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void PreemptionResourceRequestProto::clear_resource() {
  if (resource_ != NULL) resource_->::hadoop::yarn::ResourceRequestProto::Clear();
  clear_has_resource();
}
inline const ::hadoop::yarn::ResourceRequestProto& PreemptionResourceRequestProto::resource() const {
  return resource_ != NULL ? *resource_ : *default_instance_->resource_;
}
inline ::hadoop::yarn::ResourceRequestProto* PreemptionResourceRequestProto::mutable_resource() {
  set_has_resource();
  if (resource_ == NULL) resource_ = new ::hadoop::yarn::ResourceRequestProto;
  return resource_;
}
inline ::hadoop::yarn::ResourceRequestProto* PreemptionResourceRequestProto::release_resource() {
  clear_has_resource();
  ::hadoop::yarn::ResourceRequestProto* temp = resource_;
  resource_ = NULL;
  return temp;
}
inline void PreemptionResourceRequestProto::set_allocated_resource(::hadoop::yarn::ResourceRequestProto* resource) {
  delete resource_;
  resource_ = resource;
  if (resource) {
    set_has_resource();
  } else {
    clear_has_resource();
  }
}

// -------------------------------------------------------------------

// ResourceBlacklistRequestProto

// repeated string blacklist_additions = 1;
inline int ResourceBlacklistRequestProto::blacklist_additions_size() const {
  return blacklist_additions_.size();
}
inline void ResourceBlacklistRequestProto::clear_blacklist_additions() {
  blacklist_additions_.Clear();
}
inline const ::std::string& ResourceBlacklistRequestProto::blacklist_additions(int index) const {
  return blacklist_additions_.Get(index);
}
inline ::std::string* ResourceBlacklistRequestProto::mutable_blacklist_additions(int index) {
  return blacklist_additions_.Mutable(index);
}
inline void ResourceBlacklistRequestProto::set_blacklist_additions(int index, const ::std::string& value) {
  blacklist_additions_.Mutable(index)->assign(value);
}
inline void ResourceBlacklistRequestProto::set_blacklist_additions(int index, const char* value) {
  blacklist_additions_.Mutable(index)->assign(value);
}
inline void ResourceBlacklistRequestProto::set_blacklist_additions(int index, const char* value, size_t size) {
  blacklist_additions_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ResourceBlacklistRequestProto::add_blacklist_additions() {
  return blacklist_additions_.Add();
}
inline void ResourceBlacklistRequestProto::add_blacklist_additions(const ::std::string& value) {
  blacklist_additions_.Add()->assign(value);
}
inline void ResourceBlacklistRequestProto::add_blacklist_additions(const char* value) {
  blacklist_additions_.Add()->assign(value);
}
inline void ResourceBlacklistRequestProto::add_blacklist_additions(const char* value, size_t size) {
  blacklist_additions_.Add()->assign(reinterpret_cast<const char*>(value), size);
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
ResourceBlacklistRequestProto::blacklist_additions() const {
  return blacklist_additions_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
ResourceBlacklistRequestProto::mutable_blacklist_additions() {
  return &blacklist_additions_;
}

// repeated string blacklist_removals = 2;
inline int ResourceBlacklistRequestProto::blacklist_removals_size() const {
  return blacklist_removals_.size();
}
inline void ResourceBlacklistRequestProto::clear_blacklist_removals() {
  blacklist_removals_.Clear();
}
inline const ::std::string& ResourceBlacklistRequestProto::blacklist_removals(int index) const {
  return blacklist_removals_.Get(index);
}
inline ::std::string* ResourceBlacklistRequestProto::mutable_blacklist_removals(int index) {
  return blacklist_removals_.Mutable(index);
}
inline void ResourceBlacklistRequestProto::set_blacklist_removals(int index, const ::std::string& value) {
  blacklist_removals_.Mutable(index)->assign(value);
}
inline void ResourceBlacklistRequestProto::set_blacklist_removals(int index, const char* value) {
  blacklist_removals_.Mutable(index)->assign(value);
}
inline void ResourceBlacklistRequestProto::set_blacklist_removals(int index, const char* value, size_t size) {
  blacklist_removals_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ResourceBlacklistRequestProto::add_blacklist_removals() {
  return blacklist_removals_.Add();
}
inline void ResourceBlacklistRequestProto::add_blacklist_removals(const ::std::string& value) {
  blacklist_removals_.Add()->assign(value);
}
inline void ResourceBlacklistRequestProto::add_blacklist_removals(const char* value) {
  blacklist_removals_.Add()->assign(value);
}
inline void ResourceBlacklistRequestProto::add_blacklist_removals(const char* value, size_t size) {
  blacklist_removals_.Add()->assign(reinterpret_cast<const char*>(value), size);
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
ResourceBlacklistRequestProto::blacklist_removals() const {
  return blacklist_removals_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
ResourceBlacklistRequestProto::mutable_blacklist_removals() {
  return &blacklist_removals_;
}

// -------------------------------------------------------------------

// ApplicationSubmissionContextProto

// optional .hadoop.yarn.ApplicationIdProto application_id = 1;
inline bool ApplicationSubmissionContextProto::has_application_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ApplicationSubmissionContextProto::set_has_application_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ApplicationSubmissionContextProto::clear_has_application_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ApplicationSubmissionContextProto::clear_application_id() {
  if (application_id_ != NULL) application_id_->::hadoop::yarn::ApplicationIdProto::Clear();
  clear_has_application_id();
}
inline const ::hadoop::yarn::ApplicationIdProto& ApplicationSubmissionContextProto::application_id() const {
  return application_id_ != NULL ? *application_id_ : *default_instance_->application_id_;
}
inline ::hadoop::yarn::ApplicationIdProto* ApplicationSubmissionContextProto::mutable_application_id() {
  set_has_application_id();
  if (application_id_ == NULL) application_id_ = new ::hadoop::yarn::ApplicationIdProto;
  return application_id_;
}
inline ::hadoop::yarn::ApplicationIdProto* ApplicationSubmissionContextProto::release_application_id() {
  clear_has_application_id();
  ::hadoop::yarn::ApplicationIdProto* temp = application_id_;
  application_id_ = NULL;
  return temp;
}
inline void ApplicationSubmissionContextProto::set_allocated_application_id(::hadoop::yarn::ApplicationIdProto* application_id) {
  delete application_id_;
  application_id_ = application_id;
  if (application_id) {
    set_has_application_id();
  } else {
    clear_has_application_id();
  }
}

// optional string application_name = 2 [default = "N/A"];
inline bool ApplicationSubmissionContextProto::has_application_name() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ApplicationSubmissionContextProto::set_has_application_name() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ApplicationSubmissionContextProto::clear_has_application_name() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ApplicationSubmissionContextProto::clear_application_name() {
  if (application_name_ != _default_application_name_) {
    application_name_->assign(*_default_application_name_);
  }
  clear_has_application_name();
}
inline const ::std::string& ApplicationSubmissionContextProto::application_name() const {
  return *application_name_;
}
inline void ApplicationSubmissionContextProto::set_application_name(const ::std::string& value) {
  set_has_application_name();
  if (application_name_ == _default_application_name_) {
    application_name_ = new ::std::string;
  }
  application_name_->assign(value);
}
inline void ApplicationSubmissionContextProto::set_application_name(const char* value) {
  set_has_application_name();
  if (application_name_ == _default_application_name_) {
    application_name_ = new ::std::string;
  }
  application_name_->assign(value);
}
inline void ApplicationSubmissionContextProto::set_application_name(const char* value, size_t size) {
  set_has_application_name();
  if (application_name_ == _default_application_name_) {
    application_name_ = new ::std::string;
  }
  application_name_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ApplicationSubmissionContextProto::mutable_application_name() {
  set_has_application_name();
  if (application_name_ == _default_application_name_) {
    application_name_ = new ::std::string(*_default_application_name_);
  }
  return application_name_;
}
inline ::std::string* ApplicationSubmissionContextProto::release_application_name() {
  clear_has_application_name();
  if (application_name_ == _default_application_name_) {
    return NULL;
  } else {
    ::std::string* temp = application_name_;
    application_name_ = const_cast< ::std::string*>(_default_application_name_);
    return temp;
  }
}
inline void ApplicationSubmissionContextProto::set_allocated_application_name(::std::string* application_name) {
  if (application_name_ != _default_application_name_) {
    delete application_name_;
  }
  if (application_name) {
    set_has_application_name();
    application_name_ = application_name;
  } else {
    clear_has_application_name();
    application_name_ = const_cast< ::std::string*>(_default_application_name_);
  }
}

// optional string queue = 3 [default = "default"];
inline bool ApplicationSubmissionContextProto::has_queue() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ApplicationSubmissionContextProto::set_has_queue() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ApplicationSubmissionContextProto::clear_has_queue() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ApplicationSubmissionContextProto::clear_queue() {
  if (queue_ != _default_queue_) {
    queue_->assign(*_default_queue_);
  }
  clear_has_queue();
}
inline const ::std::string& ApplicationSubmissionContextProto::queue() const {
  return *queue_;
}
inline void ApplicationSubmissionContextProto::set_queue(const ::std::string& value) {
  set_has_queue();
  if (queue_ == _default_queue_) {
    queue_ = new ::std::string;
  }
  queue_->assign(value);
}
inline void ApplicationSubmissionContextProto::set_queue(const char* value) {
  set_has_queue();
  if (queue_ == _default_queue_) {
    queue_ = new ::std::string;
  }
  queue_->assign(value);
}
inline void ApplicationSubmissionContextProto::set_queue(const char* value, size_t size) {
  set_has_queue();
  if (queue_ == _default_queue_) {
    queue_ = new ::std::string;
  }
  queue_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ApplicationSubmissionContextProto::mutable_queue() {
  set_has_queue();
  if (queue_ == _default_queue_) {
    queue_ = new ::std::string(*_default_queue_);
  }
  return queue_;
}
inline ::std::string* ApplicationSubmissionContextProto::release_queue() {
  clear_has_queue();
  if (queue_ == _default_queue_) {
    return NULL;
  } else {
    ::std::string* temp = queue_;
    queue_ = const_cast< ::std::string*>(_default_queue_);
    return temp;
  }
}
inline void ApplicationSubmissionContextProto::set_allocated_queue(::std::string* queue) {
  if (queue_ != _default_queue_) {
    delete queue_;
  }
  if (queue) {
    set_has_queue();
    queue_ = queue;
  } else {
    clear_has_queue();
    queue_ = const_cast< ::std::string*>(_default_queue_);
  }
}

// optional .hadoop.yarn.PriorityProto priority = 4;
inline bool ApplicationSubmissionContextProto::has_priority() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ApplicationSubmissionContextProto::set_has_priority() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ApplicationSubmissionContextProto::clear_has_priority() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ApplicationSubmissionContextProto::clear_priority() {
  if (priority_ != NULL) priority_->::hadoop::yarn::PriorityProto::Clear();
  clear_has_priority();
}
inline const ::hadoop::yarn::PriorityProto& ApplicationSubmissionContextProto::priority() const {
  return priority_ != NULL ? *priority_ : *default_instance_->priority_;
}
inline ::hadoop::yarn::PriorityProto* ApplicationSubmissionContextProto::mutable_priority() {
  set_has_priority();
  if (priority_ == NULL) priority_ = new ::hadoop::yarn::PriorityProto;
  return priority_;
}
inline ::hadoop::yarn::PriorityProto* ApplicationSubmissionContextProto::release_priority() {
  clear_has_priority();
  ::hadoop::yarn::PriorityProto* temp = priority_;
  priority_ = NULL;
  return temp;
}
inline void ApplicationSubmissionContextProto::set_allocated_priority(::hadoop::yarn::PriorityProto* priority) {
  delete priority_;
  priority_ = priority;
  if (priority) {
    set_has_priority();
  } else {
    clear_has_priority();
  }
}

// optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;
inline bool ApplicationSubmissionContextProto::has_am_container_spec() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void ApplicationSubmissionContextProto::set_has_am_container_spec() {
  _has_bits_[0] |= 0x00000010u;
}
inline void ApplicationSubmissionContextProto::clear_has_am_container_spec() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void ApplicationSubmissionContextProto::clear_am_container_spec() {
  if (am_container_spec_ != NULL) am_container_spec_->::hadoop::yarn::ContainerLaunchContextProto::Clear();
  clear_has_am_container_spec();
}
inline const ::hadoop::yarn::ContainerLaunchContextProto& ApplicationSubmissionContextProto::am_container_spec() const {
  return am_container_spec_ != NULL ? *am_container_spec_ : *default_instance_->am_container_spec_;
}
inline ::hadoop::yarn::ContainerLaunchContextProto* ApplicationSubmissionContextProto::mutable_am_container_spec() {
  set_has_am_container_spec();
  if (am_container_spec_ == NULL) am_container_spec_ = new ::hadoop::yarn::ContainerLaunchContextProto;
  return am_container_spec_;
}
inline ::hadoop::yarn::ContainerLaunchContextProto* ApplicationSubmissionContextProto::release_am_container_spec() {
  clear_has_am_container_spec();
  ::hadoop::yarn::ContainerLaunchContextProto* temp = am_container_spec_;
  am_container_spec_ = NULL;
  return temp;
}
inline void ApplicationSubmissionContextProto::set_allocated_am_container_spec(::hadoop::yarn::ContainerLaunchContextProto* am_container_spec) {
  delete am_container_spec_;
  am_container_spec_ = am_container_spec;
  if (am_container_spec) {
    set_has_am_container_spec();
  } else {
    clear_has_am_container_spec();
  }
}

// optional bool cancel_tokens_when_complete = 6 [default = true];
inline bool ApplicationSubmissionContextProto::has_cancel_tokens_when_complete() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void ApplicationSubmissionContextProto::set_has_cancel_tokens_when_complete() {
  _has_bits_[0] |= 0x00000020u;
}
inline void ApplicationSubmissionContextProto::clear_has_cancel_tokens_when_complete() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void ApplicationSubmissionContextProto::clear_cancel_tokens_when_complete() {
  cancel_tokens_when_complete_ = true;
  clear_has_cancel_tokens_when_complete();
}
inline bool ApplicationSubmissionContextProto::cancel_tokens_when_complete() const {
  return cancel_tokens_when_complete_;
}
inline void ApplicationSubmissionContextProto::set_cancel_tokens_when_complete(bool value) {
  set_has_cancel_tokens_when_complete();
  cancel_tokens_when_complete_ = value;
}

// optional bool unmanaged_am = 7 [default = false];
inline bool ApplicationSubmissionContextProto::has_unmanaged_am() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void ApplicationSubmissionContextProto::set_has_unmanaged_am() {
  _has_bits_[0] |= 0x00000040u;
}
inline void ApplicationSubmissionContextProto::clear_has_unmanaged_am() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void ApplicationSubmissionContextProto::clear_unmanaged_am() {
  unmanaged_am_ = false;
  clear_has_unmanaged_am();
}
inline bool ApplicationSubmissionContextProto::unmanaged_am() const {
  return unmanaged_am_;
}
inline void ApplicationSubmissionContextProto::set_unmanaged_am(bool value) {
  set_has_unmanaged_am();
  unmanaged_am_ = value;
}

// optional int32 maxAppAttempts = 8 [default = 0];
inline bool ApplicationSubmissionContextProto::has_maxappattempts() const {
  return (_has_bits_[0] & 0x00000080u) != 0;
}
inline void ApplicationSubmissionContextProto::set_has_maxappattempts() {
  _has_bits_[0] |= 0x00000080u;
}
inline void ApplicationSubmissionContextProto::clear_has_maxappattempts() {
  _has_bits_[0] &= ~0x00000080u;
}
inline void ApplicationSubmissionContextProto::clear_maxappattempts() {
  maxappattempts_ = 0;
  clear_has_maxappattempts();
}
inline ::google::protobuf::int32 ApplicationSubmissionContextProto::maxappattempts() const {
  return maxappattempts_;
}
inline void ApplicationSubmissionContextProto::set_maxappattempts(::google::protobuf::int32 value) {
  set_has_maxappattempts();
  maxappattempts_ = value;
}

// optional .hadoop.yarn.ResourceProto resource = 9;
inline bool ApplicationSubmissionContextProto::has_resource() const {
  return (_has_bits_[0] & 0x00000100u) != 0;
}
inline void ApplicationSubmissionContextProto::set_has_resource() {
  _has_bits_[0] |= 0x00000100u;
}
inline void ApplicationSubmissionContextProto::clear_has_resource() {
  _has_bits_[0] &= ~0x00000100u;
}
inline void ApplicationSubmissionContextProto::clear_resource() {
  if (resource_ != NULL) resource_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_resource();
}
inline const ::hadoop::yarn::ResourceProto& ApplicationSubmissionContextProto::resource() const {
  return resource_ != NULL ? *resource_ : *default_instance_->resource_;
}
inline ::hadoop::yarn::ResourceProto* ApplicationSubmissionContextProto::mutable_resource() {
  set_has_resource();
  if (resource_ == NULL) resource_ = new ::hadoop::yarn::ResourceProto;
  return resource_;
}
inline ::hadoop::yarn::ResourceProto* ApplicationSubmissionContextProto::release_resource() {
  clear_has_resource();
  ::hadoop::yarn::ResourceProto* temp = resource_;
  resource_ = NULL;
  return temp;
}
inline void ApplicationSubmissionContextProto::set_allocated_resource(::hadoop::yarn::ResourceProto* resource) {
  delete resource_;
  resource_ = resource;
  if (resource) {
    set_has_resource();
  } else {
    clear_has_resource();
  }
}

// optional string applicationType = 10 [default = "YARN"];
inline bool ApplicationSubmissionContextProto::has_applicationtype() const {
  return (_has_bits_[0] & 0x00000200u) != 0;
}
inline void ApplicationSubmissionContextProto::set_has_applicationtype() {
  _has_bits_[0] |= 0x00000200u;
}
inline void ApplicationSubmissionContextProto::clear_has_applicationtype() {
  _has_bits_[0] &= ~0x00000200u;
}
inline void ApplicationSubmissionContextProto::clear_applicationtype() {
  if (applicationtype_ != _default_applicationtype_) {
    applicationtype_->assign(*_default_applicationtype_);
  }
  clear_has_applicationtype();
}
inline const ::std::string& ApplicationSubmissionContextProto::applicationtype() const {
  return *applicationtype_;
}
inline void ApplicationSubmissionContextProto::set_applicationtype(const ::std::string& value) {
  set_has_applicationtype();
  if (applicationtype_ == _default_applicationtype_) {
    applicationtype_ = new ::std::string;
  }
  applicationtype_->assign(value);
}
inline void ApplicationSubmissionContextProto::set_applicationtype(const char* value) {
  set_has_applicationtype();
  if (applicationtype_ == _default_applicationtype_) {
    applicationtype_ = new ::std::string;
  }
  applicationtype_->assign(value);
}
inline void ApplicationSubmissionContextProto::set_applicationtype(const char* value, size_t size) {
  set_has_applicationtype();
  if (applicationtype_ == _default_applicationtype_) {
    applicationtype_ = new ::std::string;
  }
  applicationtype_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ApplicationSubmissionContextProto::mutable_applicationtype() {
  set_has_applicationtype();
  if (applicationtype_ == _default_applicationtype_) {
    applicationtype_ = new ::std::string(*_default_applicationtype_);
  }
  return applicationtype_;
}
inline ::std::string* ApplicationSubmissionContextProto::release_applicationtype() {
  clear_has_applicationtype();
  if (applicationtype_ == _default_applicationtype_) {
    return NULL;
  } else {
    ::std::string* temp = applicationtype_;
    applicationtype_ = const_cast< ::std::string*>(_default_applicationtype_);
    return temp;
  }
}
inline void ApplicationSubmissionContextProto::set_allocated_applicationtype(::std::string* applicationtype) {
  if (applicationtype_ != _default_applicationtype_) {
    delete applicationtype_;
  }
  if (applicationtype) {
    set_has_applicationtype();
    applicationtype_ = applicationtype;
  } else {
    clear_has_applicationtype();
    applicationtype_ = const_cast< ::std::string*>(_default_applicationtype_);
  }
}

// -------------------------------------------------------------------

// ApplicationACLMapProto

// optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;
inline bool ApplicationACLMapProto::has_accesstype() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ApplicationACLMapProto::set_has_accesstype() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ApplicationACLMapProto::clear_has_accesstype() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ApplicationACLMapProto::clear_accesstype() {
  accesstype_ = 1;
  clear_has_accesstype();
}
inline ::hadoop::yarn::ApplicationAccessTypeProto ApplicationACLMapProto::accesstype() const {
  return static_cast< ::hadoop::yarn::ApplicationAccessTypeProto >(accesstype_);
}
inline void ApplicationACLMapProto::set_accesstype(::hadoop::yarn::ApplicationAccessTypeProto value) {
  assert(::hadoop::yarn::ApplicationAccessTypeProto_IsValid(value));
  set_has_accesstype();
  accesstype_ = value;
}

// optional string acl = 2 [default = " "];
inline bool ApplicationACLMapProto::has_acl() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ApplicationACLMapProto::set_has_acl() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ApplicationACLMapProto::clear_has_acl() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ApplicationACLMapProto::clear_acl() {
  if (acl_ != _default_acl_) {
    acl_->assign(*_default_acl_);
  }
  clear_has_acl();
}
inline const ::std::string& ApplicationACLMapProto::acl() const {
  return *acl_;
}
inline void ApplicationACLMapProto::set_acl(const ::std::string& value) {
  set_has_acl();
  if (acl_ == _default_acl_) {
    acl_ = new ::std::string;
  }
  acl_->assign(value);
}
inline void ApplicationACLMapProto::set_acl(const char* value) {
  set_has_acl();
  if (acl_ == _default_acl_) {
    acl_ = new ::std::string;
  }
  acl_->assign(value);
}
inline void ApplicationACLMapProto::set_acl(const char* value, size_t size) {
  set_has_acl();
  if (acl_ == _default_acl_) {
    acl_ = new ::std::string;
  }
  acl_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ApplicationACLMapProto::mutable_acl() {
  set_has_acl();
  if (acl_ == _default_acl_) {
    acl_ = new ::std::string(*_default_acl_);
  }
  return acl_;
}
inline ::std::string* ApplicationACLMapProto::release_acl() {
  clear_has_acl();
  if (acl_ == _default_acl_) {
    return NULL;
  } else {
    ::std::string* temp = acl_;
    acl_ = const_cast< ::std::string*>(_default_acl_);
    return temp;
  }
}
inline void ApplicationACLMapProto::set_allocated_acl(::std::string* acl) {
  if (acl_ != _default_acl_) {
    delete acl_;
  }
  if (acl) {
    set_has_acl();
    acl_ = acl;
  } else {
    clear_has_acl();
    acl_ = const_cast< ::std::string*>(_default_acl_);
  }
}

// -------------------------------------------------------------------

// YarnClusterMetricsProto

// optional int32 num_node_managers = 1;
inline bool YarnClusterMetricsProto::has_num_node_managers() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void YarnClusterMetricsProto::set_has_num_node_managers() {
  _has_bits_[0] |= 0x00000001u;
}
inline void YarnClusterMetricsProto::clear_has_num_node_managers() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void YarnClusterMetricsProto::clear_num_node_managers() {
  num_node_managers_ = 0;
  clear_has_num_node_managers();
}
inline ::google::protobuf::int32 YarnClusterMetricsProto::num_node_managers() const {
  return num_node_managers_;
}
inline void YarnClusterMetricsProto::set_num_node_managers(::google::protobuf::int32 value) {
  set_has_num_node_managers();
  num_node_managers_ = value;
}

// -------------------------------------------------------------------

// QueueInfoProto

// optional string queueName = 1;
inline bool QueueInfoProto::has_queuename() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void QueueInfoProto::set_has_queuename() {
  _has_bits_[0] |= 0x00000001u;
}
inline void QueueInfoProto::clear_has_queuename() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void QueueInfoProto::clear_queuename() {
  if (queuename_ != &::google::protobuf::internal::kEmptyString) {
    queuename_->clear();
  }
  clear_has_queuename();
}
inline const ::std::string& QueueInfoProto::queuename() const {
  return *queuename_;
}
inline void QueueInfoProto::set_queuename(const ::std::string& value) {
  set_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    queuename_ = new ::std::string;
  }
  queuename_->assign(value);
}
inline void QueueInfoProto::set_queuename(const char* value) {
  set_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    queuename_ = new ::std::string;
  }
  queuename_->assign(value);
}
inline void QueueInfoProto::set_queuename(const char* value, size_t size) {
  set_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    queuename_ = new ::std::string;
  }
  queuename_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* QueueInfoProto::mutable_queuename() {
  set_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    queuename_ = new ::std::string;
  }
  return queuename_;
}
inline ::std::string* QueueInfoProto::release_queuename() {
  clear_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = queuename_;
    queuename_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void QueueInfoProto::set_allocated_queuename(::std::string* queuename) {
  if (queuename_ != &::google::protobuf::internal::kEmptyString) {
    delete queuename_;
  }
  if (queuename) {
    set_has_queuename();
    queuename_ = queuename;
  } else {
    clear_has_queuename();
    queuename_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional float capacity = 2;
inline bool QueueInfoProto::has_capacity() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void QueueInfoProto::set_has_capacity() {
  _has_bits_[0] |= 0x00000002u;
}
inline void QueueInfoProto::clear_has_capacity() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void QueueInfoProto::clear_capacity() {
  capacity_ = 0;
  clear_has_capacity();
}
inline float QueueInfoProto::capacity() const {
  return capacity_;
}
inline void QueueInfoProto::set_capacity(float value) {
  set_has_capacity();
  capacity_ = value;
}

// optional float maximumCapacity = 3;
inline bool QueueInfoProto::has_maximumcapacity() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void QueueInfoProto::set_has_maximumcapacity() {
  _has_bits_[0] |= 0x00000004u;
}
inline void QueueInfoProto::clear_has_maximumcapacity() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void QueueInfoProto::clear_maximumcapacity() {
  maximumcapacity_ = 0;
  clear_has_maximumcapacity();
}
inline float QueueInfoProto::maximumcapacity() const {
  return maximumcapacity_;
}
inline void QueueInfoProto::set_maximumcapacity(float value) {
  set_has_maximumcapacity();
  maximumcapacity_ = value;
}

// optional float currentCapacity = 4;
inline bool QueueInfoProto::has_currentcapacity() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void QueueInfoProto::set_has_currentcapacity() {
  _has_bits_[0] |= 0x00000008u;
}
inline void QueueInfoProto::clear_has_currentcapacity() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void QueueInfoProto::clear_currentcapacity() {
  currentcapacity_ = 0;
  clear_has_currentcapacity();
}
inline float QueueInfoProto::currentcapacity() const {
  return currentcapacity_;
}
inline void QueueInfoProto::set_currentcapacity(float value) {
  set_has_currentcapacity();
  currentcapacity_ = value;
}

// optional .hadoop.yarn.QueueStateProto state = 5;
inline bool QueueInfoProto::has_state() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void QueueInfoProto::set_has_state() {
  _has_bits_[0] |= 0x00000010u;
}
inline void QueueInfoProto::clear_has_state() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void QueueInfoProto::clear_state() {
  state_ = 1;
  clear_has_state();
}
inline ::hadoop::yarn::QueueStateProto QueueInfoProto::state() const {
  return static_cast< ::hadoop::yarn::QueueStateProto >(state_);
}
inline void QueueInfoProto::set_state(::hadoop::yarn::QueueStateProto value) {
  assert(::hadoop::yarn::QueueStateProto_IsValid(value));
  set_has_state();
  state_ = value;
}

// repeated .hadoop.yarn.QueueInfoProto childQueues = 6;
inline int QueueInfoProto::childqueues_size() const {
  return childqueues_.size();
}
inline void QueueInfoProto::clear_childqueues() {
  childqueues_.Clear();
}
inline const ::hadoop::yarn::QueueInfoProto& QueueInfoProto::childqueues(int index) const {
  return childqueues_.Get(index);
}
inline ::hadoop::yarn::QueueInfoProto* QueueInfoProto::mutable_childqueues(int index) {
  return childqueues_.Mutable(index);
}
inline ::hadoop::yarn::QueueInfoProto* QueueInfoProto::add_childqueues() {
  return childqueues_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::QueueInfoProto >&
QueueInfoProto::childqueues() const {
  return childqueues_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::QueueInfoProto >*
QueueInfoProto::mutable_childqueues() {
  return &childqueues_;
}

// repeated .hadoop.yarn.ApplicationReportProto applications = 7;
inline int QueueInfoProto::applications_size() const {
  return applications_.size();
}
inline void QueueInfoProto::clear_applications() {
  applications_.Clear();
}
inline const ::hadoop::yarn::ApplicationReportProto& QueueInfoProto::applications(int index) const {
  return applications_.Get(index);
}
inline ::hadoop::yarn::ApplicationReportProto* QueueInfoProto::mutable_applications(int index) {
  return applications_.Mutable(index);
}
inline ::hadoop::yarn::ApplicationReportProto* QueueInfoProto::add_applications() {
  return applications_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationReportProto >&
QueueInfoProto::applications() const {
  return applications_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationReportProto >*
QueueInfoProto::mutable_applications() {
  return &applications_;
}

// -------------------------------------------------------------------

// QueueUserACLInfoProto

// optional string queueName = 1;
inline bool QueueUserACLInfoProto::has_queuename() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void QueueUserACLInfoProto::set_has_queuename() {
  _has_bits_[0] |= 0x00000001u;
}
inline void QueueUserACLInfoProto::clear_has_queuename() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void QueueUserACLInfoProto::clear_queuename() {
  if (queuename_ != &::google::protobuf::internal::kEmptyString) {
    queuename_->clear();
  }
  clear_has_queuename();
}
inline const ::std::string& QueueUserACLInfoProto::queuename() const {
  return *queuename_;
}
inline void QueueUserACLInfoProto::set_queuename(const ::std::string& value) {
  set_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    queuename_ = new ::std::string;
  }
  queuename_->assign(value);
}
inline void QueueUserACLInfoProto::set_queuename(const char* value) {
  set_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    queuename_ = new ::std::string;
  }
  queuename_->assign(value);
}
inline void QueueUserACLInfoProto::set_queuename(const char* value, size_t size) {
  set_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    queuename_ = new ::std::string;
  }
  queuename_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* QueueUserACLInfoProto::mutable_queuename() {
  set_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    queuename_ = new ::std::string;
  }
  return queuename_;
}
inline ::std::string* QueueUserACLInfoProto::release_queuename() {
  clear_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = queuename_;
    queuename_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void QueueUserACLInfoProto::set_allocated_queuename(::std::string* queuename) {
  if (queuename_ != &::google::protobuf::internal::kEmptyString) {
    delete queuename_;
  }
  if (queuename) {
    set_has_queuename();
    queuename_ = queuename;
  } else {
    clear_has_queuename();
    queuename_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// repeated .hadoop.yarn.QueueACLProto userAcls = 2;
inline int QueueUserACLInfoProto::useracls_size() const {
  return useracls_.size();
}
inline void QueueUserACLInfoProto::clear_useracls() {
  useracls_.Clear();
}
inline ::hadoop::yarn::QueueACLProto QueueUserACLInfoProto::useracls(int index) const {
  return static_cast< ::hadoop::yarn::QueueACLProto >(useracls_.Get(index));
}
inline void QueueUserACLInfoProto::set_useracls(int index, ::hadoop::yarn::QueueACLProto value) {
  assert(::hadoop::yarn::QueueACLProto_IsValid(value));
  useracls_.Set(index, value);
}
inline void QueueUserACLInfoProto::add_useracls(::hadoop::yarn::QueueACLProto value) {
  assert(::hadoop::yarn::QueueACLProto_IsValid(value));
  useracls_.Add(value);
}
inline const ::google::protobuf::RepeatedField<int>&
QueueUserACLInfoProto::useracls() const {
  return useracls_;
}
inline ::google::protobuf::RepeatedField<int>*
QueueUserACLInfoProto::mutable_useracls() {
  return &useracls_;
}

// -------------------------------------------------------------------

// ContainerLaunchContextProto

// repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;
inline int ContainerLaunchContextProto::localresources_size() const {
  return localresources_.size();
}
inline void ContainerLaunchContextProto::clear_localresources() {
  localresources_.Clear();
}
inline const ::hadoop::yarn::StringLocalResourceMapProto& ContainerLaunchContextProto::localresources(int index) const {
  return localresources_.Get(index);
}
inline ::hadoop::yarn::StringLocalResourceMapProto* ContainerLaunchContextProto::mutable_localresources(int index) {
  return localresources_.Mutable(index);
}
inline ::hadoop::yarn::StringLocalResourceMapProto* ContainerLaunchContextProto::add_localresources() {
  return localresources_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringLocalResourceMapProto >&
ContainerLaunchContextProto::localresources() const {
  return localresources_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringLocalResourceMapProto >*
ContainerLaunchContextProto::mutable_localresources() {
  return &localresources_;
}

// optional bytes tokens = 2;
inline bool ContainerLaunchContextProto::has_tokens() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ContainerLaunchContextProto::set_has_tokens() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ContainerLaunchContextProto::clear_has_tokens() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ContainerLaunchContextProto::clear_tokens() {
  if (tokens_ != &::google::protobuf::internal::kEmptyString) {
    tokens_->clear();
  }
  clear_has_tokens();
}
inline const ::std::string& ContainerLaunchContextProto::tokens() const {
  return *tokens_;
}
inline void ContainerLaunchContextProto::set_tokens(const ::std::string& value) {
  set_has_tokens();
  if (tokens_ == &::google::protobuf::internal::kEmptyString) {
    tokens_ = new ::std::string;
  }
  tokens_->assign(value);
}
inline void ContainerLaunchContextProto::set_tokens(const char* value) {
  set_has_tokens();
  if (tokens_ == &::google::protobuf::internal::kEmptyString) {
    tokens_ = new ::std::string;
  }
  tokens_->assign(value);
}
inline void ContainerLaunchContextProto::set_tokens(const void* value, size_t size) {
  set_has_tokens();
  if (tokens_ == &::google::protobuf::internal::kEmptyString) {
    tokens_ = new ::std::string;
  }
  tokens_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ContainerLaunchContextProto::mutable_tokens() {
  set_has_tokens();
  if (tokens_ == &::google::protobuf::internal::kEmptyString) {
    tokens_ = new ::std::string;
  }
  return tokens_;
}
inline ::std::string* ContainerLaunchContextProto::release_tokens() {
  clear_has_tokens();
  if (tokens_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = tokens_;
    tokens_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void ContainerLaunchContextProto::set_allocated_tokens(::std::string* tokens) {
  if (tokens_ != &::google::protobuf::internal::kEmptyString) {
    delete tokens_;
  }
  if (tokens) {
    set_has_tokens();
    tokens_ = tokens;
  } else {
    clear_has_tokens();
    tokens_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// repeated .hadoop.yarn.StringBytesMapProto service_data = 3;
inline int ContainerLaunchContextProto::service_data_size() const {
  return service_data_.size();
}
inline void ContainerLaunchContextProto::clear_service_data() {
  service_data_.Clear();
}
inline const ::hadoop::yarn::StringBytesMapProto& ContainerLaunchContextProto::service_data(int index) const {
  return service_data_.Get(index);
}
inline ::hadoop::yarn::StringBytesMapProto* ContainerLaunchContextProto::mutable_service_data(int index) {
  return service_data_.Mutable(index);
}
inline ::hadoop::yarn::StringBytesMapProto* ContainerLaunchContextProto::add_service_data() {
  return service_data_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto >&
ContainerLaunchContextProto::service_data() const {
  return service_data_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto >*
ContainerLaunchContextProto::mutable_service_data() {
  return &service_data_;
}

// repeated .hadoop.yarn.StringStringMapProto environment = 4;
inline int ContainerLaunchContextProto::environment_size() const {
  return environment_.size();
}
inline void ContainerLaunchContextProto::clear_environment() {
  environment_.Clear();
}
inline const ::hadoop::yarn::StringStringMapProto& ContainerLaunchContextProto::environment(int index) const {
  return environment_.Get(index);
}
inline ::hadoop::yarn::StringStringMapProto* ContainerLaunchContextProto::mutable_environment(int index) {
  return environment_.Mutable(index);
}
inline ::hadoop::yarn::StringStringMapProto* ContainerLaunchContextProto::add_environment() {
  return environment_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringStringMapProto >&
ContainerLaunchContextProto::environment() const {
  return environment_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringStringMapProto >*
ContainerLaunchContextProto::mutable_environment() {
  return &environment_;
}

// repeated string command = 5;
inline int ContainerLaunchContextProto::command_size() const {
  return command_.size();
}
inline void ContainerLaunchContextProto::clear_command() {
  command_.Clear();
}
inline const ::std::string& ContainerLaunchContextProto::command(int index) const {
  return command_.Get(index);
}
inline ::std::string* ContainerLaunchContextProto::mutable_command(int index) {
  return command_.Mutable(index);
}
inline void ContainerLaunchContextProto::set_command(int index, const ::std::string& value) {
  command_.Mutable(index)->assign(value);
}
inline void ContainerLaunchContextProto::set_command(int index, const char* value) {
  command_.Mutable(index)->assign(value);
}
inline void ContainerLaunchContextProto::set_command(int index, const char* value, size_t size) {
  command_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ContainerLaunchContextProto::add_command() {
  return command_.Add();
}
inline void ContainerLaunchContextProto::add_command(const ::std::string& value) {
  command_.Add()->assign(value);
}
inline void ContainerLaunchContextProto::add_command(const char* value) {
  command_.Add()->assign(value);
}
inline void ContainerLaunchContextProto::add_command(const char* value, size_t size) {
  command_.Add()->assign(reinterpret_cast<const char*>(value), size);
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
ContainerLaunchContextProto::command() const {
  return command_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
ContainerLaunchContextProto::mutable_command() {
  return &command_;
}

// repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;
inline int ContainerLaunchContextProto::application_acls_size() const {
  return application_acls_.size();
}
inline void ContainerLaunchContextProto::clear_application_acls() {
  application_acls_.Clear();
}
inline const ::hadoop::yarn::ApplicationACLMapProto& ContainerLaunchContextProto::application_acls(int index) const {
  return application_acls_.Get(index);
}
inline ::hadoop::yarn::ApplicationACLMapProto* ContainerLaunchContextProto::mutable_application_acls(int index) {
  return application_acls_.Mutable(index);
}
inline ::hadoop::yarn::ApplicationACLMapProto* ContainerLaunchContextProto::add_application_acls() {
  return application_acls_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationACLMapProto >&
ContainerLaunchContextProto::application_acls() const {
  return application_acls_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationACLMapProto >*
ContainerLaunchContextProto::mutable_application_acls() {
  return &application_acls_;
}

// -------------------------------------------------------------------

// ContainerStatusProto

// optional .hadoop.yarn.ContainerIdProto container_id = 1;
inline bool ContainerStatusProto::has_container_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ContainerStatusProto::set_has_container_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ContainerStatusProto::clear_has_container_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ContainerStatusProto::clear_container_id() {
  if (container_id_ != NULL) container_id_->::hadoop::yarn::ContainerIdProto::Clear();
  clear_has_container_id();
}
inline const ::hadoop::yarn::ContainerIdProto& ContainerStatusProto::container_id() const {
  return container_id_ != NULL ? *container_id_ : *default_instance_->container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* ContainerStatusProto::mutable_container_id() {
  set_has_container_id();
  if (container_id_ == NULL) container_id_ = new ::hadoop::yarn::ContainerIdProto;
  return container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* ContainerStatusProto::release_container_id() {
  clear_has_container_id();
  ::hadoop::yarn::ContainerIdProto* temp = container_id_;
  container_id_ = NULL;
  return temp;
}
inline void ContainerStatusProto::set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id) {
  delete container_id_;
  container_id_ = container_id;
  if (container_id) {
    set_has_container_id();
  } else {
    clear_has_container_id();
  }
}

// optional .hadoop.yarn.ContainerStateProto state = 2;
inline bool ContainerStatusProto::has_state() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ContainerStatusProto::set_has_state() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ContainerStatusProto::clear_has_state() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ContainerStatusProto::clear_state() {
  state_ = 1;
  clear_has_state();
}
inline ::hadoop::yarn::ContainerStateProto ContainerStatusProto::state() const {
  return static_cast< ::hadoop::yarn::ContainerStateProto >(state_);
}
inline void ContainerStatusProto::set_state(::hadoop::yarn::ContainerStateProto value) {
  assert(::hadoop::yarn::ContainerStateProto_IsValid(value));
  set_has_state();
  state_ = value;
}

// optional string diagnostics = 3 [default = "N/A"];
inline bool ContainerStatusProto::has_diagnostics() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ContainerStatusProto::set_has_diagnostics() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ContainerStatusProto::clear_has_diagnostics() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ContainerStatusProto::clear_diagnostics() {
  if (diagnostics_ != _default_diagnostics_) {
    diagnostics_->assign(*_default_diagnostics_);
  }
  clear_has_diagnostics();
}
inline const ::std::string& ContainerStatusProto::diagnostics() const {
  return *diagnostics_;
}
inline void ContainerStatusProto::set_diagnostics(const ::std::string& value) {
  set_has_diagnostics();
  if (diagnostics_ == _default_diagnostics_) {
    diagnostics_ = new ::std::string;
  }
  diagnostics_->assign(value);
}
inline void ContainerStatusProto::set_diagnostics(const char* value) {
  set_has_diagnostics();
  if (diagnostics_ == _default_diagnostics_) {
    diagnostics_ = new ::std::string;
  }
  diagnostics_->assign(value);
}
inline void ContainerStatusProto::set_diagnostics(const char* value, size_t size) {
  set_has_diagnostics();
  if (diagnostics_ == _default_diagnostics_) {
    diagnostics_ = new ::std::string;
  }
  diagnostics_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* ContainerStatusProto::mutable_diagnostics() {
  set_has_diagnostics();
  if (diagnostics_ == _default_diagnostics_) {
    diagnostics_ = new ::std::string(*_default_diagnostics_);
  }
  return diagnostics_;
}
inline ::std::string* ContainerStatusProto::release_diagnostics() {
  clear_has_diagnostics();
  if (diagnostics_ == _default_diagnostics_) {
    return NULL;
  } else {
    ::std::string* temp = diagnostics_;
    diagnostics_ = const_cast< ::std::string*>(_default_diagnostics_);
    return temp;
  }
}
inline void ContainerStatusProto::set_allocated_diagnostics(::std::string* diagnostics) {
  if (diagnostics_ != _default_diagnostics_) {
    delete diagnostics_;
  }
  if (diagnostics) {
    set_has_diagnostics();
    diagnostics_ = diagnostics;
  } else {
    clear_has_diagnostics();
    diagnostics_ = const_cast< ::std::string*>(_default_diagnostics_);
  }
}

// optional int32 exit_status = 4 [default = -1000];
inline bool ContainerStatusProto::has_exit_status() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ContainerStatusProto::set_has_exit_status() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ContainerStatusProto::clear_has_exit_status() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ContainerStatusProto::clear_exit_status() {
  exit_status_ = -1000;
  clear_has_exit_status();
}
inline ::google::protobuf::int32 ContainerStatusProto::exit_status() const {
  return exit_status_;
}
inline void ContainerStatusProto::set_exit_status(::google::protobuf::int32 value) {
  set_has_exit_status();
  exit_status_ = value;
}

// -------------------------------------------------------------------

// ContainerResourceIncreaseRequestProto

// optional .hadoop.yarn.ContainerIdProto container_id = 1;
inline bool ContainerResourceIncreaseRequestProto::has_container_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ContainerResourceIncreaseRequestProto::set_has_container_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ContainerResourceIncreaseRequestProto::clear_has_container_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ContainerResourceIncreaseRequestProto::clear_container_id() {
  if (container_id_ != NULL) container_id_->::hadoop::yarn::ContainerIdProto::Clear();
  clear_has_container_id();
}
inline const ::hadoop::yarn::ContainerIdProto& ContainerResourceIncreaseRequestProto::container_id() const {
  return container_id_ != NULL ? *container_id_ : *default_instance_->container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* ContainerResourceIncreaseRequestProto::mutable_container_id() {
  set_has_container_id();
  if (container_id_ == NULL) container_id_ = new ::hadoop::yarn::ContainerIdProto;
  return container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* ContainerResourceIncreaseRequestProto::release_container_id() {
  clear_has_container_id();
  ::hadoop::yarn::ContainerIdProto* temp = container_id_;
  container_id_ = NULL;
  return temp;
}
inline void ContainerResourceIncreaseRequestProto::set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id) {
  delete container_id_;
  container_id_ = container_id;
  if (container_id) {
    set_has_container_id();
  } else {
    clear_has_container_id();
  }
}

// optional .hadoop.yarn.ResourceProto capability = 2;
inline bool ContainerResourceIncreaseRequestProto::has_capability() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ContainerResourceIncreaseRequestProto::set_has_capability() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ContainerResourceIncreaseRequestProto::clear_has_capability() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ContainerResourceIncreaseRequestProto::clear_capability() {
  if (capability_ != NULL) capability_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_capability();
}
inline const ::hadoop::yarn::ResourceProto& ContainerResourceIncreaseRequestProto::capability() const {
  return capability_ != NULL ? *capability_ : *default_instance_->capability_;
}
inline ::hadoop::yarn::ResourceProto* ContainerResourceIncreaseRequestProto::mutable_capability() {
  set_has_capability();
  if (capability_ == NULL) capability_ = new ::hadoop::yarn::ResourceProto;
  return capability_;
}
inline ::hadoop::yarn::ResourceProto* ContainerResourceIncreaseRequestProto::release_capability() {
  clear_has_capability();
  ::hadoop::yarn::ResourceProto* temp = capability_;
  capability_ = NULL;
  return temp;
}
inline void ContainerResourceIncreaseRequestProto::set_allocated_capability(::hadoop::yarn::ResourceProto* capability) {
  delete capability_;
  capability_ = capability;
  if (capability) {
    set_has_capability();
  } else {
    clear_has_capability();
  }
}

// -------------------------------------------------------------------

// ContainerResourceIncreaseProto

// optional .hadoop.yarn.ContainerIdProto container_id = 1;
inline bool ContainerResourceIncreaseProto::has_container_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ContainerResourceIncreaseProto::set_has_container_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ContainerResourceIncreaseProto::clear_has_container_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ContainerResourceIncreaseProto::clear_container_id() {
  if (container_id_ != NULL) container_id_->::hadoop::yarn::ContainerIdProto::Clear();
  clear_has_container_id();
}
inline const ::hadoop::yarn::ContainerIdProto& ContainerResourceIncreaseProto::container_id() const {
  return container_id_ != NULL ? *container_id_ : *default_instance_->container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* ContainerResourceIncreaseProto::mutable_container_id() {
  set_has_container_id();
  if (container_id_ == NULL) container_id_ = new ::hadoop::yarn::ContainerIdProto;
  return container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* ContainerResourceIncreaseProto::release_container_id() {
  clear_has_container_id();
  ::hadoop::yarn::ContainerIdProto* temp = container_id_;
  container_id_ = NULL;
  return temp;
}
inline void ContainerResourceIncreaseProto::set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id) {
  delete container_id_;
  container_id_ = container_id;
  if (container_id) {
    set_has_container_id();
  } else {
    clear_has_container_id();
  }
}

// optional .hadoop.yarn.ResourceProto capability = 2;
inline bool ContainerResourceIncreaseProto::has_capability() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ContainerResourceIncreaseProto::set_has_capability() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ContainerResourceIncreaseProto::clear_has_capability() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ContainerResourceIncreaseProto::clear_capability() {
  if (capability_ != NULL) capability_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_capability();
}
inline const ::hadoop::yarn::ResourceProto& ContainerResourceIncreaseProto::capability() const {
  return capability_ != NULL ? *capability_ : *default_instance_->capability_;
}
inline ::hadoop::yarn::ResourceProto* ContainerResourceIncreaseProto::mutable_capability() {
  set_has_capability();
  if (capability_ == NULL) capability_ = new ::hadoop::yarn::ResourceProto;
  return capability_;
}
inline ::hadoop::yarn::ResourceProto* ContainerResourceIncreaseProto::release_capability() {
  clear_has_capability();
  ::hadoop::yarn::ResourceProto* temp = capability_;
  capability_ = NULL;
  return temp;
}
inline void ContainerResourceIncreaseProto::set_allocated_capability(::hadoop::yarn::ResourceProto* capability) {
  delete capability_;
  capability_ = capability;
  if (capability) {
    set_has_capability();
  } else {
    clear_has_capability();
  }
}

// optional .hadoop.common.TokenProto container_token = 3;
inline bool ContainerResourceIncreaseProto::has_container_token() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ContainerResourceIncreaseProto::set_has_container_token() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ContainerResourceIncreaseProto::clear_has_container_token() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ContainerResourceIncreaseProto::clear_container_token() {
  if (container_token_ != NULL) container_token_->::hadoop::common::TokenProto::Clear();
  clear_has_container_token();
}
inline const ::hadoop::common::TokenProto& ContainerResourceIncreaseProto::container_token() const {
  return container_token_ != NULL ? *container_token_ : *default_instance_->container_token_;
}
inline ::hadoop::common::TokenProto* ContainerResourceIncreaseProto::mutable_container_token() {
  set_has_container_token();
  if (container_token_ == NULL) container_token_ = new ::hadoop::common::TokenProto;
  return container_token_;
}
inline ::hadoop::common::TokenProto* ContainerResourceIncreaseProto::release_container_token() {
  clear_has_container_token();
  ::hadoop::common::TokenProto* temp = container_token_;
  container_token_ = NULL;
  return temp;
}
inline void ContainerResourceIncreaseProto::set_allocated_container_token(::hadoop::common::TokenProto* container_token) {
  delete container_token_;
  container_token_ = container_token;
  if (container_token) {
    set_has_container_token();
  } else {
    clear_has_container_token();
  }
}

// -------------------------------------------------------------------

// ContainerResourceDecreaseProto

// optional .hadoop.yarn.ContainerIdProto container_id = 1;
inline bool ContainerResourceDecreaseProto::has_container_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ContainerResourceDecreaseProto::set_has_container_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ContainerResourceDecreaseProto::clear_has_container_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ContainerResourceDecreaseProto::clear_container_id() {
  if (container_id_ != NULL) container_id_->::hadoop::yarn::ContainerIdProto::Clear();
  clear_has_container_id();
}
inline const ::hadoop::yarn::ContainerIdProto& ContainerResourceDecreaseProto::container_id() const {
  return container_id_ != NULL ? *container_id_ : *default_instance_->container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* ContainerResourceDecreaseProto::mutable_container_id() {
  set_has_container_id();
  if (container_id_ == NULL) container_id_ = new ::hadoop::yarn::ContainerIdProto;
  return container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* ContainerResourceDecreaseProto::release_container_id() {
  clear_has_container_id();
  ::hadoop::yarn::ContainerIdProto* temp = container_id_;
  container_id_ = NULL;
  return temp;
}
inline void ContainerResourceDecreaseProto::set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id) {
  delete container_id_;
  container_id_ = container_id;
  if (container_id) {
    set_has_container_id();
  } else {
    clear_has_container_id();
  }
}

// optional .hadoop.yarn.ResourceProto capability = 2;
inline bool ContainerResourceDecreaseProto::has_capability() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ContainerResourceDecreaseProto::set_has_capability() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ContainerResourceDecreaseProto::clear_has_capability() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ContainerResourceDecreaseProto::clear_capability() {
  if (capability_ != NULL) capability_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_capability();
}
inline const ::hadoop::yarn::ResourceProto& ContainerResourceDecreaseProto::capability() const {
  return capability_ != NULL ? *capability_ : *default_instance_->capability_;
}
inline ::hadoop::yarn::ResourceProto* ContainerResourceDecreaseProto::mutable_capability() {
  set_has_capability();
  if (capability_ == NULL) capability_ = new ::hadoop::yarn::ResourceProto;
  return capability_;
}
inline ::hadoop::yarn::ResourceProto* ContainerResourceDecreaseProto::release_capability() {
  clear_has_capability();
  ::hadoop::yarn::ResourceProto* temp = capability_;
  capability_ = NULL;
  return temp;
}
inline void ContainerResourceDecreaseProto::set_allocated_capability(::hadoop::yarn::ResourceProto* capability) {
  delete capability_;
  capability_ = capability;
  if (capability) {
    set_has_capability();
  } else {
    clear_has_capability();
  }
}

// -------------------------------------------------------------------

// StringLocalResourceMapProto

// optional string key = 1;
inline bool StringLocalResourceMapProto::has_key() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void StringLocalResourceMapProto::set_has_key() {
  _has_bits_[0] |= 0x00000001u;
}
inline void StringLocalResourceMapProto::clear_has_key() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void StringLocalResourceMapProto::clear_key() {
  if (key_ != &::google::protobuf::internal::kEmptyString) {
    key_->clear();
  }
  clear_has_key();
}
inline const ::std::string& StringLocalResourceMapProto::key() const {
  return *key_;
}
inline void StringLocalResourceMapProto::set_key(const ::std::string& value) {
  set_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    key_ = new ::std::string;
  }
  key_->assign(value);
}
inline void StringLocalResourceMapProto::set_key(const char* value) {
  set_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    key_ = new ::std::string;
  }
  key_->assign(value);
}
inline void StringLocalResourceMapProto::set_key(const char* value, size_t size) {
  set_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    key_ = new ::std::string;
  }
  key_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* StringLocalResourceMapProto::mutable_key() {
  set_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    key_ = new ::std::string;
  }
  return key_;
}
inline ::std::string* StringLocalResourceMapProto::release_key() {
  clear_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = key_;
    key_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void StringLocalResourceMapProto::set_allocated_key(::std::string* key) {
  if (key_ != &::google::protobuf::internal::kEmptyString) {
    delete key_;
  }
  if (key) {
    set_has_key();
    key_ = key;
  } else {
    clear_has_key();
    key_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional .hadoop.yarn.LocalResourceProto value = 2;
inline bool StringLocalResourceMapProto::has_value() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void StringLocalResourceMapProto::set_has_value() {
  _has_bits_[0] |= 0x00000002u;
}
inline void StringLocalResourceMapProto::clear_has_value() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void StringLocalResourceMapProto::clear_value() {
  if (value_ != NULL) value_->::hadoop::yarn::LocalResourceProto::Clear();
  clear_has_value();
}
inline const ::hadoop::yarn::LocalResourceProto& StringLocalResourceMapProto::value() const {
  return value_ != NULL ? *value_ : *default_instance_->value_;
}
inline ::hadoop::yarn::LocalResourceProto* StringLocalResourceMapProto::mutable_value() {
  set_has_value();
  if (value_ == NULL) value_ = new ::hadoop::yarn::LocalResourceProto;
  return value_;
}
inline ::hadoop::yarn::LocalResourceProto* StringLocalResourceMapProto::release_value() {
  clear_has_value();
  ::hadoop::yarn::LocalResourceProto* temp = value_;
  value_ = NULL;
  return temp;
}
inline void StringLocalResourceMapProto::set_allocated_value(::hadoop::yarn::LocalResourceProto* value) {
  delete value_;
  value_ = value;
  if (value) {
    set_has_value();
  } else {
    clear_has_value();
  }
}

// -------------------------------------------------------------------

// StringStringMapProto

// optional string key = 1;
inline bool StringStringMapProto::has_key() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void StringStringMapProto::set_has_key() {
  _has_bits_[0] |= 0x00000001u;
}
inline void StringStringMapProto::clear_has_key() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void StringStringMapProto::clear_key() {
  if (key_ != &::google::protobuf::internal::kEmptyString) {
    key_->clear();
  }
  clear_has_key();
}
inline const ::std::string& StringStringMapProto::key() const {
  return *key_;
}
inline void StringStringMapProto::set_key(const ::std::string& value) {
  set_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    key_ = new ::std::string;
  }
  key_->assign(value);
}
inline void StringStringMapProto::set_key(const char* value) {
  set_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    key_ = new ::std::string;
  }
  key_->assign(value);
}
inline void StringStringMapProto::set_key(const char* value, size_t size) {
  set_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    key_ = new ::std::string;
  }
  key_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* StringStringMapProto::mutable_key() {
  set_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    key_ = new ::std::string;
  }
  return key_;
}
inline ::std::string* StringStringMapProto::release_key() {
  clear_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = key_;
    key_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void StringStringMapProto::set_allocated_key(::std::string* key) {
  if (key_ != &::google::protobuf::internal::kEmptyString) {
    delete key_;
  }
  if (key) {
    set_has_key();
    key_ = key;
  } else {
    clear_has_key();
    key_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional string value = 2;
inline bool StringStringMapProto::has_value() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void StringStringMapProto::set_has_value() {
  _has_bits_[0] |= 0x00000002u;
}
inline void StringStringMapProto::clear_has_value() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void StringStringMapProto::clear_value() {
  if (value_ != &::google::protobuf::internal::kEmptyString) {
    value_->clear();
  }
  clear_has_value();
}
inline const ::std::string& StringStringMapProto::value() const {
  return *value_;
}
inline void StringStringMapProto::set_value(const ::std::string& value) {
  set_has_value();
  if (value_ == &::google::protobuf::internal::kEmptyString) {
    value_ = new ::std::string;
  }
  value_->assign(value);
}
inline void StringStringMapProto::set_value(const char* value) {
  set_has_value();
  if (value_ == &::google::protobuf::internal::kEmptyString) {
    value_ = new ::std::string;
  }
  value_->assign(value);
}
inline void StringStringMapProto::set_value(const char* value, size_t size) {
  set_has_value();
  if (value_ == &::google::protobuf::internal::kEmptyString) {
    value_ = new ::std::string;
  }
  value_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* StringStringMapProto::mutable_value() {
  set_has_value();
  if (value_ == &::google::protobuf::internal::kEmptyString) {
    value_ = new ::std::string;
  }
  return value_;
}
inline ::std::string* StringStringMapProto::release_value() {
  clear_has_value();
  if (value_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = value_;
    value_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void StringStringMapProto::set_allocated_value(::std::string* value) {
  if (value_ != &::google::protobuf::internal::kEmptyString) {
    delete value_;
  }
  if (value) {
    set_has_value();
    value_ = value;
  } else {
    clear_has_value();
    value_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// -------------------------------------------------------------------

// StringBytesMapProto

// optional string key = 1;
inline bool StringBytesMapProto::has_key() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void StringBytesMapProto::set_has_key() {
  _has_bits_[0] |= 0x00000001u;
}
inline void StringBytesMapProto::clear_has_key() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void StringBytesMapProto::clear_key() {
  if (key_ != &::google::protobuf::internal::kEmptyString) {
    key_->clear();
  }
  clear_has_key();
}
inline const ::std::string& StringBytesMapProto::key() const {
  return *key_;
}
inline void StringBytesMapProto::set_key(const ::std::string& value) {
  set_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    key_ = new ::std::string;
  }
  key_->assign(value);
}
inline void StringBytesMapProto::set_key(const char* value) {
  set_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    key_ = new ::std::string;
  }
  key_->assign(value);
}
inline void StringBytesMapProto::set_key(const char* value, size_t size) {
  set_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    key_ = new ::std::string;
  }
  key_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* StringBytesMapProto::mutable_key() {
  set_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    key_ = new ::std::string;
  }
  return key_;
}
inline ::std::string* StringBytesMapProto::release_key() {
  clear_has_key();
  if (key_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = key_;
    key_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void StringBytesMapProto::set_allocated_key(::std::string* key) {
  if (key_ != &::google::protobuf::internal::kEmptyString) {
    delete key_;
  }
  if (key) {
    set_has_key();
    key_ = key;
  } else {
    clear_has_key();
    key_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional bytes value = 2;
inline bool StringBytesMapProto::has_value() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void StringBytesMapProto::set_has_value() {
  _has_bits_[0] |= 0x00000002u;
}
inline void StringBytesMapProto::clear_has_value() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void StringBytesMapProto::clear_value() {
  if (value_ != &::google::protobuf::internal::kEmptyString) {
    value_->clear();
  }
  clear_has_value();
}
inline const ::std::string& StringBytesMapProto::value() const {
  return *value_;
}
inline void StringBytesMapProto::set_value(const ::std::string& value) {
  set_has_value();
  if (value_ == &::google::protobuf::internal::kEmptyString) {
    value_ = new ::std::string;
  }
  value_->assign(value);
}
inline void StringBytesMapProto::set_value(const char* value) {
  set_has_value();
  if (value_ == &::google::protobuf::internal::kEmptyString) {
    value_ = new ::std::string;
  }
  value_->assign(value);
}
inline void StringBytesMapProto::set_value(const void* value, size_t size) {
  set_has_value();
  if (value_ == &::google::protobuf::internal::kEmptyString) {
    value_ = new ::std::string;
  }
  value_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* StringBytesMapProto::mutable_value() {
  set_has_value();
  if (value_ == &::google::protobuf::internal::kEmptyString) {
    value_ = new ::std::string;
  }
  return value_;
}
inline ::std::string* StringBytesMapProto::release_value() {
  clear_has_value();
  if (value_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = value_;
    value_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void StringBytesMapProto::set_allocated_value(::std::string* value) {
  if (value_ != &::google::protobuf::internal::kEmptyString) {
    delete value_;
  }
  if (value) {
    set_has_value();
    value_ = value;
  } else {
    clear_has_value();
    value_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}


// @@protoc_insertion_point(namespace_scope)

}  // namespace yarn
}  // namespace hadoop

#ifndef SWIG
namespace google {
namespace protobuf {

template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::yarn::ContainerStateProto>() {
  return ::hadoop::yarn::ContainerStateProto_descriptor();
}
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::yarn::YarnApplicationStateProto>() {
  return ::hadoop::yarn::YarnApplicationStateProto_descriptor();
}
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::yarn::FinalApplicationStatusProto>() {
  return ::hadoop::yarn::FinalApplicationStatusProto_descriptor();
}
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::yarn::LocalResourceVisibilityProto>() {
  return ::hadoop::yarn::LocalResourceVisibilityProto_descriptor();
}
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::yarn::LocalResourceTypeProto>() {
  return ::hadoop::yarn::LocalResourceTypeProto_descriptor();
}
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::yarn::NodeStateProto>() {
  return ::hadoop::yarn::NodeStateProto_descriptor();
}
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::yarn::AMCommandProto>() {
  return ::hadoop::yarn::AMCommandProto_descriptor();
}
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::yarn::ApplicationAccessTypeProto>() {
  return ::hadoop::yarn::ApplicationAccessTypeProto_descriptor();
}
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::yarn::QueueStateProto>() {
  return ::hadoop::yarn::QueueStateProto_descriptor();
}
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::yarn::QueueACLProto>() {
  return ::hadoop::yarn::QueueACLProto_descriptor();
}
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::yarn::ContainerExitStatusProto>() {
  return ::hadoop::yarn::ContainerExitStatusProto_descriptor();
}

}  // namespace google
}  // namespace protobuf
#endif  // SWIG

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_yarn_5fprotos_2eproto__INCLUDED
